<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>原力小站</title>
  
  <subtitle>扎导的原版正联出了吗？</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://Bithub00.com/"/>
  <updated>2021-05-29T13:46:15.885Z</updated>
  <id>http://Bithub00.com/</id>
  
  <author>
    <name>Mr.shuan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>SPAGAN Shortest Path Graph Attention Network</title>
    <link href="http://Bithub00.com/2021/05/18/SPAGAN%5BIJCAI&#39;19%5D/"/>
    <id>http://Bithub00.com/2021/05/18/SPAGAN[IJCAI&#39;19]/</id>
    <published>2021-05-18T15:04:54.239Z</published>
    <updated>2021-05-29T13:46:15.885Z</updated>
    
    <content type="html"><![CDATA[<p>IJCAI19一篇关注最短路径对中心顶点的attention聚合的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>GAT中只是中心顶点与邻域顶点的顶点间attention聚合，本文关注的是路径对中心顶点的attention聚合。一条路径往往会包含很多个顶点，怎么能够对中心顶点做到“多对一”的聚合呢？在于一条路径$p^c_{ij}$的表示$\phi(p^c_{ij})$是通过路径中所有顶点的特征取平均得到，这样一来就变成“一对一”的聚合，和GAT中的顶点间attention聚合相同。</p><div align="center"><a href="https://imgtu.com/i/2Az8VP" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2Az8VP.png" alt="2Az8VP.png" border="0" width="60%"></a></div><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="Shortest-Path-Generation"><a href="#Shortest-Path-Generation" class="headerlink" title="Shortest Path Generation"></a>Shortest Path Generation</h4><p>计算最短路径使用Dijkstra，而顶点间边的权重由它们之间的attention系数决定：</p><script type="math/tex; mode=display">W_{ij}=\frac{1}{K}\sum_{k=1}^K\alpha_{ij}^{(k)}</script><h4 id="Path-Sampling"><a href="#Path-Sampling" class="headerlink" title="Path Sampling"></a>Path Sampling</h4><p>这一阶段的核心思想是，对于有着相同长度的几条最短路径，代价最小的与中心顶点的相关性更高，代价指的就是路径上边的权重的求和。记$p_{ij}^c$为顶点i到j长度为c的一条最短路径，$P^c$表示所有$p_{ij}^c$形成的集合，取样：</p><script type="math/tex; mode=display">N_i^c=top_k(P^c),k=degree_i*r</script><h4 id="Hierarchical-Path-Aggregation"><a href="#Hierarchical-Path-Aggregation" class="headerlink" title="Hierarchical Path Aggregation"></a>Hierarchical Path Aggregation</h4><p>这一阶段的层次路径聚合分为两层，第一层聚合相同长度的路径，第二层聚合不同长度的路径。</p><p>加权系数$\alpha_{ij}^{(k)}$为中心顶点i的特征$h_i’$与路径的表示$\phi(p^c_{ij})$的attention系数：</p><script type="math/tex; mode=display">l_i^c=\sum_{k=1}^K\{\sum_{p^c_{ij}\in N_i^c}\alpha_{ij}^{(k)}\phi(p^c_{ij}) \}</script><p>在第二层，进一步聚合不同长度的路径，第一层已经得到以顶点i为中心长度为c的所有路径形成的一个特征表示$l_i^c$：</p><script type="math/tex; mode=display">h_i=\sigma\{\sum_{c=2}^C\beta_cl_i^c\}</script><p>这样一来就通过路径得到了中心顶点i的新的特征表示$h_i$。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Cora、Citeseer、Pubmed</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;IJCAI19一篇关注最短路径对中心顶点的attention聚合的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>数据库的几个证明题</title>
    <link href="http://Bithub00.com/2021/05/18/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%81%E6%98%8E/"/>
    <id>http://Bithub00.com/2021/05/18/数据库证明/</id>
    <published>2021-05-18T13:15:35.239Z</published>
    <updated>2021-05-18T13:21:40.651Z</updated>
    
    <content type="html"><![CDATA[<p>数据库的几个证明题</p><a id="more"></a><p>一：证明R∈ 3NF，则R 也∈ 2NF。</p><p>证明：采用反证法。设R不是2NF，则有非主属性（Z）对码（X）存在部分函数依赖，即存在Y包含于X，X→Y，Y→Z，也就是Z传递依赖于X。这与3NF范式的定义相矛盾，所以如果R∈ 3NF，则R 也∈ 2NF。</p><p>二：证明R ∈ BCNF ，则 R 也∈ 3NF。</p><p>证明：采用反证法。设 R 不是 3NF ，则必然存在这样的码 X ，属性组 Y 和非主属性 Z （ Z 不∈ Y ），使得 X→Y （ Y 不 -&gt;X ）， Y→Z ，这样 Y→Z 函数依赖的决定因素 Y 不包含码，这与 BCNF 范式的定义相矛盾，所以如果 R ∈ BCNF ，则 R 也是 3NF 。</p><p>三：证明R ∈ BCNF，则 R 也∈ 2NF。</p><p>证明：采用反证法。假设R不属于2NF，存在X对Y的部分函数依赖，存在X的真子集X’有X’ -&gt; Y，又因为X’是码X的真子集，X’不能包含码，则X’-&gt;Y与R属于BCNF矛盾。</p><p>四：试由Armostrong公理系统推导出下面三条规则：</p><p>（1）合并规则：若X→Z，X→Y，有X→YZ</p><p>（2）伪传递规则：由X→Y，WY→Z，有XW→Z</p><p>（3）分解规则：X→Y，Z包含于Y，有X→Z</p><p>证明：</p><p>（1）已知X→Z，由增广律知XY→ZY，又因为X→Y，可得XX→XY→YZ，最后根据传递律得X→YZ。（因为XX等于X）</p><p>（2）已知X→Y，由增广律得XW→WY，又因为WY→Z，所以XW→WY→Z，通过传递律可知XW→Z。</p><p>（3）已知Z包含于Y，根据自反律得Y→Z，又因为X→Y，所以由传递律可知得X→Z。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据库的几个证明题&lt;/p&gt;
    
    </summary>
    
    
      <category term="数据库" scheme="http://Bithub00.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Personalized PageRank to a Target Node, Revisited[KDD&#39;20]</title>
    <link href="http://Bithub00.com/2021/04/24/RBS%5BKDD20%5D/"/>
    <id>http://Bithub00.com/2021/04/24/RBS[KDD20]/</id>
    <published>2021-04-24T02:42:01.068Z</published>
    <updated>2021-07-04T13:00:02.220Z</updated>
    
    <content type="html"><![CDATA[<p>KDD20一篇近似计算单目标PPR相似度的论文</p><a id="more"></a><p>这里我直接把组会分享的PPT和讲稿放上来了。</p><h3 id="讲稿"><a href="#讲稿" class="headerlink" title="讲稿"></a>讲稿</h3><p>今天我要讲的是KDD20年的一篇论文，解决的是针对目标顶点的个性化PageRank查询。个性化PageRank简称PPR，它来自于Google创始人于1998年提出的PageRank。PageRank用于度量web网络中各网页的重要性，它的核心思想有两点：被很多网页所链接的网页重要性较高；被重要的网页所链接的网页重要性较高。如果将web网络转化为图结构G(V,E)，网页看作顶点，网页间的链接看作边，则PageRank的计算方式为下面的式子，$\pi$是PPR向量有n维，每一维对应一个顶点的PageRank分数，是一个迭代的计算过程。</p><p>它可以用于衡量各顶点的全局重要性，举个例子说明这个式子的含义，有A、B、C、D四个网页，假设一个上网的人在网页A，那他会以1/3的概率跳到B、C和D，访问一个网页的概率由链接到它的所有网页的概率来决定，例如A由B、C两个网页链接，就有第一个式子。各个网页间的转移可以用一个概率转移矩阵表示，初始时上网的人在每个网页停留的概率是相等的，右乘上转移矩阵后就得到了下一时刻对每个网页的访问概率。然后不断迭代直到收敛。实际上，如果存在一个网页只链接到自己，例如图里的C，那就会像一个陷阱一样，导致概率分布值全部转移到网页C上来，所以PageRank另一部分就是以一定的概率跳转到一个随机的网页，来避免这种问题。</p><p>而PPR是PageRank的一种特殊形式，它用于衡量图上顶点关于某一顶点的相对重要性，两者之间的关系为下面的式子。一个是相对重要性一个是全局重要性。这篇论文重点关注是单目标PPR的计算问题，即给定图上某一顶点t作为目标顶点，计算图上所有顶点关于t的PPR值，它希望找到使得目标顶点t重要性较高的一系列顶点。有别于我们传统上理解的单源PPR的计算问题，后者是希望找到相对源顶点较为重要的一系列顶点。</p><p>论文做的是一个近似求解，满足一定的误差要求来提升计算的效率。近似的方法是从PPR的另一个定义方式出发，即从源顶点出发的随机游走停止在目标顶点的概率。进一步地分解，就是以0步、1步到无穷步停止的概率进行求和，近似的做法就是进行一个截断，上限不需要是无穷，截断后满足误差小于给定极限即可。单目标PPR的计算问题相关研究较少，目前时间复杂度上最优的方法是Backward Search，为$O(\frac{\overline{d}}{\delta})$，</p><p>这篇论文的贡献就是在它的基础上引入随机性，使得复杂度降为$O(\frac{1}{\delta})$。这里先介绍Backward Search的做法，然后指出论文具体在哪几个步骤做了改动。Backward Search的做法是，给定一个目标顶点t，算法对图上的每个顶点u都维护两个变量residue和reserve，我这里简称为r值和$\pi$值，每次选取当前r值最大的顶点v，更新自己的$\pi$值，再将r值以一定比例push给所有的入度邻居并置零。最后每个顶点的$\pi$值就作为PPR值的近似计算结果。因为在push操作时需要遍历所有的入度邻居，所以复杂度上会带有一个$\overline{d}$，表示图中所有顶点的平均出度。</p><p>所以论文在push这一步做了改动，提出了自己的方法RBS。它不会push给所有的入度邻居，而是只push增长值超过阈值的部分。之所以这么做，是因为Backward Search里的增长值与入度邻居u的出度成反比，对于出度较大的这部分入邻居，这次push操作对它的\pi值改变不大，即使进行了本次push，它\pi值的变化幅度也小于误差要求，所以放弃对它的push操作以节省时间。</p><p>在RBS算法里，push操作有三种情况，当出度满足要求时才确定进行push操作，如果不满足条件，产生一个0、1之间的随机数，如果出度满足小于放宽后的要求，则push一个固定值，否则不进行本次push。这样，对于每个需要push操作的入度邻居，只确定地更新了一部分并且采样了一部分进行更新以保证结果的无偏。</p><p>在实际实现时不能遍历每个入度邻居u来判断它是否满足要求，这样同样会带来$\overline{d}$的复杂度，因为push操作的条件是逐渐递减的，只需要预先对所有的入度邻居按照出度进行排序，逐个扫描到临界条件后就可以放弃查看剩下的所有邻居，因为都不会满足条件。最后是实验部分，选用的几个图数据集描述如下，有无向图也有有向图，有小图也有大图，评测指标一个是最大计算误差，另外两个是推荐常用指标。</p><p>实验结果上，因为是基于Backward Search提出的，baseline只选了这一个。图中的横轴都是查询时间，纵轴分别是各个评测指标，结果上来说就是花费同等的时间，新的方法可以达到更好的结果，达到相同的结果新的方法只需要更少的时间。</p><p>论文所研究的单目标PPR计算虽然相对冷门，但实际应用可以结合许多问题，第一个相当于是该问题下的一个特例，对顶点的重要性有更高的要求，其次在图神经网络上也有利用PPR矩阵进行改进的工作，例如ICLR19年的这个方法。</p><p>最后想重点说一下的是与SimRank相似度的关系，因为前一篇讨论班论文我讲的就是ICDE20年一篇如何高效计算SimRank相似度的论文，里面提到SimRank相似度可以看成两条分别从源顶点和目标顶点出发的随机游走，以相同的步数相遇于同一个顶点的概率，因为定义上有相似之处，可以结合PPR来计算顶点u或v到这一系列顶点w的概率。</p><p>总结来说，这篇论文的贡献是在BackWard Search的基础上引进随机化来降低时间复杂度并且保证了理论上的近似精度，并且给出了数学证明说明做法的有效性。</p><h3 id="PPT"><a href="#PPT" class="headerlink" title="PPT"></a>PPT</h3><p><a href="https://imgtu.com/i/cjNkPH" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNkPH.png" alt="cjNkPH.png"></a><br><a href="https://imgtu.com/i/cjNERA" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNERA.png" alt="cjNERA.png"></a><br><a href="https://imgtu.com/i/cjNiIe" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNiIe.png" alt="cjNiIe.png"></a><br><a href="https://imgtu.com/i/cjNVxI" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNVxI.png" alt="cjNVxI.png"></a><br><a href="https://imgtu.com/i/cjNAGd" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNAGd.png" alt="cjNAGd.png"></a><br><a href="https://imgtu.com/i/cjNeMt" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNeMt.png" alt="cjNeMt.png"></a><br><a href="https://imgtu.com/i/cjNmsP" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNmsP.png" alt="cjNmsP.png"></a><br><a href="https://imgtu.com/i/cjNnqf" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNnqf.png" alt="cjNnqf.png"></a><br><a href="https://imgtu.com/i/cjNKZ8" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNKZ8.png" alt="cjNKZ8.png"></a><br><a href="https://imgtu.com/i/cjNMdS" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNMdS.png" alt="cjNMdS.png"></a><br><a href="https://imgtu.com/i/cjNQIg" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNQIg.png" alt="cjNQIg.png"></a><br><a href="https://imgtu.com/i/cjN3Gj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjN3Gj.png" alt="cjN3Gj.png"></a><br><a href="https://imgtu.com/i/cjN1iQ" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjN1iQ.png" alt="cjN1iQ.png"></a><br><a href="https://imgtu.com/i/cjNGzn" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNGzn.png" alt="cjNGzn.png"></a><br><a href="https://imgtu.com/i/cjN8Rs" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjN8Rs.png" alt="cjN8Rs.png"></a><br><a href="https://imgtu.com/i/cjNNLV" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNNLV.png" alt="cjNNLV.png"></a><br><a href="https://imgtu.com/i/cjNYMq" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNYMq.png" alt="cjNYMq.png"></a><br><a href="https://imgtu.com/i/cjNts0" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNts0.png" alt="cjNts0.png"></a><br><a href="https://imgtu.com/i/cjNaZT" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNaZT.png" alt="cjNaZT.png"></a><br><a href="https://imgtu.com/i/cjNwoF" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNwoF.png" alt="cjNwoF.png"></a><br><a href="https://imgtu.com/i/cjNddU" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNddU.png" alt="cjNddU.png"></a><br><a href="https://imgtu.com/i/cjNszR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNszR.png" alt="cjNszR.png"></a><br><a href="https://imgtu.com/i/cjNBi4" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNBi4.png" alt="cjNBi4.png"></a><br><a href="https://imgtu.com/i/cjNDJJ" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNDJJ.png" alt="cjNDJJ.png"></a><br><a href="https://imgtu.com/i/cjNrW9" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/24/cjNrW9.png" alt="cjNrW9.png"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;KDD20一篇近似计算单目标PPR相似度的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="近似计算" scheme="http://Bithub00.com/tags/%E8%BF%91%E4%BC%BC%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>CrashSim An Efficient Algorithm for Computing SimRank over Static and Temporal Graphs[ICDE&#39;20]</title>
    <link href="http://Bithub00.com/2021/04/10/CrashSim%5BICDE20%5D/"/>
    <id>http://Bithub00.com/2021/04/10/CrashSim[ICDE20]/</id>
    <published>2021-04-10T09:05:01.001Z</published>
    <updated>2021-04-10T09:20:01.407Z</updated>
    
    <content type="html"><![CDATA[<p>ICDE20一篇高效计算SimRank相似度的论文</p><a id="more"></a><pre><code>这里我直接把组会分享的PPT和讲稿放上来了。</code></pre><h3 id="讲稿"><a href="#讲稿" class="headerlink" title="讲稿"></a>讲稿</h3><p>​    大家好，今天我要讲的是ICDE2020年的一篇论文，“一种在静态和时序图上高效计算SimRank相似度的算法”。第一眼看到这个题目会想，首先什么是SimRank相似度，然后为什么它的计算是低效的，以及论文怎么进行高效计算。按照这个逻辑，首先介绍一下SimRank相似度，它是应用于图上的一种相似度计算方法，基本思想是，关联到相同顶点的两个顶点，相互之间具有相似性。以下面这个图片为例，两位教授相似度高因为他们来自同一所大学，而两位学生的相似度要相对低一些，在于他们并不直接来自于同一位教授。SimRank相似度原始的计算方式如下，它是一个迭代的过程。要计算顶点u和v的相似度，我们需要找到它们各自邻域中所有的顶点x和y，进行求和。前面的系数是为了避免热门顶点的影响而做的惩罚。因为是迭代计算，当图中顶点数量较多的时候计算就会变得低效。而VLDB17年的一篇论文证明了可以通过随机漫步近似计算SimRank相似度，这就为高效计算带来了新的思路。从随机漫步的角度来看，顶点u和v之间的SimRank相似度，可以看作从这两个顶点出发的随机漫步序列相交的概率。这个随机漫步的定义如下，以\sqrt{c}的概率漫步到下一个邻居，1-\sqrt{c}的概率终止于当前顶点。随机漫步可以看成是一种采样的方法，在图上的应用比较广泛，包括用来生成顶点的embedding如node2vec，或者在一个大图中构建子图捕获局部信息如GraphSAGE。既然是一个采样的方法，那么采样多少来保证获取到必要的信息就是一个关键的参数。同样地，在通过随机漫步近似计算SimRank相似度时，单次漫步的长度以及漫步的次数怎么选取，才能保证近似值与实际值之间的误差小于某个界限。论文的一个主要贡献就是给出了这两个参数的选取以及证明了它们的有效性。我对证明过程的每一步作了注解放在了ppt里，这里就不详细展开。主要是通过几何分布以及正态分布的3σ原则来证明。回到刚刚的式子，有了两个序列W(u)和W(v)，这时只剩下最后一步也就是怎么计算这里的概率。最直观的办法是通过蒙特卡洛模拟，给定一对查询顶点u和v，我们总共做n次随机漫步，用其中相遇的次数所占的比例作为概率的一个近似，然而这需要进行大量的尝试，直观但效率低。论文的改进做法是，与其去判断从u和v出发的随机漫步是否会相交，不如直接判断顶点v能否到达顶点u随机漫步的范围内。因为在静态图上固定了随机漫步的长度后，一个顶点能够漫步到的范围就是固定的，因此只需要在迭代之前计算一遍即可，不需要迭代时一次次地去计算。以左边的图为例，取漫步的长度$l_{max}=4$，在这个图中顶点A能够漫步到的范围就能用右边这颗树表示。因为随机漫步就是由概率决定是停止还是继续，所以只要将右边这棵树上的边用概率表示就可以进行近似计算。论文中给出的一个表示是下面这个式子，含义是这棵树每层之间边的一个关系。在实际编程实现时用的是一个二维矩阵$U\in \mathbb{R}^{l_{max}\times |\Omega|}$来表示这棵树，为什么这样的一个关系能够保证近似计算的有效性的证明我也放在了这里，同样不展开来讲了。单看表达式比较抽象，我就继续以刚才的例子说明这个计算过程，取参数$c=0.25$，初始时因为只能停留在起点A处，所以设这个概率值为1，$U(0,A)$表示以0步漫步到顶点A的概率。而一步能够漫步到的范围包括B、C两个顶点，以B为例，它的入度邻居数目为2，对应着上面的公式计算出它的概率值。所以漫步到顶点B的概率由先到顶点A的概率决定，这也符合随机漫步的定义。接下来以此类推。对于顶点A能够到达的顶点，它们在矩阵里对应位置的值都不为0。得到这么一个U矩阵后，迭代时不断地产生顶点v的随机漫步序列W(v)，根据这里的式子来近似计算SimRank相似度，直观上的理解是W(v)这个序列多大程度上走进了顶点u的这个漫步范围。还是刚才的例子，假设我们想得到顶点A和C之间的SimRank相似度，而某次迭代时顶点C产生的一条序列为$W(C)=(C,D,B,A)$，我们查阅刚刚得到的U矩阵中对应元素的值，进行累加，多次迭代后就得到了近似计算结果。回顾一下整个算法的流程，输入是单个顶点u和一系列顶点v，我们希望知道u和这些v之间的SimRank相似度大小。首先设定两个参数的取值，接下来在迭代前先预先计算顶点u的U矩阵，矩阵中的元素表示它漫步到某个顶点的概率。迭代过程中从顶点v产生一条随机漫步序列，通过U矩阵计算这条序列与u相遇的概率，多次取平均作为结果。到这里论文就完成了静态图部分的工作，接下来就是怎么将提出的方法继续用在时序图上。一个时序图通常由一系列快照图组成，每个快照图捕获了某个时间段内顶点之间的状态，图中就是一个包含三个快照图的时序图。联系现实可以拿微博举例子，假设我是顶点H，第一周关注了用户F，第二周取关了他，第三周用户G又新关注用户F。实际中因为用户的兴趣更新频率很快，所以时序图更能表达这种动态变化的兴趣。在时序图的情景下，最常见的两种SimRank查询分别为趋势查询和阈值查询。趋势查询的含义是，在给定的时间区间内，对于顶点u，我们希望找到一系列顶点v，它们与u的SimRank相似度在这个区间内是递增或递减的。而阈值查询是指在给定的时间区间内，它们与u的SimRank相似度大于某个阈值。因为时序图的每个快照图都可以看成静态图，最直观的想法就是把刚才的方法在每个快照图上算一遍，但这样只是照搬静态图的做法，没有用上时序图的特点，所以论文的后半部分针对时序图的特点提出了两个减少计算量的策略，分别是delta剪枝和差异剪枝，它们的思想也很直观，希望只对时序图中产生变化的顶点重新进行计算。回到刚才的例子图，会发现这三张快照图变的只是蓝框部分，红框部分一直维持不变。所以红框内的部分没必要每次都进行计算。具体到delta剪枝，一条新增或删除的边x-&gt;y影响的区域定义为下面两个部分，第一部分的意思是，如果顶点u能去的范围因为新增的边变大了，对应的这棵树也会改变。而第二部分的意思是，对于顶点y能到达的最远顶点$y_{lmax}$，反过来看顶点x刚好在它漫步范围之外，所以它在前后两个快照图里是不受影响的，涉及它的SimRank计算就可以省去。根据这个观察，delta剪枝的做法就是满足该前提的条件下，避免重计算未受影响区域的顶点。论证在下面主要从时间复杂度来说明，这里就省去了。而差异剪枝的想法要简单一些，因为近似计算依靠的就是随机漫步，如果前后两张快照图里漫步的范围没变，那计算结果也不会发生改变。所以差异剪枝的做法就是只要顶点u和v漫步范围不变，它们之间就不需要进行重计算。论证同样是通过复杂度说明。这两个策略具体放在流程里体现为图里的红框和蓝框，主要是判断是否达到对应的条件，然后删去不需要重计算的顶点来减少计算量。最后是实验部分，数据集和baseline的描述如下，结果主要是准确率和效率两方面，纵轴的ME表示近似值与真实值的最大误差，五个数据集上论文的方法都是又快又准，在时序图实验上也是一样。总结来说，论文的贡献是给出了一种高效计算SimRank相似度的方法并且证明了它的有效性，并且针对时序图的情景提出了两个优化策略。因为论文涉及比较多的证明和细节，看完可能不太明白这么计算的意义。图在许多领域应用广泛，而SimRank相似度既然是一种相似度，那它就可以应用在推荐系统、社交网络等一系列任务上，同时这些场景下往往有大量的用户，高效计算就有了实际的应用背景。不过这里也是我对论文有疑问的一个地方，因为实验用到的数据集都很小，最多的顶点也才三万多个，时序图也是以天为单位，而在现实生活中可能用户兴趣可能几个小时就发生改变了，例如微博热搜。而且即使在这么一个数据集上，论文的方法也要耗费75分钟的时间进行计算，感觉并不是很高效。</p><h3 id="PPT"><a href="#PPT" class="headerlink" title="PPT"></a>PPT</h3><p><a href="https://imgtu.com/i/cdSebj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSebj.png" alt="cdSebj.png"></a><br><a href="https://imgtu.com/i/cdSnVs" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSnVs.png" alt="cdSnVs.png"></a><br><a href="https://imgtu.com/i/cdSuan" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSuan.png" alt="cdSuan.png"></a><br><a href="https://imgtu.com/i/cdSVKg" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSVKg.png" alt="cdSVKg.png"></a><br><a href="https://imgtu.com/i/cdSZrQ" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSZrQ.png" alt="cdSZrQ.png"></a><br><a href="https://imgtu.com/i/cdSlGV" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSlGV.png" alt="cdSlGV.png"></a><br><a href="https://imgtu.com/i/cdSK5q" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSK5q.png" alt="cdSK5q.png"></a><br><a href="https://imgtu.com/i/cdSQP0" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSQP0.png" alt="cdSQP0.png"></a><br><a href="https://imgtu.com/i/cdSYqJ" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSYqJ.png" alt="cdSYqJ.png"></a><br><a href="https://imgtu.com/i/cdS12T" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdS12T.png" alt="cdS12T.png"></a><br><a href="https://imgtu.com/i/cdS3xU" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdS3xU.png" alt="cdS3xU.png"></a><br><a href="https://imgtu.com/i/cdSGMF" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSGMF.png" alt="cdSGMF.png"></a><br><a href="https://imgtu.com/i/cdSJr4" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSJr4.png" alt="cdSJr4.png"></a><br><a href="https://imgtu.com/i/cdSwPx" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSwPx.png" alt="cdSwPx.png"></a><br><a href="https://imgtu.com/i/cdSNZ9" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSNZ9.png" alt="cdSNZ9.png"></a><br><a href="https://imgtu.com/i/cdSaI1" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSaI1.png" alt="cdSaI1.png"></a><br><a href="https://imgtu.com/i/cdSUaR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSUaR.png" alt="cdSUaR.png"></a><br><a href="https://imgtu.com/i/cdS0G6" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdS0G6.png" alt="cdS0G6.png"></a><br><a href="https://imgtu.com/i/cdSBRK" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSBRK.png" alt="cdSBRK.png"></a><br><a href="https://imgtu.com/i/cdS6qH" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdS6qH.png" alt="cdS6qH.png"></a><br><a href="https://imgtu.com/i/cdS5z8" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdS5z8.png" alt="cdS5z8.png"></a><br><a href="https://imgtu.com/i/cdS7LQ" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdS7LQ.png" alt="cdS7LQ.png"></a><br><a href="https://imgtu.com/i/cdSsMD" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSsMD.png" alt="cdSsMD.png"></a><br><a href="https://imgtu.com/i/cdSgZd" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSgZd.png" alt="cdSgZd.png"></a><br><a href="https://imgtu.com/i/cdS2dA" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdS2dA.png" alt="cdS2dA.png"></a><br><a href="https://imgtu.com/i/cdSRII" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSRII.png" alt="cdSRII.png"></a><br><a href="https://imgtu.com/i/cdSTsg" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSTsg.png" alt="cdSTsg.png"></a><br><a href="https://imgtu.com/i/cdShJP" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdShJP.png" alt="cdShJP.png"></a><br><a href="https://imgtu.com/i/cdSfit" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSfit.png" alt="cdSfit.png"></a><br><a href="https://imgtu.com/i/cdSoQS" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSoQS.png" alt="cdSoQS.png"></a><br><a href="https://imgtu.com/i/cdS4Rf" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdS4Rf.png" alt="cdS4Rf.png"></a><br><a href="https://imgtu.com/i/cdSbZj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSbZj.png" alt="cdSbZj.png"></a><br><a href="https://imgtu.com/i/cdSqds" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSqds.png" alt="cdSqds.png"></a><br><a href="https://imgtu.com/i/cdSLon" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSLon.png" alt="cdSLon.png"></a><br><a href="https://imgtu.com/i/cdSjJ0" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSjJ0.png" alt="cdSjJ0.png"></a><br><a href="https://imgtu.com/i/cdSXiq" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSXiq.png" alt="cdSXiq.png"></a><br><a href="https://imgtu.com/i/cdSxzT" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdSxzT.png" alt="cdSxzT.png"></a><br><a href="https://imgtu.com/i/cdpSQU" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/10/cdpSQU.png" alt="cdpSQU.png"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICDE20一篇高效计算SimRank相似度的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="高效计算" scheme="http://Bithub00.com/tags/%E9%AB%98%E6%95%88%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>How Powerful are Graph Neural Networks?[ICLR&#39;19]</title>
    <link href="http://Bithub00.com/2021/01/31/GIN%5BICLR19%5D/"/>
    <id>http://Bithub00.com/2021/01/31/GIN[ICLR19]/</id>
    <published>2021-01-31T13:28:36.766Z</published>
    <updated>2021-02-09T04:36:31.688Z</updated>
    
    <content type="html"><![CDATA[<p>ICLR19一篇从图同构测试（Graph Isomorphism Test）角度说明GNN性能表现的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>GNN性能表现好的原因是什么？</p><h4 id="贡献："><a href="#贡献：" class="headerlink" title="贡献："></a>贡献：</h4><ol><li>证明了GNN的性能上限是Weisfeiler-Lehman (WL) test，最多只和它一样有效</li><li>给出了GNN在什么条件下能够和WL test一样有效</li><li>指明了主流GNN框架如GCN、GraphSage无法区分的图结构，以及它们能够区分的图结构的特点</li><li>提出了一个简单有效的框架GIN，能够与WL test一样有效</li></ol><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>首先是介绍现有GNN框架的做法及图同构测试的定义，还有WL test的做法。</p><h4 id="GNN与WL-test"><a href="#GNN与WL-test" class="headerlink" title="GNN与WL test"></a>GNN与WL test</h4><p>论文认为主流的GNN框架可以分为下面这三步：</p><ol><li><p><strong>Aggregate</strong>：聚合邻域内的信息</p><script type="math/tex; mode=display">a_v^{(k)}=\text{AGGREGATE}^{(k)}(\{h_u^{(k-1)}:u\in N(v) \})</script></li><li><p><strong>Combine</strong>：将聚合后的邻域信息与当前顶点信息结合</p><script type="math/tex; mode=display">h_v^{(k)}=\text{COMBINE}^{(k)}(h_v^{(k-1)},a_v^{(k)})</script></li><li><p><strong>Readout</strong>：通过图中的每个顶点的表示得到图的表示</p><script type="math/tex; mode=display">h_G=\text{READOUT}({h_v^{(K)}|v\in G})</script></li></ol><p>图同构测试就是判断两张图是否在拓扑结构上相同。而WL test的做法是迭代地进行以下步骤：</p><ul><li>聚合顶点及其邻域的标签信息</li><li>将聚合后的标签集合哈希成唯一的新标签</li></ul><p>如果经过若干次迭代后，两张图中的顶点的标签出现了不同则判断为不同构。基于WL test有一种核函数被提出以计算图之间的相似性。直观上来说，如下图所示，一个顶点在第$k$次迭代时的标签，实际表示了一颗以该顶点为根顶点高度为$k$的子树。</p><div align="center">  <a href="https://imgchr.com/i/yVPBNQ" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/31/yVPBNQ.png" alt="yVPBNQ.png" border="0" width="80%"></a></div><p>而GNN同样是通过迭代地更新图中每个顶点的特征向量来捕捉图的结构信息以其周围顶点的特征，这里的结构特征同样可以是上图的根子树rooted subtree。如果给每个顶点的特征向量一个唯一的标签例如{a,b,c,…}，那一个顶点的邻域中所有顶点的特征向量可以构成一个Multiset，它的定义基本和C++中的Multiset一样，是一个Set的同时里面的元素还可以重复例如{a,a,b,c}。论文中对Multiset给出的数学定义是：$X=(S,m)$，其中$S$由Multiset中的非重复元素构成，$m$表示$S$中的元素在$X$中的频数。</p><p>直观上来说，一个有效的GNN应该只有在两个顶点对应的根子树结构相同，且其中对应顶点的特征向量也相同时，才将这两个顶点在特征空间中映射成相同的表示。也就是永远不会将不同的两个Multiset映射成同一个特征表示（因为Multiset中的顶点也是根子树中的顶点，既然它们都是通过聚合邻域得到的）。这也就意味着GNN中使用的聚合函数必须是单射的，对值域内的每一个$y$，存在最多一个定义域内的$x$使得$f(x)=y$。有下面这么一个引理：</p><blockquote><p>设$G_1$和$G_2$是两个非同构图，如果一个图神经网络$A:G\rightarrow \mathbb{R}^d$将$G_1$和$G_2$映射成不同的embedding，那么WL test同样会判断这两个图为非同构。</p></blockquote><p>引理表明在图区分任务上，一个图神经网络的表现最多和WL test一样好。而一样好的条件是，这个图神经网络的邻居聚合函数和图表示函数都是单射的。这里的一个局限是，函数考虑的定义域和值域都是离散集合。</p><p>图神经网络相较于WL test的另一个好处是，WL test输入的顶点特征向量都是one-hot编码，这无法捕捉到子树之间的结构相似度：</p><blockquote><p>Note that node feature vectors in the WL test are essentially one-hot encodings and thus cannot capture the similarity between subtrees. In contrast, a GNN satisfying the criteria in Theorem 3 generalizes the WL test by learning to embed the subtrees to low-dimensional space. This enables GNNs to not only discriminate different structures, but also to learn to map similar graph structures to similar embeddings and capture dependencies between graph structures.</p></blockquote><h4 id="图同构网络GIN"><a href="#图同构网络GIN" class="headerlink" title="图同构网络GIN"></a>图同构网络GIN</h4><p>基于上面介绍的引理和结论，论文提出的GIN框架如下：</p><script type="math/tex; mode=display">h_v^{(k)}=\text{MLP}^{(k)}\Big((1+\epsilon^{(k)})·h_v^{(k-1)}+\sum_{u\in N(v)}h_u^{(k-1)} \Big)</script><p>对比一开始论文给出的GNN主流框架，可以看到是Aggregate函数选取了求和函数，Combine函数选取了MLP+(1+$\epsilon$)的形式。常见的Aggregate函数包括求和Sum、最大值Max和平均值Mean，论文花了一部分篇幅来说明求和相较于其他两个函数的好处：</p><p><div align="center">  <a href="https://imgchr.com/i/yGIv5D" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/02/05/yGIv5D.png" alt="yGIv5D.png" border="0" width="80%"></a>  <a href="https://imgchr.com/i/yGoirt" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/02/05/yGoirt.png" alt="yGoirt.png" border="0" width="80%"></a></div><br>上面两幅图分别说明这几种聚合函数的特点及何种场景下会导致误差。第一幅图中即使减少了顶点的数量但对于取平均和最大值函数来说得到的信息保持不变，第二幅图也是想说明同样的问题，例如取平均，两个一样的顶点与三个一样的顶点取平均出来结构都是一样的，但它们分别对应的局部结构是不相同的。</p><p>对于顶点分类及边预测这类下游任务，只要得到顶点的embedding即可。而对于图分类任务，还需要根据所有顶点的embedding来得到图的一个表示，也就是前面提到的主流GNN框架做法的第三步Readout函数。论文的做法类似于<a href="http://www.bithub00.com/2020/12/22/JK-Net[ICML18]/" target="_blank" rel="noopener">JK-Net</a>，将所有层的表示都考虑进来，不过没有具体说是怎么做的。</p><p>最后，论文还探讨了那些不满足上面定理的GNN框架如GCN、GraphSAGE等，这些框架都采用一层感知机如ReLU来将Multiset映射成特征表示，而不像论文的做法采用多层感知机，而ReLU存在将不同的Multiset表示成同一种特征表示的情况，即$\exist X_1 \not=X_2,\ s.t. \ \sum_{x\in X_1}\text{ReLU}(Wx)=\sum_{x\in X_2}\text{ReLU}(Wx)$。论文中直接给了一个简单的例子：$X_1=\{1,1,1,1,1\},X_2=\{2,3\}$，因为有$\sum_{x\in X_1}\text{ReLU}(Wx)=\text{ReLU}(W\sum_{x\in X_1}x)$。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>MUTAG、PTC、NCI1、PROTEINS、COLLAB、IMDB-BINARY、IMDB-MULTI、REDDIT-BINARY、REDDIT-MULTI5K</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICLR19一篇从图同构测试（Graph Isomorphism Test）角度说明GNN性能表现的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>GCC--Graph Contrastive Coding for Graph Neural Network Pre-Training[KDD&#39;20]</title>
    <link href="http://Bithub00.com/2021/01/28/GCC%5BKDD20%5D/"/>
    <id>http://Bithub00.com/2021/01/28/GCC[KDD20]/</id>
    <published>2021-01-28T13:30:43.112Z</published>
    <updated>2021-01-29T15:11:31.339Z</updated>
    
    <content type="html"><![CDATA[<p>KDD20一篇将对比学习（contrastive learning）应用于图表示学习任务从而进行迁移的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何将自监督学习的思想应用与图表示学习，通过预训练图神经网络从而仅需要微调就可以应用于新的数据集。</p><p>图表示学习目前受到了广泛关注，但目前绝大多数的图表示学习方法都是针对特定领域的图进行学习和建模，训练出的图神经网络难以迁移。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="对比学习"><a href="#对比学习" class="headerlink" title="对比学习"></a>对比学习</h4><p>对比学习是自监督学习思想的一种典型框架，一个典型的例子如下图所示：</p><div align="center">  <a href="https://imgchr.com/i/yiECBF" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/29/yiECBF.png" alt="yiECBF.png" border="0" width="80%"></a></div><p>对比学习的思想是：尽管我们已经见过钞票很多次，能够轻易地分辨出一张钞票，我们也很少能画出一张完美无缺的钞票。<strong>表示学习算法不需要关注到样本的每一个细节，只要学到的特征能够将用来区分其它样本即可</strong>。不需要模型能够生成一匹栩栩如生的马之后它才能去分辨一张图片里的动物是不是马，这就是对比学习和生成对抗网络的一个区别。</p><p>既然是表示学习，核心就是通过一个函数把样本$x$转换成特征表示$f(x)$，而对比学习作为一种表示学习方法，它的思想是满足下面这个式子：</p><script type="math/tex; mode=display">s(f(x),f(x^+))\gg s(f(x),f(x^-))</script><p>使得类似样本之间的相似度要远大于非类似样本之间的相似度，这样才能够进行区分。</p><h4 id="图表示学习"><a href="#图表示学习" class="headerlink" title="图表示学习"></a>图表示学习</h4><p>具体到论文的图表示学习任务中，论文的一个重要假设是，具有典型性的图结构在不同的网络之间是普遍存在而且可以迁移的（Representative graph structural patterns are universal and transferable across networks）。受对比学习在计算机视觉和自然语言处理领域的成功应用，论文想把对比学习（contrastive learning）的思想放在图表示学习中。通过预训练一个图神经网络，它能够很好地区分这些典型性的图结构，这样它的表现就不会仅仅局限于某个特定的数据集。</p><div align="center"><a href="https://imgchr.com/i/y9x4KI" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/28/y9x4KI.png" alt="y9x4KI.png" border="0" width="80%"></a></div><p>论文首先将现有工作对顶点相似度的衡量分为了三类：</p><ol><li><p>邻域相似度</p><p>核心思想：越近的两个顶点之间相似度越高，包括有Jaccard、RWR、SimRank以及LINE、DeepWalk、node2vec。</p></li><li><p>结构相似度</p><p>核心思想：有相似的局部结构的两个顶点之间相似度更高。不同于邻域相似度，结构相似度不需要两个顶点之间有路径相连。常用的局部结构包括vertex degree、structural diversity、structural hole、k-core、motif等。</p></li><li><p>属性相似度</p><p>当数据集中顶点有许多标签信息时，可以将标签作为顶点的特征来衡量它们之间的相似度。</p></li></ol><p>在对比学习中，给定一个查询表示$q$以及一个包含$K+1$个键表示${k_0,\dots,k_K}$的字典，我们希望找到一个能与$q$匹配的键$k_+$。所以，论文优化的损失函数来自于InfoNCE：</p><script type="math/tex; mode=display">L=-\log \frac{\exp(q^Tk_+\tau)}{\sum_{i=0}^K\exp(q^Tk_i/\tau)}</script><p>其中$f_q、f_k$是两个图神经网络，分别将样本$x^q$和$x^k$转换为低维表示$q$与$k$。</p><h4 id="正负样本获取"><a href="#正负样本获取" class="headerlink" title="正负样本获取"></a>正负样本获取</h4><p>因为查询和键可以是任意形式，具体到本论文里，定义每一个样本都是一个从特定顶点的$r$阶邻居网络中采样的子图，这里的子图定义和其它论文一致：$S_v=\{u:d(u,v)&lt;r \}$，距离顶点$v$最短路径距离小于$r$的顶点构成的集合。既然是最短路径，给定$r$那么这个集合也基本确定了，这种情况下得到的子图数量有限，在计算机视觉领域，当输入用于训练的图片数量有限时，往往会使用反转、旋转等方式对图片进行变换，以扩充训练图片的数量，这里论文也想采取类似的做法，对得到的子图$x$进行变换，来得到对比学习中的类似$x^+$与非类似样本$x^-$，具体做法如下：</p><ol><li><strong>带重启动的随机漫步</strong>。首先从子图的中心顶点$v$开始随机漫步，每一步时都有一定概率重新回到中心顶点，而漫步到任一邻居顶点的概率与当前顶点的出度有关。</li><li><strong>子图推演</strong>。随机漫步可以得到一系列顶点，它们构成的集合记为$\tilde{S_v}$，所形成的子图记作$\tilde{G_v}$，它就可以看作子图$S_v$的一个变换。</li><li><strong>匿名化</strong>。重新定义$\tilde{G_v}$中的顶点的标签，将$\{1,2,\dots,|\tilde{S_v} |\}$的顺序随机打乱作为重新定义后的标签。</li></ol><div align="center">    <a href="https://imgchr.com/i/yiFHv8" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/29/yiFHv8.png" alt="yiFHv8.png" border="0" width="70%"></a></div><p>论文对于每个子图都进行两次上述变换，而变换后的子图显然会与原子图相似，这样就有了一组相似的子图$(x^q,x^{k_+})$。要得到不相似的子图也很容易，不是同一个子图变换得到的子图就定义为不相似：$(x^q,x^k),k\not =k_+$。在上图的例子中，$x^q$和$x^{k_0}$是从红色的中心顶点采样得到的子图，我们认为它是一对正样本，而$x^{k_1}$和$x^{k_2}$作为从蓝色的中心顶点采样得到的子图，则被作为负样本。在变换时之所以要做最后一步，是为了防止图神经网络在判断两个子图是否相似时，仅仅是通过判断对应顶点的标签是不是一样，这样显然没有学到任何有用的结构信息。这里有一个小结论：</p><blockquote><p>绝大多数图神经网络对于输入图中顶点的顺序的随机扰动有稳定性</p></blockquote><p>现在有了正样本和负样本，下一步就是训练一个图神经网络对它们加以区分了，论文选取的是GIN。这就是自监督学习的思想，对比学习就是这种思想的一种典型框架。因为现有的图神经网络框架都需要额外的顶点特征作为输入，论文提出了一种位置embedding来作为其中特征：$I-D^{-1/2}AD^{-1/2}=U\Lambda U^T$，矩阵$U$中排序靠前的特征向量作为embedding。其它特征还包括顶点度的one-hot编码和中心顶点的指示向量。</p><h4 id="模型学习"><a href="#模型学习" class="headerlink" title="模型学习"></a>模型学习</h4><p>在模型学习时采用了何凯明组的MoCo框架的思想：</p><div align="center">  <a href="https://imgchr.com/i/yimVaD" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/29/yimVaD.png" alt="yimVaD.png" border="0" width="80%"></a></div><p>在对比学习中，我们需要维护一个大小为$K$的字典和编码器，要计算上面定义的损失函数，理想的情况是把所有负样本加入字典中进行计算，这会导致$K$很大字典难以维护。在MoCo的方法中，为了增大字典大小$K$，需要维护一个负样本的队列，队列中包含此前训练过的batch的样本作为负样本。在更新参数时，只有$q$的编码器图神经网络$f_q$中的参数通过反向传播进行更新，而$k$的编码器$f_k$中的值通过一种动量法进行更新：$\theta_k\leftarrow m\theta_k+(1-m)\theta_q$。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Academia、DBLP(SNAP)、DBLP(NetRep)、IMDB、Facebook、LiveJournal</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;KDD20一篇将对比学习（contrastive learning）应用于图表示学习任务从而进行迁移的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Link Prediction Based on Graph Neural Networks[NIPS&#39;18]</title>
    <link href="http://Bithub00.com/2021/01/26/SEAL%5BNIPS18%5D/"/>
    <id>http://Bithub00.com/2021/01/26/SEAL[NIPS18]/</id>
    <published>2021-01-26T12:34:08.608Z</published>
    <updated>2021-02-01T13:44:37.333Z</updated>
    
    <content type="html"><![CDATA[<p>NIPS18一篇使用图神经网络来做图的边预测任务的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何能自动而非人工定义的方式来学习图中的结构信息，从而进行边预测。</p><p>边预测任务就是预测图中的两个顶点是否有可能有边相连。一种常用的方法为启发式方法(heuristic)，它根据定义的顶点相似度来判断这条边存在的概率有多大。几种定义相似度的方法可以根据需要使用的邻居顶点的跳数来分类，例如common neighbors与preferential attachment是一阶的，因为它们只需要一跳邻居的信息，而Adamic-Adar和resource allocation为二阶，Katz、rooted PageRank与SimRank是更高阶的相似度。</p><p>这种启发式方法的缺点在于，边存在的概率很大程度依赖于定义的顶点相似度。例如选取common neighbors这个相似度，在社交网络可能是成立的，因为如果两个人有很多共同的朋友，他们两个确实更有可能认识，但是在蛋白质交互网络截然相反，有越多相同邻居顶点的蛋白质反而越不可能建立联系。所以，与其预先定义一种相似度，不如根据网络的特点自动的学习出来。</p><p>另一个挑战是，高阶的相似度相较于低阶相似度往往能带来更好的表现，但是随着阶数越高，每个顶点所形成的子图会越来越逼近完整的图，这样会带来过高的时间复杂度与空间复杂度。本文的另一个贡献就在于，定义了一种逼近的方式，不需要$h$阶的子图也能近似的获取$h$阶子图中包含的信息，之间的误差有理论上限。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>同ICLR20的论文<a href="http://www.bithub00.com/2021/01/14/ICMC[ICLR20]/" target="_blank" rel="noopener">ICMC</a>一样（毕竟是同一个作者），论文对子图的定义方式为，给定一对顶点$(x,y)$，它的子图为顶点$x$与$y$不高于$h$阶的邻域的一个并集，数学描述如下，也就是与顶点$x$或$y$的距离小于等于$h$所构成的点的集合：</p><blockquote><p>给定一个图$G=(V,E)$，以及图上两个顶点$x、y$，它的$h$阶围绕子图(enclosing subgraph)$G^h_{x,y}$为图$G$的一个子图，满足$\{i|d(i,x)\le h\ or\ d(i,y)\le h\}$.</p></blockquote><p>接下来是定义一个$\gamma$-decaying heuristic函数，它用来逼近$h$阶子图的信息而不需要实际计算$h$阶子图：</p><script type="math/tex; mode=display">H(x,y)=\eta\sum_{l=1}^{\infin}\gamma^lf(x,y,l)</script><p>其中$\gamma$是一个位于$(0,1)$的衰减因子，$\eta$是一个正的常数或一个上界为常数的函数。因为这里的求和从1到$\infin$，接下来的定理说明可以用有限项去逼近$H(x,y)$，误差随着$h$的增加而指数下降：</p><blockquote><p>定理一：</p><p>如果函数$f(x,y,l)$满足：</p><ol><li>$f(x,y,l)\le \lambda^l$，其中$\lambda &lt;\frac{1}{\gamma}$</li><li>对于$l=1,2,\dots,g(h)$，$f(x,y,l)$能够从$h$阶子图$G^h_{x,y}$中计算得到，其中$g(h)=ah+b$，$a,b\in \N,\ a&gt;0$</li></ol></blockquote><p>证明的方法很容易理解：</p><blockquote><p>逼近项为：</p><script type="math/tex; mode=display">\tilde{H}(x,y)=\eta\sum_{l=1}^{g(h)}\gamma^lf(x,y,l)</script><p>计算差值可以得到：</p><script type="math/tex; mode=display">\begin{aligned}|H(x,y)-\tilde{H}(x,y)|&=\eta\sum_{l=g(h)+1}^{\infin}\gamma^lf(x,y,l)\\&\le \eta\sum_{l=ah+b+1}^{\infin}\gamma^l\lambda^l\\&=\eta\frac{(\gamma \lambda)^{ah+b+1}}{1-\gamma \lambda}\end{aligned}</script></blockquote><p>第一个不等式是根据定理一的第一个条件，最后一个等号是根据等比数列的求和公式，当项数$n\rightarrow \infin$且$q\in(0,1)$时，结果为$\frac{a_1}{1-q}$。</p><p>到这里可能还是不知道这个$H(x,y)$和图中$h$阶的信息有什么关系，下面就通过Katz、rooted PageRank和SimRank三个高阶相似度来具体说明怎么使用：</p><p>在说明之前，先介绍一个引理，接下来会用到，证明起来也很直观：</p><blockquote><p>顶点$x$与$y$之间任意一条长度$l$满足$l\le2h+1$的路径都被包含在子图$G^h_{x,y}$中</p></blockquote><p>证明：</p><blockquote><p>即证明给定一条长度为$l$的路径$w=<x,v_1,\dots,v_{l-1},y>$中的每一个顶点都在子图中。取其中任意一个顶点$v_i$，满足$d(v_i,x)\ge h$且$d(v_i,y)\ge h$，根据子图$G^h_{x,y}$的定义它不在其中。那么有：</x,v_1,\dots,v_{l-1},y></p><script type="math/tex; mode=display">2h+1\ge l=|<x,v_1,\dots,v_i>|+|<v_i,\dots,v_{l-1},y>|\ge d(v_i,x)+d(v_i,y)=2h+2</script><p>矛盾，不等号是因为$d(x,y)$就是表示两个顶点之间的最短路径，所以有$d(v_i,x)&lt;h$或$d(v_i,y)&lt;h$，则顶点$v_i$在子图$G^h_{x,y}$中。</p></blockquote><h4 id="Katz-index"><a href="#Katz-index" class="headerlink" title="Katz index"></a>Katz index</h4><p>给定一对顶点$(x,y)$，Katz index定义为：</p><script type="math/tex; mode=display">\text{Katz}_{x,y}=\sum_{l=1}^{\infin}\beta^l|\text{walks}^{<l>}(x,y)|=\sum_{l=1}^{\infin}\beta^l[A^l]_{x,y}</script><p>其中$\text{walk}^{<l>}(x,y)$是这两个顶点之间长度为$l$的路径构成的集合，$A^l$是邻接矩阵的$l$次幂。从表达式可以看到，长度越长的路径在计算时会被$\beta^l$衰减的越多$(0&lt;\beta&lt;1)$，短路径有更大的权重。</l></p><p>对比两式可以发现：</p><script type="math/tex; mode=display">\text{Katz}_{x,y}=\sum_{l=1}^{\infin}\beta^l|\text{walks}^{<l>}(x,y)|=\sum_{l=1}^{\infin}\beta^l[A^l]_{x,y}\\H(x,y)=\eta\sum_{l=1}^{\infin}\gamma^lf(x,y,l)</script><p>Katz index是论文中定义的$\gamma$-decaying heuristic函数的一种特殊形式，取$\eta=1,\gamma=\beta$，$f(x,y,l)=|\text{walks}^{<l>}(x,y)|=[A^l]_{x,y}$。根据引理，只要取长度小于2h+1的路径，其中的顶点就会全部被子图给包含，这也就满足了定理一的第2个“可计算”条件。对于第一个条件，可以通过数学归纳法说明Katz index的表达式同样满足：</l></p><blockquote><p>给定任意的顶点$i、j$，$[A^l]_{i,j}$的上限为$d^l$，其中$d$是网络中的最大顶点度</p></blockquote><p>数学归纳法证明：</p><blockquote><p>当$l=1$时，$A_{i,j}$退化成了顶点的度，那显然有$A_{i,j}\le d$成立。假设$k=l$时也成立$[A^l]_{i,j}\le d^l$，当$k=l+1$时：</p><script type="math/tex; mode=display">[A^{l+1}]_{i,j}=\sum_{k=1}^{|V|}[A^l]_{i,k}A_{k,j}\le d^l\sum_{k=1}^{|V|}A_{k,j}\le d^ld=d^{l+1}</script></blockquote><p>第一个等式就是矩阵乘法的定义，因为$[A^{l+1}]$的含义就是$l+1$个邻接矩阵$A$相乘。因此，对比定理一的第一个条件，我们只要取$\lambda=d$，$d$满足$d&lt;\frac{1}{\beta}$就能够成立，这样一来两个条件都被满足了，这说明Katz index能够很好地从$h$阶子图中近似。</p><h4 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h4><p>rooted PageRank来源于这篇论文<a href="https://dl.acm.org/doi/10.1145/511446.511513" target="_blank" rel="noopener">Topic-sensitive PageRank</a>，它通过迭代计算PageRank向量$\pi_x$来得到某一点相对于其它顶点的相似度。具体来说，它计算一个从顶点$x$开始的随机漫步的平稳分布，这个随机漫步以概率$\alpha$移动到任一邻居上或以概率$1-\alpha$回到顶点$x$。这个平稳分布满足：</p><script type="math/tex; mode=display">\pi_x=\alpha P\pi_x+(1-\alpha)e_x</script><p>其中$[\pi_x]_i$表示在这个平稳分布下漫步到顶点$i$的概率，$P$为转移矩阵，其中$P_{i,j}=\frac{1}{|\Gamma(v_j)|}$，这里的$\Gamma(v_j)$表示顶点$v_j$的一跳邻居构成的集合。如果一个顶点与五个顶点相连，那它转移到其中任意一个顶点的概率就是$\frac{1}{5}$。</p><p>rooted PageRank应用于边预测任务时，用来得到一对顶点$(x,y)$的分数，以$[\pi_x]_y$或$[\pi_x]_y+[\pi_y]_x$（对称）表示，分数越高越有可能有边相连。</p><p>接下来就要说明rooted PageRank如何能够同样以论文中提出的$\gamma$-decaying heuristic函数进行表示。根据<a href="http://infolab.stanford.edu/~glenj/spws.pdf" target="_blank" rel="noopener">inverse P-distance理论</a>，$[\pi_x]_y$能够等价地改写为：</p><script type="math/tex; mode=display">[\pi_x]_y=(1-\alpha)\sum_{w:x\leadsto y}P[w]\alpha^{len(w)}</script><p> 这里的求和范围$w:x\leadsto y$表示所有从$x$开始结束于$y$的路径，$P[w]$定义为$\prod_{i=0}^{k-1}\frac{1}{|\Gamma(v_i)|}$，$k$是路径长度，$v_i$是路径中的顶点，通过这条路径来从$x$到$y$的概率就是漫步到路径中每一个顶点的概率的连乘。</p><p>接下来就是证明这个形式满足定理一的两个条件：</p><blockquote><p>首先进一步改写：</p><script type="math/tex; mode=display">[\pi_x]_y=(1-\alpha)\sum_{l=1}^{\infin}\sum_{W:x\leadsto y\\len(w)=l}P[w]\alpha^l\\H(x,y)=\eta\sum_{l=1}^{\infin}\gamma^lf(x,y,l)</script><p>对比：取$\gamma=\alpha,\eta=(1-\alpha),f(x,y,l)=\sum_{l=1}^{\infin}\sum_{W:x\leadsto y\\len(w)=l}P[w]$。因为这时候$f(x,y,l)$表示一个随机漫步恰好以$l$步从顶点$x$漫步到$y$的概率，有$\sum_{z\in V}f(x,z,l)=1$，则$f(x,y,l)\le1&lt;\frac{1}{\alpha}$，这样就满足了定理一，而根据引理，只要取长度小于等于2h+1的路径，路径中的点就会被全部包含在子图中，也就满足了第二个”可计算“条件。</p></blockquote><h4 id="SimRank"><a href="#SimRank" class="headerlink" title="SimRank"></a>SimRank</h4><p>SimRank的核心思想是，如果两个顶点的邻域相似，那它们也相似：</p><script type="math/tex; mode=display">s(x,y)=\gamma \frac{\sum_{a\in\Gamma(x)}\sum_{b\in \Gamma(y)}s(a,b)}{|\Gamma(x)|·|\Gamma(y)|}</script><p>它有一个<a href="https://dl.acm.org/doi/10.1145/775047.775126" target="_blank" rel="noopener">等价定义形式</a>：</p><script type="math/tex; mode=display">s(x,y)=\sum_{w:(x,y)\multimap (z,z)}P[w]\gamma^{len(w)}</script><p>其中$w:(x,y)\multimap (z,z)$表示从顶点$x$开始的随机漫步与从顶点$y$开始的随机漫步第一次相遇于顶点$z$。证明与rooted PageRank基本一致，可以见原论文。</p><p>总结来说，$\gamma$-decaying heuristic函数的思想是，对于远离目标顶点的结构信息通过指数衰减的方式给一个更小的权重，因为它们带来的信息十分有限。</p><h4 id="SEAL框架"><a href="#SEAL框架" class="headerlink" title="SEAL框架"></a>SEAL框架</h4><div align="center"><a href="https://imgchr.com/i/ypCC6A" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/28/ypCC6A.png" alt="ypCC6A.png" border="0" width="80%"></a></div><p>这一节就是根据上面的理论分析建立一个用于边预测任务的框架。一个图神经网络的典型输入形式是$(A,X)$，在本论文中，$A$自然地被定义为子图$G^h_{x,y}$的邻接矩阵，子图的获取即来自正样本（已知边）也来自负样本（未知边）。接下来的部分就是介绍论文怎么定义顶点的特征矩阵$X$，它包含三个部分：structural node labels、node embeddings和node attributes。</p><h5 id="Node-labeling"><a href="#Node-labeling" class="headerlink" title="Node labeling"></a>Node labeling</h5><p>跟作者的另一篇论文<a href="http://www.bithub00.com/2021/01/14/ICMC[ICLR20]/" target="_blank" rel="noopener">ICMC</a>一样，通过给顶点打标签的方式来区别顶点在子图中的不同角色，这么做的意义在另一篇博客说过了这里就不写了，具体打标签的方式为：</p><ul><li>起始顶点$x$与目标顶点$y$的标签都为”1“</li><li>如果两个顶点$i、j$距离起始顶点与目标顶点的距离都相同，那么它们的标签一样</li><li>$(d(i,x),d(i,y))=(a,b)\rightarrow label:a+b$</li></ul><p>将顶点的标签进行one-hot编码后作为结构特征。</p><h5 id="Node-embeddings-Node-attributes"><a href="#Node-embeddings-Node-attributes" class="headerlink" title="Node embeddings + Node attributes"></a>Node embeddings + Node attributes</h5><p>Node attributes一般数据集直接给定，而Node embeddings是通过一个GNN得到，具体做法是：给定正样本$E_p\in E$，负样本$E_n$，$E_p\and E_n=\empty$，在这么一个图$G’=(V,E\and E_n)$上生成embeddings，防止过拟合。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>USAir、NS、PB、Yeast、C.ele、Power、Router、E.coli</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;NIPS18一篇使用图神经网络来做图的边预测任务的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>C++常用操作</title>
    <link href="http://Bithub00.com/2021/01/17/c++%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
    <id>http://Bithub00.com/2021/01/17/c++常用操作/</id>
    <published>2021-01-17T13:48:25.048Z</published>
    <updated>2021-05-28T09:03:51.235Z</updated>
    
    <content type="html"><![CDATA[<p>记录备查</p><a id="more"></a><h2 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h2><ul><li>从字符串中删除子串</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">removeSubstrs</span><span class="params">(<span class="built_in">string</span>&amp; s, <span class="keyword">const</span> <span class="built_in">string</span>&amp; e)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = e.length();</span><br><span class="line">        <span class="keyword">for</span>(<span class="built_in">string</span>::size_type i = s.find(e); i != <span class="built_in">string</span>::npos; i = s.find(e))</span><br><span class="line">            s.erase(i, n);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ul><li>使用STL库实现小顶堆</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">priority_queue &lt;<span class="keyword">int</span>, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;, greater&lt;<span class="keyword">int</span>&gt; &gt; pq;</span><br></pre></td></tr></table></figure><ul><li>自定义排序</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Edge</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> x, y, len;</span><br><span class="line">    Edge(<span class="keyword">int</span> x, <span class="keyword">int</span> y, <span class="keyword">int</span> len) : x(x), y(y), len(len)&#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;Edge&gt; edges;</span><br><span class="line">sort(edges.begin(), edges.end(), [](Edge a, Edge b) -&gt; <span class="keyword">int</span> &#123;<span class="keyword">return</span> a.len &lt; b.len;&#125;);</span><br></pre></td></tr></table></figure><ul><li>初始化二维vector</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> row = <span class="number">3</span>, col = <span class="number">3</span>;</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; matrix(row, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(col, <span class="number">0</span>));</span><br></pre></td></tr></table></figure><ul><li>位运算</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//求二进制中1的个数</span></span><br><span class="line"><span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span>(n != <span class="number">0</span>)&#123;</span><br><span class="line">  n &amp;= n<span class="number">-1</span>;</span><br><span class="line">  count++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//除2</span></span><br><span class="line">x &gt;&gt;= <span class="number">1</span>;</span><br><span class="line"><span class="comment">//乘2</span></span><br><span class="line">x &lt;&lt;= <span class="number">1</span>;</span><br><span class="line"><span class="comment">//大写转小写</span></span><br><span class="line">ch |= <span class="string">' '</span>;</span><br><span class="line"><span class="comment">//小写转大写</span></span><br><span class="line">ch &amp;= <span class="string">'_'</span>;</span><br><span class="line"><span class="comment">//第i位是否为1</span></span><br><span class="line">(val &gt;&gt; i) &amp; <span class="number">1</span>;</span><br></pre></td></tr></table></figure><ul><li>分割字符串</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//完全分割</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">split</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; s, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; record, <span class="keyword">const</span> <span class="keyword">char</span> delim = <span class="string">'.'</span>)</span> </span>&#123;</span><br><span class="line">        record.clear();</span><br><span class="line">        <span class="function"><span class="built_in">istringstream</span> <span class="title">is</span><span class="params">(s)</span></span>;</span><br><span class="line">        <span class="built_in">string</span> temp;</span><br><span class="line">        <span class="keyword">while</span> (getline(is, temp, delim)) &#123;</span><br><span class="line">            record.push_back(move(temp));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//只分割一次</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">split</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; s, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; record, <span class="keyword">const</span> <span class="keyword">char</span> delim = <span class="string">'.'</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//s="www.bithub00.com"➡"bithub00.com"、"com"</span></span><br><span class="line">        record.clear();</span><br><span class="line">        <span class="keyword">int</span> index = s.find(<span class="string">'.'</span>);</span><br><span class="line">  <span class="keyword">while</span>(index &gt; <span class="number">0</span>)&#123;</span><br><span class="line">  <span class="built_in">string</span> t = s.substr(index+<span class="number">1</span>);</span><br><span class="line">          record.push_back(t);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ul><li>从句子中读取单词</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">string</span> A = <span class="string">"Data Mining"</span>;</span><br><span class="line"><span class="function"><span class="built_in">istringstream</span> <span class="title">in</span><span class="params">(A)</span></span>;</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; v;</span><br><span class="line"><span class="built_in">string</span> t;</span><br><span class="line"><span class="keyword">while</span>(in &gt;&gt; t)&#123;</span><br><span class="line">v.push_back(t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>求文件行数</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">length</span><span class="params">(<span class="keyword">char</span> *File)</span> </span>&#123;</span><br><span class="line"><span class="function">ifstream <span class="title">myfile</span><span class="params">(File)</span></span>;</span><br><span class="line"><span class="built_in">string</span> line;</span><br><span class="line"><span class="keyword">int</span> lineNum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (getline(myfile, line))</span><br><span class="line">lineNum++;</span><br><span class="line">myfile.clear();</span><br><span class="line">myfile.seekg(<span class="number">0</span>, ios::beg); <span class="comment">//回到文件第一行</span></span><br><span class="line"><span class="keyword">return</span> lineNum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>循环查找子串出现的所有位置</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> pos = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">string</span> str;</span><br><span class="line"><span class="built_in">string</span> substr;</span><br><span class="line"><span class="keyword">while</span>(pos != <span class="built_in">string</span>::npos) &#123;</span><br><span class="line">  pos = str.find(substr, pos);</span><br><span class="line">  pos++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>二分区间查找</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> left = <span class="number">0</span>, right = arr.size()<span class="number">-1</span>;</span><br><span class="line"><span class="keyword">while</span>(left &lt;= right) &#123;</span><br><span class="line">  <span class="keyword">int</span> mid = left + (right-left)/<span class="number">2</span>;</span><br><span class="line">  <span class="keyword">if</span>(arr[mid] &gt; value) right = mid<span class="number">-1</span>;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(arr[mid] &lt; value) left = mid+<span class="number">1</span>;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    right = mid;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//此时arr[right]就是arr中小于等于value的最大数</span></span><br><span class="line"><span class="keyword">return</span> arr[right];</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录备查&lt;/p&gt;
    
    </summary>
    
    
      <category term="C++" scheme="http://Bithub00.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Inductive Matrix Completion Based on Graph Neural Networks[ICLR&#39;20]</title>
    <link href="http://Bithub00.com/2021/01/14/ICMC%5BICLR20%5D/"/>
    <id>http://Bithub00.com/2021/01/14/ICMC[ICLR20]/</id>
    <published>2021-01-14T12:56:15.050Z</published>
    <updated>2021-01-15T02:46:33.394Z</updated>
    
    <content type="html"><![CDATA[<p>ICLR20一篇使用GNN来解决现有矩阵补全方法无法泛化问题的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何让矩阵补全方法中一个数据集得到的embedding，能够迁移到另一个数据集上，同时不依赖额外的信息。</p><p>与另一篇论文<a href="http://www.bithub00.com/2021/01/09/GCMC[KDD18]/" target="_blank" rel="noopener">GCMC</a>应用的问题相同，具体地，这篇论文做的是推荐系统方向下的矩阵补全问题，给定一个评分矩阵，如何根据已有的评分记录来预测用户对其他物品的评分。传统的做法是将输入的评分矩阵分解成用户与物品的embedding，通过embedding重构评分矩阵，填补其中的缺失值，从而做出预测，如下图所示：</p><div align="center"><a href="https://imgchr.com/i/sd6O1S" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/14/sd6O1S.png" alt="sd6O1S.png" border="0" width="80%"></a></div><p>很多现有方法研究的都是如何得到更好的embedding，但它们都是直推式(transductive)而非启发式(inductive)的，意味着没法迁移，例如MovieLens数据集上得到的embedding就不能直接用于Douban数据集上，需要重新训练一个新的embedding。即使对于同一个数据集而言，如果加入新的评分记录，往往需要整个embedding重新训练。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="Enclosing-Subgraph-Extraction"><a href="#Enclosing-Subgraph-Extraction" class="headerlink" title="Enclosing Subgraph Extraction"></a>Enclosing Subgraph Extraction</h4><p>论文的做法是为每一个评分记录提取一个子图，并且训练一个图神经网络来将得到的子图映射为预测评分。要想为评分记录提取子图，首先要将评分矩阵转换为图，转换的方法与另一篇论文<a href="http://www.bithub00.com/2021/01/09/GCMC[KDD18]/" target="_blank" rel="noopener">GCMC</a>相同，博客中有具体介绍，这里就不重复说明了。论文中对子图的定义方式为，给定一个评分记录$(u,v)$，表示用户$u$给物品$v$评过分，那么这个评分记录提取的子图由该用户$u$、物品$v$以及它们各自的$h$跳邻域内的顶点构成。为了具体说明是怎么从一个评分记录提取出子图的，我从论文作者的视频中截取了这部分内容，如下图所示：</p><p>假设第一张图中深绿色的方格是缺失值，这里先填入了模型的预测评分，倒退着来说明预测评分是怎么通过子图得到的。我们首先找到这个用户评过分的其它物品，对应于第五个物品的四分与第八个物品的两分，如第二张图所示。下一步是找到为这个物品评过分的其他用户，对应于第三个用户的五分与第四个用户的五分。</p><div align="center"><a href="https://imgchr.com/i/sdfNf1" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/14/sdfNf1.png" alt="sdfNf1.png" border="0"></a></div><p>通过图二和图三找到的关系，就可以提取出这个评分记录的子图了，如下图所示：</p><div align="center"><a href="https://imgchr.com/i/sd4urT" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/14/sd4urT.png" alt="sd4urT.png" border="0" width="90%"></a></div><p>可以看到，这个提取出的子图能提供许多有用的信息，例如用户平均评分、物品平均评分、物品累计评价次数以及基于路径的结构信息。论文希望通过这种结构信息来找到一些特征，从而做出预测，例如，如果用户$u_0$喜欢一个物品$v_0$，那么对于另一个与他品味相同的用户$u_1$，我们可能发现他也喜欢$v_0$。品味相同可以表示为两个用户都喜欢另一个物品$v_1$，这个特征可以表示为这么一条路径：$u_0\rightarrow_{like}v_1\rightarrow_{liked\ by}u_1\rightarrow_{like}v_0$，如果$u_0$与$v_0$之间存在多条这样的路径，那么我们就可以推测$u_0$喜欢$v_0$。类似这样的结构特征数不胜数。因此，与其人工来手动定义大量这样的启发式特征(heuristics)，不如直接将子图输入一个图神经网络，来自动学习更通用的、更有表达能力的特征。</p><h4 id="Node-Labeling"><a href="#Node-Labeling" class="headerlink" title="Node Labeling"></a>Node Labeling</h4><p>这一步给顶点打标签是为了让子图中的顶点有着不同的角色，例如区分哪个是需要预测的目标用户与目标物品，区分用户顶点与物品顶点。而论文中打标签的方式十分简单：</p><ul><li>目标用户与目标物品分别标记为0和1</li><li>对于$h$跳邻域内的顶点，如果是用户顶点标记为$2h$，物品顶点则标记为$2h+1$</li></ul><p>标记之后，我们就能知道哪个是需要预测的目标用户与目标物品、哪些是用户顶点，因为用户顶点的标签均为偶数，以及邻域内顶点距离目标顶点距离的远近。这些标签将转换为one-hot编码的形式作为图神经网络输入的初始特征$x_0$。</p><p>这一节的最后论文作者还说到了这种标记方式与<a href="http://www.bithub00.com/2021/01/09/GCMC[KDD18]/" target="_blank" rel="noopener">GCMC</a>做法的不同之处。GCMC中同样是将标签转换为one-hot编码的形式作为GNN的初始特征，不同的是它用顶点在整个bipartite graph中的全局id作为它的标签，这等价于将GNN第一层信息传递网络的参数，转换为与每个顶点的全局id相关联的embedding函数，可以理解为一个embedding查找表，输入一个全局id，输出它对应的embedding。这显然是直推式的，对于不在查找表中的id，就无法得到它的embedding。这种情况对应于在小数据集上训练网络得到embedding，然后换到大数据集上，因为大数据集的顶点数量肯定要多于小数据集，这就会使得顶点的全局id范围变大，超出了训练出来的这个embedding查找表的范围。</p><h4 id="Graph-Neural-Network"><a href="#Graph-Neural-Network" class="headerlink" title="Graph Neural Network"></a>Graph Neural Network</h4><p>这一步的目的就是训练一个GNN来将提取出的子图映射成预测评分。论文所使用的GNN分为两个部分：信息传递层与池化层。前者的作用是得到子图中各顶点的特征向量，后者是根据得到的特征向量形成子图的一个特征表示。</p><p>信息传递部分使用的是<a href="https://arxiv.org/pdf/1703.06103v4.pdf" target="_blank" rel="noopener">R-GCN</a>：</p><script type="math/tex; mode=display">x_i^{l+1}=W_0^lx_i^l+\sum_{r\in R}\sum_{j\in N_r(i)}\frac{1}{|N_r(i)|}W_r^lx_j^l</script><p>其中$x_i^l$表示第$i$个顶点在第$l$层的特征向量，$N_r(i)$表示评分水平$r$下顶点$i$的邻域，顶点$i$以不同的边权重$r$所连接的顶点$j$用不同的参数矩阵$W_r^l$来进行处理。通过堆叠$L$层网络可以得到顶点$i$的$L$个特征向量，通过拼接的方式得到它最终的特征表示$h_i$：</p><script type="math/tex; mode=display">h_i=\text{concat}(x_i^1,x_i^2,\dots,x_i^L)</script><p>池化部分只选取子图中目标用户与目标顶点的特征向量进行拼接，来得到该子图的特征表示，这么做的原因是这两个顶点携带了最多的信息。</p><script type="math/tex; mode=display">g=\text{concat}(h_u,h_v)</script><p>在得到子图的特征表示后，最后一步是通过一个MLP将它转换为一个预测评分$\hat{r}$：</p><script type="math/tex; mode=display">\hat{r}=w^T\sigma(Wg)</script><h4 id="Adjacent-Rating-Regularization"><a href="#Adjacent-Rating-Regularization" class="headerlink" title="Adjacent Rating Regularization"></a>Adjacent Rating Regularization</h4><p>论文对于信息传递部分使用的R-GCN还提出了一点改进，在原始的R-GCN中，不同的评分水平是独立看待的，彼此之间没有关联，例如对于1、4、5这三个评分，显然地4和5都表示了用户的喜爱而1表示了用户的厌恶，同时4和5的相似程度要大于4和1，但这种次序关系及大小关系在原始的R-GCN中都被丢掉了。因此本论文添加了一个约束来引入这部分丢失的信息，具体做法也很简单，就是使得相邻的评分水平使用的参数矩阵更加相似：</p><script type="math/tex; mode=display">L_{ARR}=\sum_{i=1,2,\dots,|R|-1}||W_{r_i+1}-W_{r_i}||_F^2</script><p>这里假设评分$r_1,r_2,\dots,r_{|R|}$表示了用户喜爱程度的递增，通过这个约束就保留了评分的次序信息，同时可以使得出现次数较少的评分水平可以从相邻的评分水平中迁移信息，来弥补数据不足带来的问题。</p><h4 id="Graph-level-GNN-vs-Node-level-GNN"><a href="#Graph-level-GNN-vs-Node-level-GNN" class="headerlink" title="Graph-level GNN vs Node-level GNN"></a>Graph-level GNN vs Node-level GNN</h4><p>这一节还是在于GCMC作比较。在GCMC中，采用的是顶点层面的图神经网络，它应用于图中的顶点来得到顶点的embedding，再通过embedding得到预测评分，如下右图所示。这么做的缺陷是它独立地学习两个顶点所关联的子树，而忽略了这两棵子树之间可能存在的联系。</p><p><div align="center"><a href="https://imgchr.com/i/swYFij" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/15/swYFij.png" alt="swYFij.png" border="0" width="50%"></a></div></p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Flixster、Douban、YahooMusic、ML-100K、ML-1M</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICLR20一篇使用GNN来解决现有矩阵补全方法无法泛化问题的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Variational Graph Auto-Encoders[NIPS&#39;16]</title>
    <link href="http://Bithub00.com/2021/01/09/VGAE%5BNIPS16%5D/"/>
    <id>http://Bithub00.com/2021/01/09/VGAE[NIPS16]/</id>
    <published>2021-01-09T13:54:14.216Z</published>
    <updated>2021-01-11T04:48:15.109Z</updated>
    
    <content type="html"><![CDATA[<p>NIPS16一篇将变分自编码器迁移到图结构数据上的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在图结构数据上如何使用变分自编码器</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>将已知的图进行编码（图卷积）得到图中顶点向量表示的一个分布，在分布中采样得到顶点的向量表示，然后进行解码重新构建图。</p><h4 id="变分自编码器"><a href="#变分自编码器" class="headerlink" title="变分自编码器"></a>变分自编码器</h4><p>因为这篇论文做的是一个迁移的工作，变分自编码器的背景对于理解这篇论文来说十分重要，首先进行介绍。</p><p>变分自编码器是自编码器的一种，一个自编码器由编码器和解码器构成，编码器将输入数据转换为低维向量表示，解码器通过得到的低维向量表示进行重构。</p><div align="center"><a href="https://imgchr.com/i/sl9ZxP" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/sl9ZxP.jpg" alt="sl9ZxP.jpg" border="0" width="80%"></a><a href="https://imgchr.com/i/sl9G2q" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/sl9G2q.jpg" alt="sl9G2q.jpg" border="0" width="65%"></a></div>这种结构的不足之处在于，只能产生与输入数据相似的样本，而无法产生新的样本，低维向量表示必须是有真实样本通过编码器得到的，随机产生的低维向量经过重构几乎不可能得到近似真实的样本。而变分自编码器可以解决这个问题。变分自编码器将输入数据编码为一个分布，而不是一个个低维向量表示，然后从这个分布中随机采样来得到低维向量表示。一般假设这个分布为正态分布，因此编码器的任务就是从输入数据中得到均值$\mu$与方差$\sigma^2$。<div align="center"><a href="https://imgchr.com/i/slCW60" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slCW60.jpg" alt="slCW60.jpg" border="0" width="80%"></a><a href="https://imgchr.com/i/slPZB8" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slPZB8.jpg" alt="slPZB8.jpg" border="0" width="80%"></a></div>然而，如果是将所有输入数据编码到同一个分布里，从这个分布中随机采样的样本$Z_i$无法与输入样本$X_i$一一对应，会影响模型的学习效果。所以，实际的变分自编码器结构如下图所示，为每一个输入样本学习一个正态分布：<div align="center"><a href="https://imgchr.com/i/slPgED" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slPgED.jpg" alt="slPgED.jpg" border="0" width="80%"></a></div>采样时常用"重参数"技巧(reparameterization trick)，从分布$N(\mu,\sigma^2)$中采样一个$Z$相当于从$N(0,1)$中采样一个$\epsilon$使得$Z=\mu+\sigma*\epsilon$。  #### 图变分自编码器介绍完传统的变分自编码器，接下来就是介绍这篇论文的工作，如何将变分自编码器的思想迁移到图上。针对图这个数据结构，输入的数据变为图的邻接矩阵$A$与特征矩阵$X$：  邻接矩阵$A$：<div align="center"><a href="https://imgchr.com/i/slFHhQ" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slFHhQ.jpg" alt="slFHhQ.jpg" border="0" width="60%"></a></div>特征矩阵$X$：<div align="center"><a href="https://imgchr.com/i/slFz7T" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slFz7T.jpg" alt="slFz7T.jpg" border="0" width="60%"></a></div><p>接下来的工作与变分自编码器相同，通过编码器（图卷积）学习图中顶点低维向量表示分布的均值$\mu$与方差$\sigma^2$，再通过解码器生成图。</p><div align="center"><a href="https://imgchr.com/i/slk1gA" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slk1gA.jpg" alt="slk1gA.jpg" border="0" width="80%"></a></div><p>编码器采用两层结构的图卷积网络，第一层产生一个低维的特征矩阵：</p><script type="math/tex; mode=display">\bar{X}=\text{GCN}(X,A)=\text{ReLU}(\tilde{A}XW_0)\\\tilde{A}=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}</script><p>第二层得到分布的均值$\mu$与方差$\sigma^2$：</p><script type="math/tex; mode=display">\mu=\text{GCN}_{\mu}(X,A)=\tilde{A}\bar{X}W_1\\\log\sigma^2=\text{GCN}_{\sigma}(X,A)=\tilde{A}\bar{X}W_1</script><p>将两层网络的表达式合并可以得到编码器的表达式：</p><script type="math/tex; mode=display">\text{GCN}(X,A)=\tilde{A}\text{ReLU}(\tilde{A}XW_0)W_1</script><p>同样地使用重参数技巧来得到低维向量表示$Z=\mu+\sigma*\epsilon$。</p><p>编码器重构出图的邻接矩阵，从而得到一个新的图。之所以使用点积的形式来得到邻接矩阵，原因在于我们希望学习到每个顶点的低维向量表示$z$的相似程度，来更好地重构邻接矩阵。而点积可以计算两个向量之间的cosine相似度，这种距离度量方式不受量纲的影响。因此，重构的邻接矩阵可以学习到各个顶点之间的相似程度。</p><script type="math/tex; mode=display">\hat{A}=\sigma(zz^T)</script><p>损失函数用于衡量生草样本与真是样本之间的差异，但如果只用距离度量作为损失函数，为了让编码器的效果最佳，模型会将方差的值学为0，这样从正态分布中采样出来的就是定值，有利于减小生成样本和真实样本之间的差异。但这样一来，就退化成了普通的自编码器，因此在构建损失函数时，往往还会加入各独立正态分布与标准正态分布的KL散度，来使得各个正态分布逼近标准正态分布：</p><script type="math/tex; mode=display">L=E_{q(Z|X,A)}[\log p(A|Z)]-\text{KL}[q(Z|X,A)||p(Z)],\quad where\quad p(Z)=N(0,1)</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Cora、Citeseer、Pubmed</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;NIPS16一篇将变分自编码器迁移到图结构数据上的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Graph Convolutional Matrix Completion[KDD&#39;18]</title>
    <link href="http://Bithub00.com/2021/01/09/GCMC%5BKDD18%5D/"/>
    <id>http://Bithub00.com/2021/01/09/GCMC[KDD18]/</id>
    <published>2021-01-09T13:17:15.588Z</published>
    <updated>2021-01-09T13:30:55.861Z</updated>
    
    <content type="html"><![CDATA[<p>KDD18一篇将图卷积网络用于矩阵补全问题的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何将图卷积网络应用于矩阵补全问题。</p><p>具体地，这篇论文做的是推荐系统方向下的矩阵补全问题，给定一个评分矩阵，如何根据已有的评分记录来预测用户对其他物品的评分。如果将评分矩阵转换为一张图，转换方法在下面有进行介绍，这时矩阵补全问题也可以看成图上的边预测问题。要预测用户对一个物品的评分，就是预测图上两个对应顶点之间相连的边的权重。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>论文通过一个编码器-解码器的架构来实现从已有评分到特征表示再到预测评分的过程。</p><div align="center"><a href="https://imgchr.com/i/sQUdAS" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQUdAS.png" alt="sQUdAS.png" border="0" width="70%"></a></div><h4 id="Bipartite-Graph-Construction"><a href="#Bipartite-Graph-Construction" class="headerlink" title="Bipartite Graph Construction"></a>Bipartite Graph Construction</h4><p>首先是将推荐任务里的评分数据转化为一张图，具体做法是将用户和物品都看作图中的顶点，交互记录看作边，分数作为边的权重，如图所示：</p><div align="center"><a href="https://imgchr.com/i/su9fr4" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/08/su9fr4.png" alt="su9fr4.png" border="0" width="60%"></a></div><h4 id="Graph-Convolutional-Encoder"><a href="#Graph-Convolutional-Encoder" class="headerlink" title="Graph Convolutional Encoder"></a>Graph Convolutional Encoder</h4><p>上一步所构建的图的输入形式为邻接矩阵$A\in \mathbb{R}^{n\times n}$与图中顶点的特征矩阵$X\in \mathbb{R}^{n\times d}$。编码器在这一步的作用就是得到用户与物品的特征表示$A,X^u,X^v\rightarrow U,V$。</p><p>具体编码时，论文将不同的评分水平分开考虑$r\in \{1,2,3,4,5\}$，我的理解是它们类似于处理图像数据时的多个channel。以一个评分水平$r$为例，说明编码得到特征表示的过程。假设用户$u_i$对电影$v_j$评分为$r$，而这部电影的特征向量为$x_j$，那么这部电影对这个用户特征表示的贡献可以表示为下面的式子(1)，相当于对特征向量进行了一个线性变换。</p><div align="center"><a href="https://imgchr.com/i/sQUHnx" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQUHnx.png" alt="sQUHnx.png" border="0" width="80%"></a></div>对当前评分水平下所有评过分的电影进行求和，再对所有评分水平求和拼接，经过一个非线性变换，就得到了用户$u_i$的特征表示$h_{u_i}$，物品的做法相同。<div align="center"><a href="https://imgchr.com/i/sQdv6A" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQdv6A.png" alt="sQdv6A.png" border="0" width="80%"></a></div><div align="center"><a href="https://imgchr.com/i/sQwmmq" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQwmmq.png" alt="sQwmmq.png" border="0" width="80%"></a></div><h4 id="Bilinear-Decoder"><a href="#Bilinear-Decoder" class="headerlink" title="Bilinear Decoder"></a>Bilinear Decoder</h4><p>在分别得到用户与物品的特征表示$U$与$V$后，解码器计算出用户对物品评分为$r$的概率，再对每个评分的概率进行求和，得到最终预测的评分。</p><script type="math/tex; mode=display">\begin{aligned}(P_r)_{ij}&=\frac{\exp(u_i^TQ_rv_j)}{\sum_{s\in R}\exp(u_i^TQ_sv_j)} \\\hat{M}&=\sum_{r\in R}rP_r\end{aligned}</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Flixster、Douban、YahooMusic、MovieLens</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;KDD18一篇将图卷积网络用于矩阵补全问题的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Graph Neural Networks for Social Recommendation[WWW&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/GraphRec%5BWWW19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/GraphRec[WWW19]/</id>
    <published>2020-12-22T03:22:36.248Z</published>
    <updated>2021-05-29T14:16:57.583Z</updated>
    
    <content type="html"><![CDATA[<p>WWW19将GNN应用于社会化推荐的一篇论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何将GNN应用于社会化推荐任务上。</p><p>面临的挑战有三点：</p><ol><li>在一个社会化推荐任务中，输入的数据包括社会关系图和用户-物品交互图，将两张图的信息都聚合才能得到用户更好的一个表示，而此前的GNN只是在同一张图上对邻域内的信息聚合。</li><li>在用户-物品交互图中，顶点与顶点之间的边也包含更多的信息，除了表示是否交互，还能表示用户对一个物品的偏好（喜爱还是厌恶），而此前的GNN只是将边用来表示是否交互。</li><li>社会关系图中用户之间的纽带有强有弱，显然地，一个用户更可能与强纽带的其它用户有类似的喜好。如果将所有纽带关系都看成一样，会有偏差。</li></ol><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>创新：</p><ul><li>在不同图(user-user graph和user-item graph)上进行信息传递与聚合</li><li>除了捕获user-item间的交互关系，还利用了user对item的评分</li><li>用attention机制表示社交关系的重要性，用户纽带的强与弱</li></ul><div align="center"><a href="https://imgchr.com/i/r0xT1A" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/r0xT1A.png" alt="r0xT1A.png" border="0" width="90%"></a></div><p>整个GraphRec框架由三个部分组成，分别为user modeling、item modeling和rating prediction。其中user modeling用来学习用户的特征表示，学习的方式是两个聚合：item aggregation和social aggregation，类似地item modeling用来学习物品的特征表示，学习的方式是一个聚合：user aggregation。</p><h4 id="User-Modeling"><a href="#User-Modeling" class="headerlink" title="User Modeling"></a>User Modeling</h4><h5 id="item-aggregation"><a href="#item-aggregation" class="headerlink" title="item aggregation"></a>item aggregation</h5><div align="center"><a href="https://imgchr.com/i/rBuFzt" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/rBuFzt.png" alt="rBuFzt.png" border="0" width="40%"></a></div><p>item aggregation的目的是通过用户交互过的物品以及对这些物品的倾向，来学习物品侧的用户特征表示，数学表示为：</p><script type="math/tex; mode=display">h_i^I=\sigma(W·Aggre_{items}(\{x_{ia},\forall a\in C(i)\})+b)</script><p>$C(i)$就表示用户交互过的物品的一个集合。这里的$x_{ia}$是一个表示向量，它应该能够同时表示交互关系和用户倾向。论文中的做法是通过一个MLP来结合物品的embedding和倾向的embedding，两者分别用$q_a$和$e_r$表示。倾向的embedding可能很难理解，以五分制评分为例，倾向的embedding表示为$e_r\in \mathbb{R}^d$，其中$r\in \{1,2,3,4,5\}$。</p><script type="math/tex; mode=display">x_{ia}=g_v([q_a\oplus e_r])</script><p>定义好$x_{ia}$后，下一步就是如何选取聚合函数$Aggre$了。论文中使用的是attention机制，来源于<a href="#Graph Attention Networks[ICLR&#39;18]">GAT</a>：</p><script type="math/tex; mode=display">\begin{aligned}h_i^I&=\sigma(W·\Big\{\sum_{a\in C(i)}\alpha_{ia}x_{ia}\Big\}+b) \\\alpha_{ia}'&=w_2^T·\sigma(W_1·[x_{ia}\oplus p_i]+b_1)+b_2 \\\alpha_{ia}&=\frac{\exp(\alpha_{ia}')}{\sum_{a\in C(i)}\exp(\alpha_{ia}')}\end{aligned}</script><p>这里的权重$\alpha_{ia}$考虑了$x_{ia}$和用户$u_i$的embedding $p_i$，使得权重能够与当前用户相关。</p><h5 id="social-aggregation"><a href="#social-aggregation" class="headerlink" title="social aggregation"></a>social aggregation</h5><div align="center"><a href="https://imgchr.com/i/rBK7g1" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/rBK7g1.png" alt="rBK7g1.png" border="0" width="40%"></a></div><p>social aggregation中，同样地使用了attention机制，通过attention机制来选取强纽带的其它用户（表现为聚合时权重更大）并聚合他们的信息，聚合的就是物品侧的用户特征表示。</p><script type="math/tex; mode=display">\begin{aligned}h_i^S&=\sigma(W·\Big\{\sum_{o\in N(i)}\beta_{io}h_o^I\Big\}+b) \\\beta_{io}'&=w_2^T·\sigma(W_1·[h_o^I\oplus p_i]+b_1)+b_2 \\\beta_{io}&=\frac{\exp(\beta_{io}')}{\sum_{o\in N(i)}\exp(\beta_{io}')}\end{aligned}</script><p>这里跟item aggregation基本一模一样，就不多介绍了。</p><p>得到物品侧的用户特征表示$h_i^I$和社交侧的用户特征表示$h_i^S$后，用一个MLP将它们结合，得到用户最终的特征表示：</p><script type="math/tex; mode=display">\begin{aligned}c_1&=[h_i^I\oplus h_i^S] \\c_2&=\sigma(W_2·c_1+b_2) \\&······ \\h_i&=\sigma(W_l·c_{l-1}+b_l)\end{aligned}</script><h4 id="Item-Modeling"><a href="#Item-Modeling" class="headerlink" title="Item Modeling"></a>Item Modeling</h4><h5 id="user-aggregation"><a href="#user-aggregation" class="headerlink" title="user aggregation"></a>user aggregation</h5><div align="center"><a href="https://imgchr.com/i/rBYtjH" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/rBYtjH.png" alt="rBYtjH.png" border="0" width="50%"></a></div><p>Item modeling与User modeling的做法基本一模一样…公式都是一一对应的：</p><script type="math/tex; mode=display">\begin{aligned}f_{jt}&=g_u([p_t\oplus e_r]) \\z_j&=\sigma(W·\Big\{\sum_{t\in B(j)}\mu_{jt}f_{jt}\Big\}+b) \\\mu_{jt}'&=w_2^T·\sigma(W_1·[f_{jt}\oplus q_j]+b_1)+b_2 \\\mu_{jt}&=\frac{\exp(\mu_{jt}')}{\sum_{a\in C(i)}\exp(\mu_{jt}')}\end{aligned}</script><h4 id="Rating-Prediction"><a href="#Rating-Prediction" class="headerlink" title="Rating Prediction"></a>Rating Prediction</h4><p>最后来到评分预测部分，由上面两个部分我们得到了用户特征表示$h_i$与物品特征表示$z_j$，产生评分用的也是一个MLP：</p><script type="math/tex; mode=display">\begin{aligned}g_1&=[h_i\oplus z_j] \\g_2&=\sigma(W_2·g_1+b_2) \\&······ \\g_{l-1}&=\sigma(W_l·g_{l-1}+b_l) \\r_{ij}&=w^T·g_{l-1}\end{aligned}</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Ciao、Epinions</p><p>在科技论文写作课上对这篇论文进行了分享，这里直接把讲稿和PPT放上来。</p><h3 id="PPT"><a href="#PPT" class="headerlink" title="PPT"></a>PPT</h3><p><a href="https://imgtu.com/i/2EP9mj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EP9mj.png" alt="2EP9mj.png"></a><br><a href="https://imgtu.com/i/2EPSXQ" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPSXQ.png" alt="2EPSXQ.png"></a><br><a href="https://imgtu.com/i/2ECz6g" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2ECz6g.png" alt="2ECz6g.png"></a><br><a href="https://imgtu.com/i/2EPP7n" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPP7n.png" alt="2EPP7n.png"></a><br><a href="https://imgtu.com/i/2EPC0s" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPC0s.png" alt="2EPC0s.png"></a><br><a href="https://imgtu.com/i/2EPkt0" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPkt0.png" alt="2EPkt0.png"></a><br><a href="https://imgtu.com/i/2EPFkq" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPFkq.png" alt="2EPFkq.png"></a><br><a href="https://imgtu.com/i/2EPVpT" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPVpT.png" alt="2EPVpT.png"></a><br><a href="https://imgtu.com/i/2EPAhV" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPAhV.png" alt="2EPAhV.png"></a><br><a href="https://imgtu.com/i/2EPZ1U" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPZ1U.png" alt="2EPZ1U.png"></a><br><a href="https://imgtu.com/i/2EPecF" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPecF.png" alt="2EPecF.png"></a><br><a href="https://imgtu.com/i/2EPmX4" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPmX4.png" alt="2EPmX4.png"></a><br><a href="https://imgtu.com/i/2EPunJ" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPunJ.png" alt="2EPunJ.png"></a><br><a href="https://imgtu.com/i/2EPKB9" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPKB9.png" alt="2EPKB9.png"></a><br><a href="https://imgtu.com/i/2EPM7R" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPM7R.png" alt="2EPM7R.png"></a><br><a href="https://imgtu.com/i/2EPlA1" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPlA1.png" alt="2EPlA1.png"></a><br><a href="https://imgtu.com/i/2EP1tx" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EP1tx.png" alt="2EP1tx.png"></a><br><a href="https://imgtu.com/i/2EPG9K" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPG9K.png" alt="2EPG9K.png"></a><br><a href="https://imgtu.com/i/2EP3h6" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EP3h6.png" alt="2EP3h6.png"></a><br><a href="https://imgtu.com/i/2EPJ1O" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPJ1O.png" alt="2EPJ1O.png"></a><br><a href="https://imgtu.com/i/2EPtje" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPtje.png" alt="2EPtje.png"></a><br><a href="https://imgtu.com/i/2EPYcD" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPYcD.png" alt="2EPYcD.png"></a><br><a href="https://imgtu.com/i/2EPUnH" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPUnH.png" alt="2EPUnH.png"></a><br><a href="https://imgtu.com/i/2EPaBd" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPaBd.png" alt="2EPaBd.png"></a><br><a href="https://imgtu.com/i/2EPdHA" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPdHA.png" alt="2EPdHA.png"></a><br><a href="https://imgtu.com/i/2EP0AI" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EP0AI.png" alt="2EP0AI.png"></a><br><a href="https://imgtu.com/i/2EPBNt" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPBNt.png" alt="2EPBNt.png"></a><br><a href="https://imgtu.com/i/2EPD4P" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPD4P.png" alt="2EPD4P.png"></a><br><a href="https://imgtu.com/i/2EPy38" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPy38.png" alt="2EPy38.png"></a><br><a href="https://imgtu.com/i/2EPs9f" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EPs9f.png" alt="2EPs9f.png"></a><br><a href="https://imgtu.com/i/2EiqRf" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EiqRf.png" alt="2EiqRf.png"></a><br><a href="https://imgtu.com/i/2EiLz8" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EiLz8.png" alt="2EiLz8.png"></a><br><a href="https://imgtu.com/i/2EibJP" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EibJP.png" alt="2EibJP.png"></a><br><a href="https://imgtu.com/i/2EiHit" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EiHit.png" alt="2EiHit.png"></a></p><h3 id="讲稿"><a href="#讲稿" class="headerlink" title="讲稿"></a>讲稿</h3><p>老师和同学们大家好，今天我们要介绍的是WWW会议19年的一篇论文，基于图神经网络的社会推荐。WWW会议是数据挖掘领域的CCF-A类会议。本次介绍由四个部分组成，分别是背景介绍、论文细节、实验评估以及写作技巧。</p><p>首先是背景部分，进入信息时代，我们被越来越多的信息所淹没，表面上我们有了更多的选择，但反而不知道如何选择。而推荐系统就是能够有效缓解这种“信息超载”现象的一个很好的方法。它希望根据你的历史行为记录，来挖掘你的个人喜好，从而向你推荐可能喜欢的物品。它就像一位了解我们喜好的隐形的朋友，在我们浏览或购物时陪伴左右。实际上推荐系统已经和我们的生活息息相关：不管是QQ音乐的”为你推荐”、淘宝的”猜你喜欢”或者是亚马逊的”推荐购买”，都是为我们个性化推荐的内容。</p><p>因为用户和物品的交互记录很容易以图的形式进行表示，以电影评分为例，如果将用户和电影都看成图上的顶点，而评分记录看成对应顶点间的一条边，自然就形成了一张图。而图神经网络是针对图类型数据的一种神经网络架构，很自然地就想到用图神经网络来解决推荐系统的问题，这也是本文研究的动机。图神经网络根据”相邻的顶点具有相似性“这一假设，通过聚合邻域顶点的信息来将图中顶点映射为特征空间中的向量，使得结构上相似的顶点在特征空间中有相似的特征表示。给定一张由顶点和边组成的图作为输入，通常分为如下两个步骤：邻域聚合和状态更新。</p><p>而社会推荐任务的难点在于，首先，数据往往包含两种类型的图，分别是用户-物品交互记录以及用户间的社交关系，而传统的图神经网络都是在同一张图上进行信息的传递和聚合，如何才能利用社交关系图的信息来帮助推荐相关物品？其次，交互记录还包含了更丰富的信息，例如评分高表示喜爱，评分低表示厌恶，如何将这种偏好也体现在模型的构建中？最后，社交网络中不同的好友对我们的偏好影响程度是不同的，关系越好的朋友向我们推荐的物品我们越可能接受。论文的贡献就是解决了这几个问题。</p><p>论文的架构有两条主线，分别是用户侧和物品侧，得到各自的特征表示后，计算出用户对物品的预测评分。首先是用户侧，因为给定的数据中两张图都和用户有关，我们希望能将两部分的信息都利用起来。对于用户-物品交互图，用上面提到的图神经网络的邻域聚合步骤，用户的特征表示由它交互过的物品的特征表示进行聚合得到，同时还将评分的高低纳入考虑，以引入用户的偏好。这种聚合方式是通过物品来定义用户。论文在这里额外地考虑了一步，对用户交互过的物品，它们对用户偏好的贡献也是不同的，为了表示这种不同，论文使用了attention网络来为每个物品计算出一个权重系数，以自适应地聚合这些物品的信息。attention网络涉及的细节较多，因为时间关系不在这里详细介绍，只需要了解通过attention网络可以得到不同物品相对的重要性程度。</p><p>类似地，不同的好友给一个用户偏好带来的影响也是不同的，所以在社交网络图上聚合邻域好友的信息时，论文同样使用了attention网络来为每个好友计算出一个权重系数，以表示好友对用户的重要程度。到这里，我们就从物品和好友两个角度得到了用户的特征表示，将两部分结合起来就得到了用户的特征表示。</p><p>知道用户侧的做法之后再看物品侧的做法就容易理解多了，因为采用了类似的信息聚合过程。对于一个物品，我们可以得到与它交互过的所有用户，那么该物品的特征表示就由这些用户的特征表示进行聚合得到，不出意外地，这里同样使用了attention网络来表示各个用户的重要性来进行加权聚合。现在，我们得到了用户和物品的特征表示后，剩下最后一步就是预测用户对这个物品的评分，对应这个部分的输入输出。论文在这部分采取的架构是多层感知机，因为时间原因不在这里详细介绍，它可以通过用户和物品的特征向量来预测用户对物品的一个评分，评分高的物品我们就作为候选列表向用户推荐。到这里模型的细节就介绍完了，可以看到主要是两个模块的重复使用，邻域聚合和attention表示重要性。</p><p>实验部分，论文的优化目标是减少预测值与实际值之间的偏差，使用的两个推荐系统数据集描述如下，它们的共同点都是十分稀疏，评分数相对于用户数和物品数要少得多，这也符合现实中的情况，人们往往不愿意给出自己对于物品的意见。结果部分，选取的两个指标MAE和RMSE都是越小代表预测效果越好，论文提出的模型GraphRec在所有比较模型里取得了最好的性能，同样还做了参数实验，探究不同参数的取值对结果的影响。介绍完了论文的各个部分后，最后我们来分析一下这篇论文在写作上有什么值得我们借鉴的地方。</p><p>论文做的好的一个地方是图表部分，正如老师上课所说，不应该只用颜色来进行区分不同的结果，有些学者可能喜欢将论文打印成纸质版进行阅读，这时颜色传递的信息就会被丢失。这里论文除了颜色外，图表中还在不同的数据上使用了不同的底纹，这样当进行黑白打印时，仍然能通过底纹来获取颜色所传递的信息。同时，在正文里引用图表的时候，也会在随后通过文字对图标传达的信息进行说明，这样可以让读者即使不阅读图标也能明白图表的含义，而不是不给出任何信息只是单纯为了让读者去看图表。</p><p>然而，论文中也有我们认为的不足之处，碰巧也是图表部分。图表使用了不同的颜色却没有用图例来对每种颜色的含义进行说明，这让人感觉使用颜色仅仅是为了让论文更好看而已。与之相对比的是同年会议的另一篇论文，解决的也是社会推荐问题，其中的图表部分虽然涉及了更多的颜色，但有图例进行详细的说明。让读者能够清晰地明白每种颜色的含义。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;WWW19将GNN应用于社会化推荐的一篇论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Predict then Propagate Graph Neural Networks meet Personalized PageRank[ICLR&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/PPNP%5BICLR19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/PPNP[ICLR19]/</id>
    <published>2020-12-22T03:21:34.349Z</published>
    <updated>2020-12-22T03:21:34.349Z</updated>
    
    <content type="html"><![CDATA[<p>ICLR19将PageRank与GNN结合以解决GCN层数无法加深的一篇论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>GCN层数增加后性能反而变差，如何加深GCN的层数。</p><p>根据GCN的定义，每一层网络用来捕获一跳邻居的信息，例如一个三层的GCN网络捕获的就是一个顶点三跳邻居以内的信息，而现在如果只能用浅层模型，表示只能捕获有限跳内的邻域信息，而有时候要多几跳才能捕获到有用的信息，例如<a href="#Representation Learning on Graphs with Jumping Knowledge Networks[ICML&#39;18]">JK-Net</a>中的例子。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>这一篇论文的工作其实是接着JK-Net继续往下，在那篇论文中，作者分析了GCN中信息传递这个过程与随机漫步之间的关系，论证了当层数加深之后，GCN会收敛到这个随机漫步的极限分布，而这个极限分布只与图的全局属性有关，没有把随机漫步的起始顶点，或者说是GCN中从邻域中传递和聚合信息的根顶点考虑在内，这么一来，层数加深之后每个顶点聚合出来的样子都差不多，无法区分从而导致性能变差，另一个看待的角度是，因为原始GCN是对所有聚合的信息做平均操作，层数加深之后各个顶点的邻域都变得跟整张图差不多，既然每个顶点的邻域都变得差不多，做的又是平均操作，每个顶点聚合出来的样子就会都差不多。</p><p>论文提出的解决办法是引入PageRank的思想，这也是从JK-Net中的结论观察出来的。JK-Net中所说的GCN会收敛到的极限分布的计算方法如下：</p><script type="math/tex; mode=display">\pi_{lim}=\hat{A}\pi_{lim}</script><p>而PageRank的计算方法如下：</p><script type="math/tex; mode=display">\pi_{pr}=A_{rw}\pi_{pr}</script><p>其中$A_{rw}=AD^{-1}$，两个计算方法明显地相似，区别在于，PageRank中邻接矩阵$A$没有考虑根顶点自身，而极限分布的计算里$\hat{A}$是引入了自环的。而Personalized PageRank通过引入自环而考虑了根顶点自身，论文的想法就是将随机漫步的极限分布用Personalized PageRank来代替，它的计算方法为：</p><script type="math/tex; mode=display">\pi_{ppr}(i_x)=(1-\alpha)\hat{A}\pi_{ppr}(i_x)+\alpha i_x \\\rightarrow \pi_{ppr}(i_x)=\alpha\Big(I_n-(1-\alpha)\hat{A}\Big)^{-1}i_x</script><p>其中$i_x$是一个one_hot指示向量，用来从根顶点重新启动。</p><blockquote><p>Personalized PageRank算法的目标是要计算所有节点相对于用户u的相关度。从用户u对应的节点开始游走，每到一个节点都以α的概率停止游走并从u重新开始，或者以1-α的概率继续游走，从当前节点指向的节点中按照均匀分布随机选择一个节点往下游走。这样经过很多轮游走之后，每个顶点被访问到的概率也会收敛趋于稳定，这个时候我们就可以用概率来进行排名了。</p></blockquote><p>相较于原始的GCN模型，现在根顶点$x$对顶点$y$的影响程度$I(x,y)$，变得与$\pi_{ppr}(i_x)$中的第$y$个元素相关，这个影响程度对于每个根顶点都有不同的取值：</p><script type="math/tex; mode=display">\require{cancel}I(x,y)\propto \prod_{ppr}^{(yx)},\prod_{ppr}^{(yx)}=\alpha\Big(I_n-(1-\alpha)\hat{A}\Big)^{-1}\cancel{I_{n}}</script><h4 id="PPNP"><a href="#PPNP" class="headerlink" title="PPNP"></a>PPNP</h4><p>经过上面的铺垫与介绍，论文提出的模型PPNP可以表示为：</p><script type="math/tex; mode=display">Z_{PPNP}=\text{softmax}\Big(\alpha\Big(I_n-(1-\alpha)\hat{A}\Big)^{-1}H\Big),H_{i,:}=f_{\theta}(X_i,:)</script><p>其中$X$为特征矩阵，$f_{\theta}$是一个参数为$\theta$的神经网络，用来产生预测类别$H\in \mathbb{R}^{n\times c}$。</p><div align="center"><a href="https://imgchr.com/i/ravXN9" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/20/ravXN9.png" alt="ravXN9.png" border="0" width="90%"></a></div><p>由公式和图中都可以看到，PPNP其实是由两部分组成，左边的神经网络与右边的信息传递网络，神经网络部分就类似于在<a href="#Semi-Supervised Classification with Graph Convolutional Network [ICLR&#39;17]">GCN</a>中介绍的，输入顶点特征与图的结构信息（邻接矩阵），输出顶点新的特征表示。信息传递网络部分，在PPNP中通过它来得到预测标签，而原始GCN的做法是$Z_{GCN}=\text{softmax}(\hat{A}HW)$，其中$W$是每层网络的参数。</p><h4 id="APPNP"><a href="#APPNP" class="headerlink" title="APPNP"></a>APPNP</h4><p>从前面的构造方式可以看到，矩阵$\prod_{ppr}$将会有$\mathbb{R}^{n\times n}$大小，会带来时间和空间上的复杂度。因此论文提出了一种近似的计算方法APPNP，计算方式如下：</p><script type="math/tex; mode=display">\begin{aligned}Z^{(0)}&=H=f_{\theta}(X) \\Z^{(k+1)}&=(1-\alpha)\hat{A}Z^{(k)}+\alpha H \\Z^{(K)}&=\text{softmax}\Big((1-\alpha)\hat{A}Z^{(K-1)}+\alpha H\Big)\end{aligned}</script><p>其中$K$为信息传递的跳数或者说是随机漫步的步数，$k\in[0,K-2]$，这样一来就不用构造一个$\mathbb{R}^{n\times n}$的矩阵了。（不知道为什么…）  </p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Citeseer、Cora-ML、Pubmed、MS Academic  </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICLR19将PageRank与GNN结合以解决GCN层数无法加深的一篇论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>DeepInf - Social Influence Prediction with Deep Learning[KDD&#39;18]</title>
    <link href="http://Bithub00.com/2020/12/22/DeepInf%5BKDD18%5D/"/>
    <id>http://Bithub00.com/2020/12/22/DeepInf[KDD18]/</id>
    <published>2020-12-22T03:18:21.401Z</published>
    <updated>2020-12-22T03:18:21.401Z</updated>
    
    <content type="html"><![CDATA[<p>KDD18一篇将GNN应用于社交网络中用户影响力预测任务的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何在图结构的社交数据中预测顶点的影响力。</p><p>在图中，给定顶点$v$与它的邻域以及一个时间段，通过对开始时各顶点的状态进行建模，来对结束时顶点$v$的状态进行预测（是否被激活）。</p><h4 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h4><ul><li>邻域：给定图$G=(V,E)$，顶点$v$的邻域定义为$N_v^r=\{u:d(u,v)\le r\}$，是一个顶点集合，不包含顶点$v$自身</li><li>中心网络：由邻域中的顶点及边所组成的网络，以$G_v^r$表示</li><li>用户行为：以$s_v^t$表示，用户对应于图中的顶点，对于一个时刻$t$，如果顶点$v$有产生动作，例如转发、引用等，则$s_v^t=1$</li></ul><p>给定用户$v$的中心网络、邻域中用户的行为集合$S_v^t=\{s_i^t:i\in N_v^r\}$，论文想解决的问题是，在一段时间$Δt$后，对用户$v$的行为的预测：</p><script type="math/tex; mode=display">P(s_v^{t+Δt}|G_v^r,S_v^t)</script><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><p><a href="https://imgchr.com/i/BGDfOO" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/29/BGDfOO.png" alt="BGDfOO.png" border="0"></a></p><p>数据预处理方面，论文通过带重启的随机漫步来为图中的每个顶点$v$获取固定大小$n$的中心网络$G_v^r$，接着使用$\text{DeepWalk}$来得到图中顶点的embedding，最后进行归一化。通过这几个步骤对图中的特征进行提取后，论文还进一步添加了几种人工提取的特征，包括用户是否活跃等等：</p><div align="center"><a href="https://imgchr.com/i/BGyXX6" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/29/BGyXX6.png" alt="BGyXX6.png" border="0" width="70%"></a></div><blockquote><p>摘要里说传统的影响力建模方法都是人工提取图中顶点及结构的特征，论文的出发点就是自动学习这种特征表示，结果在预处理的最后还是添加了几种人工提取的特征，这不是自相矛盾吗？</p></blockquote><p>经过上面的步骤后，最后得到包含所有用户特征的一个特征矩阵$H\in \mathbb{R}^{n\times F}$，每一行$h_i^T$表示一个用户的特征，$F$等同于$\text{DeepWalk}$长度加上人工特征长度。</p><h4 id="影响力计算"><a href="#影响力计算" class="headerlink" title="影响力计算"></a>影响力计算</h4><p>这一步纯粹是在套GAT的框架，没什么可以说的，计算如下：</p><script type="math/tex; mode=display">H'=\text{GAT}(H)=g(A_{\text{GAT}}(G)HW^T+b)\\A_{\text{GAT}}(G)=[a_{ij}]_{n\times n}</script><p>其中$W\in \mathbb{R}^{F’\times F}, b\in \mathbb{R}^{F’}$是模型的参数，$a_{ij}$的计算在GAT论文的笔记中有记录，不再赘述。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>OAG、Digg、Twitter、Weibo</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;KDD18一篇将GNN应用于社交网络中用户影响力预测任务的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>KGAT - Knowledge Graph Attention Network for Recommendation[KDD&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/KGAT%5BKDD19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/KGAT[KDD19]/</id>
    <published>2020-12-22T03:16:39.766Z</published>
    <updated>2020-12-22T03:18:37.048Z</updated>
    
    <content type="html"><![CDATA[<p>KDD19一篇将知识图谱与GNN融合的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在推荐系统中，如何将用户-物品交互信息与物品自身的属性相结合以做出更好的推荐，从另一个角度来说，即如何融合用户-物品交互图与知识图谱</p><div align="center"><a href="https://imgchr.com/i/BnaHGn" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/BnaHGn.png" alt="BnaHGn.png" border="0" width="65%"></a></div><p>以上面的图为例，在电影推荐场景中，用户对应于观众，物品对应于电影，实体Entities可以有多种含义，例如导演、演员、电影类别等，对应的就会有多种关系，对应图中的$r_1-r_4$。对于用户$u_1$，协同过滤更关注于他的相似用户，即同样看过$i_1$的$u_4$与$u_5$；而有监督学习方法例如因子分解机等会更关注物品之间的联系，例如$i_1$与$i_2$同样有着属性$e_1$，但它无法进一步建模更高阶的关系，例如图中黄色圈内的用户$u_2$与$u_3$观看了同一个导演$e_1$的电影$i_2$，而这名导演$e_1$又作为演员参演了灰色圈内的电影$i_3$与$i_4$。图中上半部分对应于用户-物品交互图，下半部分对应于知识图谱。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p><a href="https://imgchr.com/i/BnDu0f" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/BnDu0f.png" alt="BnDu0f.png" border="0"></a></p><h4 id="CKG-Embedding-Layer"><a href="#CKG-Embedding-Layer" class="headerlink" title="CKG Embedding Layer"></a>CKG Embedding Layer</h4><p>知识图谱的一般形式可以表示为三元组的集合$\{(h,r,t)\}$，表示头实体$h$与尾实体$t$之间有关系$r$，例如$\text{(Hugh Jackman,ActorOf,Logan)}$表示狼叔是电影罗根的演员，这是一种主动的关系，自然就有逆向的被动关系。而对于用户-物品交互信息来说，通常的表示形式为一个矩阵$R$，$R_{ui}$表示用户$u$与物品$i$的关系，有交互则值为1，否则为0。因此，为了统一两种表示形式，论文中将用户-物品交互信息同样改成三元组的集合$\text$，这样一来得到的统一后的新图称之为Collaborative Knowledge Graph(CKG)。</p><p>第一个步骤是对CKG做embedding，得到图中顶点和边的向量表示形式。论文使用了知识图谱中常用的一个方法$\text{TransR}$，即对于一个三元组$(h,r,t)$，目标为：</p><script type="math/tex; mode=display">e_h^r+e_r\approx e_t^r</script><p>其中$e_h,e_t\in \mathbb{R}d、e_r\in \mathbb{R}k$分别为$h、t、r$的embedding，而$e_h^r,e_t^r$为$e_h、e_t$在$r$所处空间中的投影，损失函数定义为：</p><script type="math/tex; mode=display">g(h,r,t)=||W_re_h+e_r-W_re_t||^2_2</script><p>值越小说明该三元组在知识图谱中更可能存在，即头实体$h$与尾实体$t$之间更可能有关系$r$。经过这一步骤之后，CKG中所有的顶点及边我们都得到了它们的embedding。</p><h4 id="Attentive-Embedding-Propagation-Layers"><a href="#Attentive-Embedding-Propagation-Layers" class="headerlink" title="Attentive Embedding Propagation Layers"></a>Attentive Embedding Propagation Layers</h4><p>第二个步骤直接用的GCN与GAT的想法，在一层embedding propagation layer中，利用图卷积网络在邻域中进行信息传播，利用注意力机制来衡量邻域中各邻居顶点的重要程度。再通过堆叠$l$层来聚合$l$阶邻居顶点的信息。</p><p>在每一层中，首先将顶点$h$的邻域以向量形式表示，系数$\pi(h,r,t)$还会进行$\text{softmax}$归一化：</p><script type="math/tex; mode=display">\begin{aligned}e_{N_h}&=\sum_{(h,r,t)\in N_h}\pi(h,r,t)e_t \\\pi(h,r,t)&=(W_re_t)^T\text{tanh}\big(W_re_h+e_r\big)\end{aligned}</script><p>通过堆叠$l$层来聚合$l$阶邻居顶点的信息：</p><script type="math/tex; mode=display">\begin{aligned}e_h^{(l)}&=f\big( e_h^{(l-1)},e_{N_h}^{(l-1)} \big) \\&=\text{LeakyReLU}\big( W_1(e_h+e_{N_h})\big)+\text{LeakyReLU}\big( W_2(e_h\odot e_{N_h})\big)\end{aligned}</script><p>论文中所使用的聚合函数$f$在GCN与GraphSage的基础上，还额外地引入了第二项中$e_h$与$e_{N_h}$的交互，这使得聚合的过程对于两者之间的相近程度更为敏感，会在更相似的顶点中传播更多的信息。</p><h4 id="Model-Prediction"><a href="#Model-Prediction" class="headerlink" title="Model Prediction"></a>Model Prediction</h4><p>在得到$L$层embedding propagation layer的表示后，使用JK-Net中的LSTM-attention进行聚合，在通过点积的形式给出预测分数：</p><script type="math/tex; mode=display">e_u^*=\text{LSTM-attention}(e_u^{(0)},e_u^{(L)})\\e_i^*=\text{LSTM-attention()}e_i^{(0)}||\dots||e_i^{(L)}\\\hat{y}(u,i)={e_u^*}^Te_i^*</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Amazon-book、Last-FM、Yelp2018</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;KDD19一篇将知识图谱与GNN融合的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Session-Based Recommendation with Graph Neural Networks[AAAI&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/SRGCN%5BAAAI19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/SRGCN[AAAI19]/</id>
    <published>2020-12-22T03:13:14.168Z</published>
    <updated>2020-12-22T03:13:29.818Z</updated>
    
    <content type="html"><![CDATA[<p>AAAI19一篇将gated GNN应用于序列推荐任务的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在序列推荐任务中，现有的方法很难在每条序列中取得准确的用户embedding，因为得到的序列数据往往是匿名的，且序列中记录的点击数据所透露出来的用户行为信息有限。同时，序列中物品间的关系虽然常被证实有效，但现有的方法往往只考虑一阶的前后连续关系，即对于$a\rightarrow b \rightarrow  c$，只考虑$a\rightarrow b$或者$b\rightarrow c$</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p><a href="https://imgchr.com/i/BF3uuT" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BF3uuT.png" alt="BF3uuT.png" border="0"></a></p><h4 id="Session-Graph-Modeling"><a href="#Session-Graph-Modeling" class="headerlink" title="Session Graph Modeling"></a>Session Graph Modeling</h4><p>将每条序列$s$表示成一个有向图，并对图中的边进行正则化，具体做法为边的出现次数除以边起始顶点的出度。以序列$s=[v_1,v_2,v_3,v_2,v_4]$为例构建一个有向图，得到邻接矩阵：</p><div align="center"><a href="https://imgchr.com/i/BF17nO" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BF17nO.png" alt="BF17nO.png" border="0" width="80%"></a></div><p>上面的邻接矩阵以考虑顶点的出边并以出度正则化，类似地可以考虑顶点的入边并以入度正则化，将得到的两种邻接矩阵进行拼接，得到论文中提到的连接矩阵$A_s\in \mathbb{R}^{n\times 2n}$，其中的一行$A_{s,i:}\in \mathbb{R}^{1\times 2n}$对应于所构建的有向图中的一个顶点$v_{s,i}$：</p><div align="center"><a href="https://imgchr.com/i/BFGCkQ" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BFGCkQ.png" alt="BFGCkQ.png" border="0" width="80%"></a></div><h4 id="Node-Representation-Learning"><a href="#Node-Representation-Learning" class="headerlink" title="Node Representation Learning"></a>Node Representation Learning</h4><p>论文使用gated GNN来学习图中顶点的表示，为了类比地说明各式的具体含义，首先对Gated Recurrent Units（GRU）进行介绍，它是循环神经网络中的一个概念。</p><h5 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h5><p>一个典型的GRU如下所示，输入为上一时刻的隐层表示$H_{t-1}$及当前时刻的表示$X_t$，包含一个重置门Reset Gate和一个更新门Update Gate：</p><div align="center"><a href="https://imgchr.com/i/BFaaAf" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BFaaAf.png" alt="BFaaAf.png" border="0" width="60%"></a></div><p>直观的来说，重置门决定有多少历史信息被保留，而更新门决定利用多少当前时刻$X_t$的信息。给定当前时刻输入$X_t\in \mathbb{R}^{n\times d}$，上一时刻隐层表示$H_{t-1}\in \mathbb{R}^{n\times h}$，重置门与更新门的输出由下式计算得到：</p><script type="math/tex; mode=display">R_t=\sigma(X_tW_{xr}+H_{t-1}W_{hr}+b_r)\\Z_t=\sigma(X_tW_{xz}+H_{t-1}W_{hz}+b_z)</script><p>式中的$W$与$b$分别为权重与偏置参数。</p><h5 id="Reset-Gate"><a href="#Reset-Gate" class="headerlink" title="Reset Gate"></a>Reset Gate</h5><p>传统RNN网络的隐式状态更新公式为：</p><script type="math/tex; mode=display">H_t=\tanh(X_tW_{xh}+H_{t-1}W_{hh}+b_h)</script><p>如果我们需要减少历史信息带来的影响，可以将$H_{t-1}$与$R_t$逐元素相乘。如果$R_t$中的元素接近于1，得到的结果就是传统的RNN，如果$R_t$中的结果接近于0，得到的结果就是以$X_t$作为输入的MLP，计算出来的$\tilde{H_t}$称为候选状态：</p><script type="math/tex; mode=display">\tilde{H_t}=\tanh(X_tW_{xh}+(R_t\odot{H_{t-1}})W_{hh}+b_h)</script><h5 id="Update-Gate"><a href="#Update-Gate" class="headerlink" title="Update Gate"></a>Update Gate</h5><p>更新门决定新的隐式状态$H_t$多大程度上与上一时刻$H_{t-1}$相同，以及重置门得到的候选状态$\tilde{H_t}$中有多少信息可以被利用，如果$Z_t$中的元素接近于1，将主要保留历史信息，当前时刻$X_t$的信息基本被忽略，这相当于跳过了时刻$t$；当$Z_t$中的元素接近于0时，$H_t$将主要由$\tilde{H_t}决定$：</p><script type="math/tex; mode=display">H_t=Z_t\odot H_{t-1}+(1-Z_t)\odot \tilde{H_t}</script><p>介绍完了GRU的基本概念，接下来是论文中的方法，可以类比地进行学习：</p><p><a href="https://imgchr.com/i/BkiNUU" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BkiNUU.png" alt="BkiNUU.png" border="0"></a></p><p>最主要的不同之处在公式$(1)$，它用于在连接矩阵$A_s$的约束下进行不同顶点间的信息传播，具体来说，它提取了邻域的隐向量并将它们作为GNN的输入。</p><h4 id="Session-Representation-Generation"><a href="#Session-Representation-Generation" class="headerlink" title="Session Representation Generation"></a>Session Representation Generation</h4><p>现有的做法都假设每条序列中的用户都有一个独特的隐式表示，而论文中提出的方法不对这个隐式向量做任何假设，相反，它用序列中顶点的表示来作为序列的表示，而顶点的表示正是上一步将所有序列构建的图送入gated GNN学习得到的。给定一个序列$\text{s}=[v_{s,1},v_{s,2},\dots,v_{s,n}]$，这一步的目的是得到它的embedding向量$s\in \mathbb{R}^d$。为了结合用户的长期偏好与当前兴趣，生成的embedding向量也有局部和全局两部分组成。</p><p>局部embedding向量的构造非常简单，就是最后一个点击过的物品的表示，因为最后一个点击过的物品就表明了用户当前的兴趣：</p><script type="math/tex; mode=display">s_l=v_n</script><p>全局embedding向量的构造需要将所有顶点的表示都聚合进来，论文的做法是做一个线性加权，权重使用$\text{soft-attention}$机制来计算得到：</p><script type="math/tex; mode=display">\begin{aligned}s_g&=\sum_{i=1}^{n}\alpha_iv_i\\\alpha_i&=q^T\sigma(W_1v_n+W_2v_i+c)\end{aligned}</script><p>最后使用一个$\text{Linear}$层来将局部与全局embedding向量进行结合得到最终的序列embedding向量：</p><script type="math/tex; mode=display">s_h=W_3[s_l;s_g]</script><h4 id="Making-Recommendation"><a href="#Making-Recommendation" class="headerlink" title="Making Recommendation"></a>Making Recommendation</h4><p>对于一个待推荐物品$v_i\in V$，计算它在序列$s$中作为下一个被点击物品的概率：</p><script type="math/tex; mode=display">\hat{y_i}=\text{softmax}(s_h^Tv_i)</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Yoochoose、Diginetica</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;AAAI19一篇将gated GNN应用于序列推荐任务的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Representation Learning on Graphs with Jumping Knowledge Networks[ICML&#39;18]</title>
    <link href="http://Bithub00.com/2020/12/22/JK-Net%5BICML18%5D/"/>
    <id>http://Bithub00.com/2020/12/22/JK-Net[ICML18]/</id>
    <published>2020-12-22T03:11:56.918Z</published>
    <updated>2021-05-29T14:19:26.712Z</updated>
    
    <content type="html"><![CDATA[<p>ICML18一篇解决GCN层数加深性能反而变差的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>当图卷积网络GCN的层数超过两层时模型的表现会变差，这使得GCN只能作为浅层模型使用，且在对邻域节点的信息进行聚合时，即使同样是采用$k$层网络来聚合$k$跳邻居的信息，有着不同局部结构的顶点获得的信息也可能完全不同，以下图为例：</p><div align="center"><a href="https://imgchr.com/i/BpCLz8" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/20/BpCLz8.jpg" alt="BpCLz8.jpg" border="0" width="70%"></a></div><p>图$(a)$中的顶点位于核心区域，因此采用$4$层网络把几乎整个图的信息都进行聚合了，而不是它的邻域，这会导致过度平滑，而图$(b)$中顶点位于图边缘的一个树状结构中，采取同样的$4$层网络只囊括了一小部分顶点的信息，只有在第$5$层囊括了核心顶点之后才有效地囊括了更多顶点的信息。</p><p>所以，对于处于核心区域的顶点，GCN中每多一层即每多一次卷积操作，节点的表达会更倾向全局，这导致核心区域的很多顶点的表示到最后没有区分性。对于这样的顶点应该减少GCN的层数来让顶点更倾向局部从而在表示上可以区分；而处于边缘的顶点，即使更新多次，聚合的信息也寥寥无几，对于这样的顶点应该增加GCN的层数，来学习到更充分的信息。因此，对于不同的顶点应该选取不同的层数，传统做法对于所有顶点都用一个值会带来偏差。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>理论部分，论文主要讨论的问题是，在一个$k$层的GCN中，顶点$x$对顶点$y$的影响程度，即顶点$x$输入特征的改变，会对顶点$y$在最后一层得到的表示产生多大的变化，也可以说是顶点$y$对于顶点$x$有多敏感。假设输入的特征为$X\in \mathbb{R}^{n\times f}$，输出的预测标签为$Z\in \mathbb{R}^{n\times c}$，其中$n$为图中顶点数目，$c$为类别数目，$f$为特征数目，则这种影响程度可以表示为$I(x,y)=\sum_i\sum_j\frac{\partial Z_{yi}}{\partial X_{xj}}$。</p><p>更特别地，论文证明了这个影响程度与从顶点$x$开始的$k$步随机漫步的分布有关，如果对$k$取极限$k\rightarrow \infty$，则随机漫步的分布会收敛到$P_{lim}(\rightarrow y)$。详细论证过程可见原文。这说明，结果与随机漫步的的起始顶点$x$没有关系，通过这种方法来得到$x$的邻域信息是不适用的。</p><p>另一种说法是，一个$k$层的图卷积网络等同于一个$k$阶的多项式过滤器，其中的系数是预先确定的<a href="https://arxiv.org/abs/2007.02133v1" target="_blank" rel="noopener">SDC</a>。这么一个过滤器与随机漫步类似，最终会收敛到一个静态向量，从而导致过度平滑。</p><p>实践部分，论文提出JK-Net，通过Layer aggregation来让顶点最后的表示自适应地聚合不同层的信息，局部还是全部，让模型自己来学习：</p><div align="center"><a href="https://imgchr.com/i/BpEvLT" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/20/BpEvLT.jpg" alt="BpEvLT.jpg" border="0" width="50%"></a></div><p>论文的重点在于最后的Layer aggregation层，可选的三种操作为：Concat、Max-pooing以及LSTM-attn。</p><ol><li><p>Concat</p><p>将各层的表示直接拼接在一起，送入Linear层。对于小数据集及结构单一的图这种聚合方式会更好，因为它们不需要顶点在聚合邻域的顶点信息时具有什么自适应性。</p></li><li><p>Max-pooling</p><p>选取各层的表示中包含信息量最多的作为顶点的最终表示，在多层结构中，低层聚合更多局部信息，而高层会聚合更多全局信息，因此对于核心区域内的顶点可能会选取高层表示而边缘顶点选取低层表示。</p></li><li><p>LSTM-attention</p><p>对于各层的表示，attention机制通过计算一个系数$s_v^{(l)}$来表示各层表示的重要性，其中$\sum_ls_v^{(l)}=1$，顶点最终的表示就是各层表示的一个加权和：$\sum_ls_v^{(l)}·h_v^{(l)}$。</p><blockquote><p>$s_v^{(l)}$的计算：将$k$层网络各层的表示$h_v^{(1)},\dots,h_v^{(k)}$输入一个双向LSTM中，同时生成各层$l$的前向LSTM与反向LSTM的隐式特征，分别表示为$f_v^{(l)}、b_v^{(l)}$，拼接后将$|f_v^{(l)}||b_v^{(l)}|$送入一个Linear层，将Linear层的结果进行Softmax归一化操作就得到了系数$s_v^{l}$。</p></blockquote></li></ol><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Citeseer、Cora、Reddit、PPI</p><p>在模式识别上对这篇论文进行了简短的一个分享，这里直接把讲稿和PPT放上来。</p><h3 id="PPT"><a href="#PPT" class="headerlink" title="PPT"></a>PPT</h3><p><a href="https://imgtu.com/i/2EFaFI" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFaFI.png" alt="2EFaFI.png"></a><br><a href="https://imgtu.com/i/2EFdYt" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFdYt.png" alt="2EFdYt.png"></a><br><a href="https://imgtu.com/i/2EFDl8" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFDl8.png" alt="2EFDl8.png"></a><br><a href="https://imgtu.com/i/2EFwfP" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFwfP.png" alt="2EFwfP.png"></a><br><a href="https://imgtu.com/i/2EFNTA" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFNTA.png" alt="2EFNTA.png"></a><br><a href="https://imgtu.com/i/2EFBSf" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFBSf.png" alt="2EFBSf.png"></a><br><a href="https://imgtu.com/i/2EFr6S" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFr6S.png" alt="2EFr6S.png"></a><br><a href="https://imgtu.com/i/2EFRkn" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFRkn.png" alt="2EFRkn.png"></a><br><a href="https://imgtu.com/i/2EFcwj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFcwj.png" alt="2EFcwj.png"></a><br><a href="https://imgtu.com/i/2EFff0" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFff0.png" alt="2EFff0.png"></a><br><a href="https://imgtu.com/i/2EFLkR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFLkR.png" alt="2EFLkR.png"></a><br><a href="https://imgtu.com/i/2EFoXF" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/29/2EFoXF.png" alt="2EFoXF.png"></a></p><h3 id="讲稿"><a href="#讲稿" class="headerlink" title="讲稿"></a>讲稿</h3><p>大家好，今天我要介绍的是ICML会议18年的一篇论文，通过跳跃知识网络进行图上的表示学习，论文的亮点在于引入ResNet的思想解决图神经网络层数无法加深的问题。图神经网络简称GNN，它受卷积神经网络CNN启发，主要应用于图这种非欧几里得结构数据。它根据”相邻的顶点具有相似性“这一假设，通过聚合邻域顶点的信息来进行图上顶点的表示学习。不同于图像这种排列整齐的欧几里得结构数据，在图上不同顶点的邻居顶点数目是不同的，这就为图上的问题带来了挑战。</p><p>给定一张由顶点和边组成的图作为输入，图神经网络通常分为如下两个步骤：邻域聚合和状态更新。邻域聚合对应式子的后半部分，而状态更新对应于式子的前半部分。在每一层的网络，首先对邻域内的顶点的表示进行聚合，再将得到的聚合结果和上一层得到的表示组合在一起，共同作为当前层顶点的表示。这里的聚合和组合有多种定义方式，因为时间原因不在这里进行介绍。虽然图神经网络的出现给图上问题的解决方法带来了新的思路，但它也面临着挑战。不同于CNN，GNN在层数加深时会出现性能下降的问题，典型的网络如图卷积网络GCN、图注意力网络GAT等都是在2~4层时取得最好的性能表现。本文的一个贡献就是从理论上分析了性能下降的原因。导致这个现象的一个主要原因是所谓的”过平滑“现象，即随着网络层数的加深，图中顶点经过网络学习得到的特征表示会趋向于相等的现象。这就会导致顶点间不再具有区分度，进而导致下游任务效果变差。例如图中的例子，从左到右表示层数的加深，可以看到，六层网络时不同的顶点几乎都混在了一起，比浅层网络时的效果要差很多。论文从随机游走的角度说明了原因，一个K层的GNN相当于从源顶点出发到目标顶点的一个K步的随机游走，当K趋向于无穷即层数不断加深时, 顶点的极限分布与初始的顶点表示无关，只与图的结构相关。也就是说，本来聚合邻域的信息是为了得到中心顶点的特征表示，当随着层数加深聚合的信息越多，反而得到的表示与中心顶点无关，这就导致每个顶点都会得到相等的特征表示。</p><p>因为ResNet等深层神经网络模型在计算机视觉领域的成功，本文受此启发引入ResNet中的残差模块，在GNN的框架中引入额外的连接。左边对应于论文提出的架构图，从架构图可以看到，不同于传统GNN每一层的表示只与上一层有关，现在每一层的表示都会额外地连接到最后一层，使得在最后一层得到最终的顶点表示时可以聚合不同层的信息，来避免前面说到的过平滑问题。聚合有三种方式：Concat、Max-pooling和LSTM-attention，每种方式有各自适合的场景，例如第三种方式通过双向LSTM来得到各层表示的重要程度，进而自适应地聚合各层的信息，得到更好的特征表示。因为时间关系不再展开介绍。实验部分，论文选取的baseline都是经典的GNN模型，包括图卷积网络GCN和图注意力网络GAT，可以看到在几个benchmark数据集上都取得了最好的结果，也使用了更深的网络层数。我今天的分享到此结束，谢谢大家。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICML18一篇解决GCN层数加深性能反而变差的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Graph Attention Networks[ICLR&#39;18]</title>
    <link href="http://Bithub00.com/2020/12/22/GAT%5BICLR18%5D/"/>
    <id>http://Bithub00.com/2020/12/22/GAT[ICLR18]/</id>
    <published>2020-12-22T03:05:16.191Z</published>
    <updated>2020-12-22T03:14:01.743Z</updated>
    
    <content type="html"><![CDATA[<p>ICLR18一篇解决GCN聚合信息时无法区分信息重要性的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何将attention机制应用于图类型的数据上。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="图卷积"><a href="#图卷积" class="headerlink" title="图卷积"></a>图卷积</h4><div align="center"><img src="https://s1.ax1x.com/2020/10/16/07O1IK.png" alt="1" border="0" width="60%"><img src="https://s1.ax1x.com/2020/10/16/07O8PO.png" alt="2" border="0" width="60%"></div><p>给定一个含$n$个顶点的图，其中顶点的特征构成的集合为$(\overrightarrow{h_1},\overrightarrow{h_2},\dots,\overrightarrow{h_n})$，$\overrightarrow{h_i}\in \mathbb{R}^F$且邻接矩阵为$A$。一个图卷积层根据已有的顶点特征和图的结构来计算一个新的特征集合$(\overrightarrow{h_1’},\overrightarrow{h_2’},\dots,\overrightarrow{h_n’})$，$\overrightarrow{h_i’}\in \mathbb{R}^{F’}$</p><p>每个图卷积层首先会进行特征转换，以特征矩阵$W$表示，$W\in \mathbb{R}^{F’\times F}$它将特征向量线性转换为$\overrightarrow{g_i}=W\overrightarrow{h_i}$，再将新得到的特征向量以某种方式进行结合。为了利用邻域的信息，一种典型的做法如下：</p><script type="math/tex; mode=display">\overrightarrow{h_i}'=\sigma\bigg(\sum_{j\in N_i}\alpha_{ij}\overrightarrow{g_j}\bigg)</script><p>其中$N_i$表示顶点$i$的邻域（典型的构造方式是选取直接相连的顶点，包括自身），$\alpha_{ij}$表示顶点$j$的特征对于顶点$i$的重要程度，也可以看成一种权重。</p><p>现有的做法都是显式地定义$\alpha_{ij}$，本文的创新之处在于使用attention机制隐式地定义$\alpha_{ij}$。所使用的attention机制定义为$a:R^{F’}\times \mathbb{R}^{F’} \rightarrow \mathbb{R}$，以一个权重向量$\overrightarrow{a}\in \mathbb{R}^{2F’}$表示，对应于论文中的self-attention。  </p><h4 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h4><ol><li>基于顶点的特征计算系数$e_{ij}$</li></ol><script type="math/tex; mode=display">e_{ij}=a(W\overrightarrow{h_i},W\overrightarrow{h_j})</script><ol><li>以顶点的邻域将上一步计算得到的系数正则化，这么做能引入图的结构信息：</li></ol><script type="math/tex; mode=display">\begin{aligned}\alpha_{ij}&=\text{softmax}_j(e_{ij})=\frac{\exp(e_{ij})}{\sum_{k\in N_i}\exp(e_{ik})}\\&=\frac{\exp(\text{LeakyReLU}(\overrightarrow{a}^T[W\overrightarrow{h}_i||W\overrightarrow{h}_j]))}{\sum_{k\in N_i}\exp(\text{LeakyReLU}(\overrightarrow{a}^T[W\overrightarrow{h}_i||W\overrightarrow{h}_k]))}\end{aligned}</script><p><img src="https://s1.ax1x.com/2020/10/16/0H5cX6.png" alt="0H5cX6.png" border="0" width="30%"></p><blockquote><p>次序不变性：给定$(i,j),(i,k),(i’,j),(i’,k)$表示两个顶点间的关系，可以为边或自环。$a$为对应的attention系数，如果$a_{ij}&gt;a_{ik}$，则有$a_{i’j}&gt;a_{i’k}$</p></blockquote><p>​    <a href="https://dl.acm.org/doi/10.1145/3219819.3220077" target="_blank" rel="noopener">DeepInf</a>中给出了证明：</p><p>​    将权重向量$\overrightarrow{a}\in \mathbb{R}^{2F’}$重写为$\overrightarrow{a}=[p^T，q^T]$，则有</p><script type="math/tex; mode=display">e_{ij}=\text{LeakyReLU}(p^TWh_i+q^TWh_j)</script><p>​    由softmax与LeakyReLU的单调性可知，因为$a_{ij}&gt;a_{ik}$，有$q^TWh_j&gt;q^TWh_k$，类似地就可以得到$a_{i’j}&gt;a_{i’k}$。</p><p>​    这意味着，即使每个顶点都只关注于自己的邻域，但得到的attention系数却具有全局性。</p><ol><li>以上一步得到的系数$\alpha_{ij}$作为顶点$j$的特征对顶点$i$的重要程度，将领域中各顶点的特征做一个线性组合以作为顶点$i$最终输出的特征表示：</li></ol><script type="math/tex; mode=display">\overrightarrow{h_i'}=\sigma\bigg(\sum_{j\in N_i}\alpha_{ij}W\overrightarrow{h_j}\bigg)</script><h4 id="Multi-head-attention"><a href="#Multi-head-attention" class="headerlink" title="Multi-head attention"></a>Multi-head attention</h4><p>为了稳定self-attention的学习过程，论文引入了multi-head attention，即由$K$个相互独立的self-attention得到各自的特征，再进行拼接：</p><p><img src="https://s1.ax1x.com/2020/10/16/0HbZlj.png" alt="0HbZlj.png" border="0" width="60%"></p><script type="math/tex; mode=display">\overrightarrow{h_i'}=\Vert_{k=1}^K\sigma\bigg(\sum_{j\in N_i}\alpha_{ij}^kW^k\overrightarrow{h_j}\bigg)</script><p>其中$\alpha_{ij}^k$是第$k$个attention机制$(a^k)$计算出来的正则化系数，$W^k$是对应的将输入进行线性转化的权重矩阵。论文选取的拼接操作为求平均：</p><script type="math/tex; mode=display">\overrightarrow{h_i'}=\sigma\bigg(\frac{1}{K}\sum_{k=1}^K\sum_{j\in N_i}\alpha_{ij}^kW^k\overrightarrow{h_j}\bigg)</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Cora、Citeseer、Pubmed、PPI</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICLR18一篇解决GCN聚合信息时无法区分信息重要性的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Learning Convolutional Neural Networks for Graphs[ICML&#39;16]</title>
    <link href="http://Bithub00.com/2020/12/22/Learning-Convolutional-Neural-Networks-for-Graphs%5BICML16%5D/"/>
    <id>http://Bithub00.com/2020/12/22/Learning-Convolutional-Neural-Networks-for-Graphs[ICML16]/</id>
    <published>2020-12-22T03:04:15.061Z</published>
    <updated>2020-12-22T03:14:11.624Z</updated>
    
    <content type="html"><![CDATA[<p>ICML16一篇将CNN应用到图数据上的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>卷积神经网络都是应用在图像数据上，如何将它有效地应用于图类型的数据上。</p><p>对于图像数据，应用一个卷积神经网络可以看成将receptive field（图中为$3\times3$）以固定的步长将图像遍历，因为图像中像素点的排列有一定的次序，receptive field的移动顺序总是从上到下，从左到右。这也唯一地决定了receptive field对一个像素点的遍历方式以及它如何被映射到向量空间中。</p><div align="center"><img src="https://s1.ax1x.com/2020/10/12/0WKA5n.png" alt="0WKA5n.png" border="0" width="65%"></div><p>然而对于图结构数据这种隐式的结构特征很多时候是缺失的，而且当给定不止一张图时，各个图之间的顶点没有必然的联系。因此，在将卷积神经网络应用在图数据上时，需要解决下面两个问题：</p><ol><li><p>决定邻域中顶点的产生次序</p></li><li><p>计算一个将图映射到向量空间的映射方法</p></li></ol><p><img src="https://s1.ax1x.com/2020/10/12/0W1Zo4.png" alt="0W1Zo4.png" border="0" width="80%"></p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>论文提出方法的流程如下：</p><p><img src="https://s1.ax1x.com/2020/10/12/0W3X5Q.png" alt="0W3X5Q.png" border="0" width="60%"></p><h4 id="Node-Sequence-Selection"><a href="#Node-Sequence-Selection" class="headerlink" title="Node Sequence Selection"></a>Node Sequence Selection</h4><p>从图中选取固定数量$w$的顶点，它类比于图像的宽度，而选出的顶点就是卷积操作中小矩形的中心顶点。$w$就是在这个图上所做的卷积操作的个数。如下图所示，$w=6$，代表需要从图中选择6个顶点做卷积操作。论文中选取顶点的方式为$\text{DFS}$，关键点在于图标签函数$l$，这个函数的作用是决定选取顶点的次序，可以选区的函数为between centrality与WL算法等等</p><p><img src="https://s1.ax1x.com/2020/10/12/0WGInP.png" alt="0WGInP.png" border="0"></p><p><img src="https://s1.ax1x.com/2020/10/12/0WyWOU.png" alt="0WyWOU.png" border="0"></p><h4 id="Neighborhood-Assembly"><a href="#Neighborhood-Assembly" class="headerlink" title="Neighborhood Assembly"></a>Neighborhood Assembly</h4><p>选取完顶点后，下一步是为它们构建receptive field，类似于第一张图中的$3\times3$矩阵。选取的方式为，以顶点$v$为中心，通过$\text{BFS}$添加领域顶点，直到满足receptive field长度$k$：</p><div align="center"><img src="https://s1.ax1x.com/2020/10/12/0WDBw9.png" alt="0WDBw9.png" border="0" width="60%"></div><p><img src="https://s1.ax1x.com/2020/10/12/0W6V0g.png" alt="0W6V0g.png" border="0" width="80%"></p><h4 id="Graph-Normalization"><a href="#Graph-Normalization" class="headerlink" title="Graph Normalization"></a>Graph Normalization</h4><p>在选取了满足数量的邻域顶点后，下一步是通过图标签函数$l$为这些顶点赋予一个次序，目的在于将无序的领域映射为一个有序的向量：</p><p><img src="https://s1.ax1x.com/2020/10/12/0Wy1dH.png" alt="0Wy1dH.png" border="0"></p><div align="center"><img src="https://s1.ax1x.com/2020/10/12/0W6rnO.png" alt="0W6rnO.png" border="0" width="60%"></div><h4 id="Convolutional-Architecture"><a href="#Convolutional-Architecture" class="headerlink" title="Convolutional Architecture"></a>Convolutional Architecture</h4><p>最后一步就是应用卷积层提取特征，顶点和边的属性对应于传统图像CNN中的channel：</p><p><img src="https://s1.ax1x.com/2020/10/13/0fpKeK.png" alt="0fpKeK.png" border="0" width="75%"></p><p>假设顶点特征的数目为$a_v$，边的特征个数为$a_e$，$w$为选取的顶点个数，$k$为receptive field中的顶点个数，则对于输入的一系列图中的每一个，可以得到两个张量维度分别为$(w,k,a_v)、(w,k,k,a_e)$，可以变换为$(wk,a_v)、(wk^2,a_e)$，其中$a_v$与$a_e$可以看成是传统图像卷积中channel的个数，对它们做一维的卷积操作，第一个的receptive field的大小为$k$，第二个的receptive field的大小为$k^2$。</p><p><img src="https://s1.ax1x.com/2020/10/13/0fpWwT.png" alt="0fpWwT.png" border="0" width="75%"></p><p>整体卷积结构：</p><p><img src="https://s1.ax1x.com/2020/10/13/0fpbOx.png" alt="0fpbOx.png" border="0" width="75%"></p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>MUTAG、PTC、NCI、D&amp;D</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICML16一篇将CNN应用到图数据上的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Inductive Representation Learning on Large Graphs[NIPS&#39;17]</title>
    <link href="http://Bithub00.com/2020/12/22/GraphSage%5BNIPS17%5D/"/>
    <id>http://Bithub00.com/2020/12/22/GraphSage[NIPS17]/</id>
    <published>2020-12-22T03:03:07.830Z</published>
    <updated>2020-12-22T03:14:22.897Z</updated>
    
    <content type="html"><![CDATA[<p>NIPS17一篇解决GCN不能泛化到未知顶点的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>对于学习图上顶点的embedding，现有的方法多为直推式学习，学习目标是直接生成当前顶点的embedding，不能泛化到未知顶点上</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>论文提出一种归纳式学习方法GrdaphSAGE，不为每个顶点学习单独的embedding，而是学习一种聚合函数$\text{AGGREGATE}$，从一个顶点的局部邻域聚合特征信息，为未知的顶点直接生成embedding，因此旧的顶点只要邻域发生变化也能得到一个新的embedding</p><blockquote><p>GCN不是归纳式，因为每次迭代会用到整个图的邻接矩阵$A$；而GraphSAGE可以对GCN做了精简，每次迭代只抽样取直接相连的邻居</p></blockquote><h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><ol><li>给定顶点$v$及其特征$x_v$,作为它的初始表示$h_v^0=x_v$。</li><li>计算邻域向量$h^k_{N(v)}=\text{AGGREGATE}({h_u^{(k-1)}}, \forall u\in N(v))$，当前层顶点的邻居从上一层采样，且邻居个数固定，非所有邻居，这样每个顶点和采样后邻居的个数都相同，可以直接拼成一个batch送到GPU中进行批训练</li><li>将邻域向量与自身上一层的表示拼接，通过非线性激活函数$\sigma$后作为这一层的表示$h_v^k=\sigma(W^k\text{CONCAT}(h_v^{(k-1)},h^k_{N(v)})$</li><li>标准化 $h_v^k=h_v^k/||h_v^k||_2$</li></ol><p><img src="https://s1.ax1x.com/2020/10/06/0tja9K.png" alt="0tja9K.png" border="0"></p><div align="center"><img src="https://s1.ax1x.com/2020/10/06/0tvRaR.jpg" alt="0tvRaR.jpg" width="50%" border="0"></div><h4 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h4><ol><li>MEAN</li></ol><script type="math/tex; mode=display">h_v^k=\sigma(W·\text{MEAN}(\{h_v^{k-1}\}\cup\{h_u^{k-1},\forall u\in N(v) \})</script><ol><li>LSTM</li><li>Pooling<br>GraphSAGE采用的max-pooling策略能够隐式地选取领域中重要的顶点：</li></ol><script type="math/tex; mode=display">\text{AGGREGATE}_k^{pool}=\text{max}(\{\sigma(W_{pool}h_u^k + b),\forall u\in N(v)\})</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>BioGRID、Reddit</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;NIPS17一篇解决GCN不能泛化到未知顶点的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
</feed>
