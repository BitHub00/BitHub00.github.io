<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>原力小站</title>
  
  <subtitle>扎导的原版正联出了吗？</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://Bithub00.com/"/>
  <updated>2021-01-10T03:26:07.089Z</updated>
  <id>http://Bithub00.com/</id>
  
  <author>
    <name>Mr.shuan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Variational Graph Auto-Encoders[NIPS&#39;16]</title>
    <link href="http://Bithub00.com/2021/01/09/VGAE%5BNIPS16%5D/"/>
    <id>http://Bithub00.com/2021/01/09/VGAE[NIPS16]/</id>
    <published>2021-01-09T13:54:14.216Z</published>
    <updated>2021-01-10T03:26:07.089Z</updated>
    
    <content type="html"><![CDATA[<p>NIPS16一篇将变分自编码器迁移到图结构数据上的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在图结构数据上如何使用变分自编码器</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>将已知的图进行编码（图卷积）得到图中顶点向量表示的一个分布，在分布中采样得到顶点的向量表示，然后进行解码重新构建图。</p><h4 id="变分自编码器"><a href="#变分自编码器" class="headerlink" title="变分自编码器"></a>变分自编码器</h4><p>因为这篇论文做的是一个迁移的工作，变分自编码器的背景对于理解这篇论文来说十分重要，首先进行介绍。</p><p>变分自编码器是自编码器的一种，一个自编码器由编码器和解码器构成，编码器将输入数据转换为低维向量表示，解码器通过得到的低维向量表示进行重构。</p><div align="center"><a href="https://imgchr.com/i/sl9ZxP" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/sl9ZxP.jpg" alt="sl9ZxP.jpg" border="0" width="80%"></a><a href="https://imgchr.com/i/sl9G2q" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/sl9G2q.jpg" alt="sl9G2q.jpg" border="0" width="65%"></a></div>这种结构的不足之处在于，只能产生与输入数据相似的样本，而无法产生新的样本，低维向量表示必须是有真实样本通过编码器得到的，随机产生的低维向量经过重构几乎不可能得到近似真实的样本。而变分自编码器可以解决这个问题。变分自编码器将输入数据编码为一个分布，而不是一个个低维向量表示，然后从这个分布中随机采样来得到低维向量表示。一般假设这个分布为正态分布，因此编码器的任务就是从输入数据中得到均值$\mu$与方差$\sigma^2$。<div align="center"><a href="https://imgchr.com/i/slCW60" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slCW60.jpg" alt="slCW60.jpg" border="0" width="80%"></a><a href="https://imgchr.com/i/slPZB8" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slPZB8.jpg" alt="slPZB8.jpg" border="0" width="80%"></a></div>然而，如果是将所有输入数据编码到同一个分布里，从这个分布中随机采样的样本$Z_i$无法与输入样本$X_i$一一对应，会影响模型的学习效果。所以，实际的变分自编码器结构如下图所示，为每一个输入样本学习一个正态分布：<div align="center"><a href="https://imgchr.com/i/slPgED" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slPgED.jpg" alt="slPgED.jpg" border="0" width="80%"></a></div>采样时常用"重参数"技巧(reparameterization trick)，从分布$N(\mu,\sigma^2)$中采样一个$Z$相当于从$N(0,1)$中采样一个$\epsilon$使得$Z=\mu+\sigma*\epsilon$。#### 图变分自编码器介绍完传统的变分自编码器，接下来就是介绍这篇论文的工作，如何将变分自编码器的思想迁移到图上。针对图这个数据结构，输入的数据变为图的邻接矩阵$A$与特征矩阵$X$：邻接矩阵$A$：<div align="center"><a href="https://imgchr.com/i/slFHhQ" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slFHhQ.jpg" alt="slFHhQ.jpg" border="0" width="60%"></a></div>特征矩阵$X$：<div align="center"><a href="https://imgchr.com/i/slFz7T" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slFz7T.jpg" alt="slFz7T.jpg" border="0" width="60%"></a></div><p>接下来的工作与变分自编码器相同，通过编码器（图卷积）学习图中顶点低维向量表示分布的均值$\mu$与方差$\sigma^2$，再通过解码器生成图。</p><div align="center"><a href="https://imgchr.com/i/slk1gA" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slk1gA.jpg" alt="slk1gA.jpg" border="0" width="80%"></a></div><p>编码器采用两层结构的图卷积网络，第一层产生一个低维的特征矩阵：</p><script type="math/tex; mode=display">\bar{X}=\text{GCN}(X,A)=\text{ReLU}(\tilde{A}XW_0)\\\tilde{A}=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}</script><p>第二层得到分布的均值$\mu$与方差$\sigma^2$：</p><script type="math/tex; mode=display">\mu=\text{GCN}_{\mu}(X,A)=\tilde{A}\bar{X}W_1\\\log\sigma^2=\text{GCN}_{\sigma}(X,A)=\tilde{A}\bar{X}W_1</script><p>将两层网络的表达式合并可以得到编码器的表达式：</p><script type="math/tex; mode=display">\text{GCN}(X,A)=\tilde{A}\text{ReLU}(\tilde{A}XW_0)W_1</script><p>同样地使用重参数技巧来得到低维向量表示$Z=\mu+\sigma*\epsilon$。</p><p>编码器重构出图的邻接矩阵，从而得到一个新的图。之所以使用点积的形式来得到邻接矩阵，原因在于我们希望学习到每个顶点的低维向量表示$z$的相似程度，来更好地重构邻接矩阵。而点积可以计算两个向量之间的cosine相似度，这种距离度量方式不受量纲的影响。因此，重构的邻接矩阵可以学习到各个顶点之间的相似程度。</p><script type="math/tex; mode=display">\hat{A}=\sigma(zz^T)</script><p>损失函数用于衡量生草样本与真是样本之间的差异，但如果只用距离度量作为损失函数，为了让编码器的效果最佳，模型会将方差的值学为0，这样从正态分布中采样出来的就是定值，有利于减小生成样本和真实样本之间的差异。但这样一来，就退化成了普通的自编码器，因此在构建损失函数时，往往还会加入各独立正态分布与标准正态分布的KL散度，来使得各个正态分布逼近标准正态分布：</p><script type="math/tex; mode=display">L=E_{q(Z|X,A)}[\log p(A|Z)]-\text{KL}[q(Z|X,A)||p(Z)],\quad where\quad p(Z)=N(0,1)</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Cora、Citeseer、Pubmed</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;NIPS16一篇将变分自编码器迁移到图结构数据上的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Graph Convolutional Matrix Completion[KDD&#39;18]</title>
    <link href="http://Bithub00.com/2021/01/09/GCMC%5BKDD18%5D/"/>
    <id>http://Bithub00.com/2021/01/09/GCMC[KDD18]/</id>
    <published>2021-01-09T13:17:15.588Z</published>
    <updated>2021-01-09T13:30:55.861Z</updated>
    
    <content type="html"><![CDATA[<p>KDD18一篇将图卷积网络用于矩阵补全问题的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何将图卷积网络应用于矩阵补全问题。</p><p>具体地，这篇论文做的是推荐系统方向下的矩阵补全问题，给定一个评分矩阵，如何根据已有的评分记录来预测用户对其他物品的评分。如果将评分矩阵转换为一张图，转换方法在下面有进行介绍，这时矩阵补全问题也可以看成图上的边预测问题。要预测用户对一个物品的评分，就是预测图上两个对应顶点之间相连的边的权重。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>论文通过一个编码器-解码器的架构来实现从已有评分到特征表示再到预测评分的过程。</p><div align="center"><a href="https://imgchr.com/i/sQUdAS" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQUdAS.png" alt="sQUdAS.png" border="0" width="70%"></a></div><h4 id="Bipartite-Graph-Construction"><a href="#Bipartite-Graph-Construction" class="headerlink" title="Bipartite Graph Construction"></a>Bipartite Graph Construction</h4><p>首先是将推荐任务里的评分数据转化为一张图，具体做法是将用户和物品都看作图中的顶点，交互记录看作边，分数作为边的权重，如图所示：</p><div align="center"><a href="https://imgchr.com/i/su9fr4" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/08/su9fr4.png" alt="su9fr4.png" border="0" width="60%"></a></div><h4 id="Graph-Convolutional-Encoder"><a href="#Graph-Convolutional-Encoder" class="headerlink" title="Graph Convolutional Encoder"></a>Graph Convolutional Encoder</h4><p>上一步所构建的图的输入形式为邻接矩阵$A\in \mathbb{R}^{n\times n}$与图中顶点的特征矩阵$X\in \mathbb{R}^{n\times d}$。编码器在这一步的作用就是得到用户与物品的特征表示$A,X^u,X^v\rightarrow U,V$。</p><p>具体编码时，论文将不同的评分水平分开考虑$r\in \{1,2,3,4,5\}$，我的理解是它们类似于处理图像数据时的多个channel。以一个评分水平$r$为例，说明编码得到特征表示的过程。假设用户$u_i$对电影$v_j$评分为$r$，而这部电影的特征向量为$x_j$，那么这部电影对这个用户特征表示的贡献可以表示为下面的式子(1)，相当于对特征向量进行了一个线性变换。</p><div align="center"><a href="https://imgchr.com/i/sQUHnx" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQUHnx.png" alt="sQUHnx.png" border="0" width="80%"></a></div>对当前评分水平下所有评过分的电影进行求和，再对所有评分水平求和拼接，经过一个非线性变换，就得到了用户$u_i$的特征表示$h_{u_i}$，物品的做法相同。<div align="center"><a href="https://imgchr.com/i/sQdv6A" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQdv6A.png" alt="sQdv6A.png" border="0" width="80%"></a></div><div align="center"><a href="https://imgchr.com/i/sQwmmq" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQwmmq.png" alt="sQwmmq.png" border="0" width="80%"></a></div><h4 id="Bilinear-Decoder"><a href="#Bilinear-Decoder" class="headerlink" title="Bilinear Decoder"></a>Bilinear Decoder</h4><p>在分别得到用户与物品的特征表示$U$与$V$后，解码器计算出用户对物品评分为$r$的概率，再对每个评分的概率进行求和，得到最终预测的评分。</p><script type="math/tex; mode=display">\begin{aligned}(P_r)_{ij}&=\frac{\exp(u_i^TQ_rv_j)}{\sum_{s\in R}\exp(u_i^TQ_sv_j)} \\\hat{M}&=\sum_{r\in R}rP_r\end{aligned}</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Flixster、Douban、YahooMusic、MovieLens</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;KDD18一篇将图卷积网络用于矩阵补全问题的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Graph Neural Networks for Social Recommendation[WWW&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/GraphRec%5BWWW19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/GraphRec[WWW19]/</id>
    <published>2020-12-22T03:22:36.248Z</published>
    <updated>2020-12-22T03:22:36.248Z</updated>
    
    <content type="html"><![CDATA[<p>WWW19将GNN应用于社会化推荐的一篇论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何将GNN应用于社会化推荐任务上。</p><p>面临的挑战有三点：</p><ol><li>在一个社会化推荐任务中，输入的数据包括社会关系图和用户-物品交互图，将两张图的信息都聚合才能得到用户更好的一个表示，而此前的GNN只是在同一张图上对邻域内的信息聚合。</li><li>在用户-物品交互图中，顶点与顶点之间的边也包含更多的信息，除了表示是否交互，还能表示用户对一个物品的偏好（喜爱还是厌恶），而此前的GNN只是将边用来表示是否交互。</li><li>社会关系图中用户之间的纽带有强有弱，显然地，一个用户更可能与强纽带的其它用户有类似的喜好。如果将所有纽带关系都看成一样，会有偏差。</li></ol><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>创新：</p><ul><li>在不同图(user-user graph和user-item graph)上进行信息传递与聚合</li><li>除了捕获user-item间的交互关系，还利用了user对item的评分</li><li>用attention机制表示社交关系的重要性，用户纽带的强与弱</li></ul><div align="center"><a href="https://imgchr.com/i/r0xT1A" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/r0xT1A.png" alt="r0xT1A.png" border="0" width="90%"></a></div><p>整个GraphRec框架由三个部分组成，分别为user modeling、item modeling和rating prediction。其中user modeling用来学习用户的特征表示，学习的方式是两个聚合：item aggregation和social aggregation，类似地item modeling用来学习物品的特征表示，学习的方式是一个聚合：user aggregation。</p><h4 id="User-Modeling"><a href="#User-Modeling" class="headerlink" title="User Modeling"></a>User Modeling</h4><h5 id="item-aggregation"><a href="#item-aggregation" class="headerlink" title="item aggregation"></a>item aggregation</h5><div align="center"><a href="https://imgchr.com/i/rBuFzt" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/rBuFzt.png" alt="rBuFzt.png" border="0" width="40%"></a></div><p>item aggregation的目的是通过用户交互过的物品以及对这些物品的倾向，来学习物品侧的用户特征表示，数学表示为：</p><script type="math/tex; mode=display">h_i^I=\sigma(W·Aggre_{items}(\{x_{ia},\forall a\in C(i)\})+b)</script><p>$C(i)$就表示用户交互过的物品的一个集合。这里的$x_{ia}$是一个表示向量，它应该能够同时表示交互关系和用户倾向。论文中的做法是通过一个MLP来结合物品的embedding和倾向的embedding，两者分别用$q_a$和$e_r$表示。倾向的embedding可能很难理解，以五分制评分为例，倾向的embedding表示为$e_r\in \mathbb{R}^d$，其中$r\in \{1,2,3,4,5\}$。</p><script type="math/tex; mode=display">x_{ia}=g_v([q_a\oplus e_r])</script><p>定义好$x_{ia}$后，下一步就是如何选取聚合函数$Aggre$了。论文中使用的是attention机制，来源于<a href="#Graph Attention Networks[ICLR&#39;18]">GAT</a>：</p><script type="math/tex; mode=display">\begin{aligned}h_i^I&=\sigma(W·\Big\{\sum_{a\in C(i)}\alpha_{ia}x_{ia}\Big\}+b) \\\alpha_{ia}'&=w_2^T·\sigma(W_1·[x_{ia}\oplus p_i]+b_1)+b_2 \\\alpha_{ia}&=\frac{\exp(\alpha_{ia}')}{\sum_{a\in C(i)}\exp(\alpha_{ia}')}\end{aligned}</script><p>这里的权重$\alpha_{ia}$考虑了$x_{ia}$和用户$u_i$的embedding $p_i$，使得权重能够与当前用户相关。</p><h5 id="social-aggregation"><a href="#social-aggregation" class="headerlink" title="social aggregation"></a>social aggregation</h5><div align="center"><a href="https://imgchr.com/i/rBK7g1" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/rBK7g1.png" alt="rBK7g1.png" border="0" width="40%"></a></div><p>social aggregation中，同样地使用了attention机制，通过attention机制来选取强纽带的其它用户（表现为聚合时权重更大）并聚合他们的信息，聚合的就是物品侧的用户特征表示。</p><script type="math/tex; mode=display">\begin{aligned}h_i^S&=\sigma(W·\Big\{\sum_{o\in N(i)}\beta_{io}h_o^I\Big\}+b) \\\beta_{io}'&=w_2^T·\sigma(W_1·[h_o^I\oplus p_i]+b_1)+b_2 \\\beta_{io}&=\frac{\exp(\beta_{io}')}{\sum_{o\in N(i)}\exp(\beta_{io}')}\end{aligned}</script><p>这里跟item aggregation基本一模一样，就不多介绍了。</p><p>得到物品侧的用户特征表示$h_i^I$和社交侧的用户特征表示$h_i^S$后，用一个MLP将它们结合，得到用户最终的特征表示：</p><script type="math/tex; mode=display">\begin{aligned}c_1&=[h_i^I\oplus h_i^S] \\c_2&=\sigma(W_2·c_1+b_2) \\&······ \\h_i&=\sigma(W_l·c_{l-1}+b_l)\end{aligned}</script><h4 id="Item-Modeling"><a href="#Item-Modeling" class="headerlink" title="Item Modeling"></a>Item Modeling</h4><h5 id="user-aggregation"><a href="#user-aggregation" class="headerlink" title="user aggregation"></a>user aggregation</h5><div align="center"><a href="https://imgchr.com/i/rBYtjH" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/rBYtjH.png" alt="rBYtjH.png" border="0" width="50%"></a></div><p>Item modeling与User modeling的做法基本一模一样…公式都是一一对应的：</p><script type="math/tex; mode=display">\begin{aligned}f_{jt}&=g_u([p_t\oplus e_r]) \\z_j&=\sigma(W·\Big\{\sum_{t\in B(j)}\mu_{jt}f_{jt}\Big\}+b) \\\mu_{jt}'&=w_2^T·\sigma(W_1·[f_{jt}\oplus q_j]+b_1)+b_2 \\\mu_{jt}&=\frac{\exp(\mu_{jt}')}{\sum_{a\in C(i)}\exp(\mu_{jt}')}\end{aligned}</script><h4 id="Rating-Prediction"><a href="#Rating-Prediction" class="headerlink" title="Rating Prediction"></a>Rating Prediction</h4><p>最后来到评分预测部分，由上面两个部分我们得到了用户特征表示$h_i$与物品特征表示$z_j$，产生评分用的也是一个MLP：</p><script type="math/tex; mode=display">\begin{aligned}g_1&=[h_i\oplus z_j] \\g_2&=\sigma(W_2·g_1+b_2) \\&······ \\g_{l-1}&=\sigma(W_l·g_{l-1}+b_l) \\r_{ij}&=w^T·g_{l-1}\end{aligned}</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Ciao、Epinions</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;WWW19将GNN应用于社会化推荐的一篇论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Predict then Propagate Graph Neural Networks meet Personalized PageRank[ICLR&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/PPNP%5BICLR19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/PPNP[ICLR19]/</id>
    <published>2020-12-22T03:21:34.349Z</published>
    <updated>2020-12-22T03:21:34.349Z</updated>
    
    <content type="html"><![CDATA[<p>ICLR19将PageRank与GNN结合以解决GCN层数无法加深的一篇论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>GCN层数增加后性能反而变差，如何加深GCN的层数。</p><p>根据GCN的定义，每一层网络用来捕获一跳邻居的信息，例如一个三层的GCN网络捕获的就是一个顶点三跳邻居以内的信息，而现在如果只能用浅层模型，表示只能捕获有限跳内的邻域信息，而有时候要多几跳才能捕获到有用的信息，例如<a href="#Representation Learning on Graphs with Jumping Knowledge Networks[ICML&#39;18]">JK-Net</a>中的例子。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>这一篇论文的工作其实是接着JK-Net继续往下，在那篇论文中，作者分析了GCN中信息传递这个过程与随机漫步之间的关系，论证了当层数加深之后，GCN会收敛到这个随机漫步的极限分布，而这个极限分布只与图的全局属性有关，没有把随机漫步的起始顶点，或者说是GCN中从邻域中传递和聚合信息的根顶点考虑在内，这么一来，层数加深之后每个顶点聚合出来的样子都差不多，无法区分从而导致性能变差，另一个看待的角度是，因为原始GCN是对所有聚合的信息做平均操作，层数加深之后各个顶点的邻域都变得跟整张图差不多，既然每个顶点的邻域都变得差不多，做的又是平均操作，每个顶点聚合出来的样子就会都差不多。</p><p>论文提出的解决办法是引入PageRank的思想，这也是从JK-Net中的结论观察出来的。JK-Net中所说的GCN会收敛到的极限分布的计算方法如下：</p><script type="math/tex; mode=display">\pi_{lim}=\hat{A}\pi_{lim}</script><p>而PageRank的计算方法如下：</p><script type="math/tex; mode=display">\pi_{pr}=A_{rw}\pi_{pr}</script><p>其中$A_{rw}=AD^{-1}$，两个计算方法明显地相似，区别在于，PageRank中邻接矩阵$A$没有考虑根顶点自身，而极限分布的计算里$\hat{A}$是引入了自环的。而Personalized PageRank通过引入自环而考虑了根顶点自身，论文的想法就是将随机漫步的极限分布用Personalized PageRank来代替，它的计算方法为：</p><script type="math/tex; mode=display">\pi_{ppr}(i_x)=(1-\alpha)\hat{A}\pi_{ppr}(i_x)+\alpha i_x \\\rightarrow \pi_{ppr}(i_x)=\alpha\Big(I_n-(1-\alpha)\hat{A}\Big)^{-1}i_x</script><p>其中$i_x$是一个one_hot指示向量，用来从根顶点重新启动。</p><blockquote><p>Personalized PageRank算法的目标是要计算所有节点相对于用户u的相关度。从用户u对应的节点开始游走，每到一个节点都以α的概率停止游走并从u重新开始，或者以1-α的概率继续游走，从当前节点指向的节点中按照均匀分布随机选择一个节点往下游走。这样经过很多轮游走之后，每个顶点被访问到的概率也会收敛趋于稳定，这个时候我们就可以用概率来进行排名了。</p></blockquote><p>相较于原始的GCN模型，现在根顶点$x$对顶点$y$的影响程度$I(x,y)$，变得与$\pi_{ppr}(i_x)$中的第$y$个元素相关，这个影响程度对于每个根顶点都有不同的取值：</p><script type="math/tex; mode=display">\require{cancel}I(x,y)\propto \prod_{ppr}^{(yx)},\prod_{ppr}^{(yx)}=\alpha\Big(I_n-(1-\alpha)\hat{A}\Big)^{-1}\cancel{I_{n}}</script><h4 id="PPNP"><a href="#PPNP" class="headerlink" title="PPNP"></a>PPNP</h4><p>经过上面的铺垫与介绍，论文提出的模型PPNP可以表示为：</p><script type="math/tex; mode=display">Z_{PPNP}=\text{softmax}\Big(\alpha\Big(I_n-(1-\alpha)\hat{A}\Big)^{-1}H\Big),H_{i,:}=f_{\theta}(X_i,:)</script><p>其中$X$为特征矩阵，$f_{\theta}$是一个参数为$\theta$的神经网络，用来产生预测类别$H\in \mathbb{R}^{n\times c}$。</p><div align="center"><a href="https://imgchr.com/i/ravXN9" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/20/ravXN9.png" alt="ravXN9.png" border="0" width="90%"></a></div><p>由公式和图中都可以看到，PPNP其实是由两部分组成，左边的神经网络与右边的信息传递网络，神经网络部分就类似于在<a href="#Semi-Supervised Classification with Graph Convolutional Network [ICLR&#39;17]">GCN</a>中介绍的，输入顶点特征与图的结构信息（邻接矩阵），输出顶点新的特征表示。信息传递网络部分，在PPNP中通过它来得到预测标签，而原始GCN的做法是$Z_{GCN}=\text{softmax}(\hat{A}HW)$，其中$W$是每层网络的参数。</p><h4 id="APPNP"><a href="#APPNP" class="headerlink" title="APPNP"></a>APPNP</h4><p>从前面的构造方式可以看到，矩阵$\prod_{ppr}$将会有$\mathbb{R}^{n\times n}$大小，会带来时间和空间上的复杂度。因此论文提出了一种近似的计算方法APPNP，计算方式如下：</p><script type="math/tex; mode=display">\begin{aligned}Z^{(0)}&=H=f_{\theta}(X) \\Z^{(k+1)}&=(1-\alpha)\hat{A}Z^{(k)}+\alpha H \\Z^{(K)}&=\text{softmax}\Big((1-\alpha)\hat{A}Z^{(K-1)}+\alpha H\Big)\end{aligned}</script><p>其中$K$为信息传递的跳数或者说是随机漫步的步数，$k\in[0,K-2]$，这样一来就不用构造一个$\mathbb{R}^{n\times n}$的矩阵了。（不知道为什么…）  </p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Citeseer、Cora-ML、Pubmed、MS Academic  </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICLR19将PageRank与GNN结合以解决GCN层数无法加深的一篇论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>DeepInf - Social Influence Prediction with Deep Learning[KDD&#39;18]</title>
    <link href="http://Bithub00.com/2020/12/22/DeepInf%5BKDD18%5D/"/>
    <id>http://Bithub00.com/2020/12/22/DeepInf[KDD18]/</id>
    <published>2020-12-22T03:18:21.401Z</published>
    <updated>2020-12-22T03:18:21.401Z</updated>
    
    <content type="html"><![CDATA[<p>KDD18一篇将GNN应用于社交网络中用户影响力预测任务的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何在图结构的社交数据中预测顶点的影响力。</p><p>在图中，给定顶点$v$与它的邻域以及一个时间段，通过对开始时各顶点的状态进行建模，来对结束时顶点$v$的状态进行预测（是否被激活）。</p><h4 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h4><ul><li>邻域：给定图$G=(V,E)$，顶点$v$的邻域定义为$N_v^r=\{u:d(u,v)\le r\}$，是一个顶点集合，不包含顶点$v$自身</li><li>中心网络：由邻域中的顶点及边所组成的网络，以$G_v^r$表示</li><li>用户行为：以$s_v^t$表示，用户对应于图中的顶点，对于一个时刻$t$，如果顶点$v$有产生动作，例如转发、引用等，则$s_v^t=1$</li></ul><p>给定用户$v$的中心网络、邻域中用户的行为集合$S_v^t=\{s_i^t:i\in N_v^r\}$，论文想解决的问题是，在一段时间$Δt$后，对用户$v$的行为的预测：</p><script type="math/tex; mode=display">P(s_v^{t+Δt}|G_v^r,S_v^t)</script><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><p><a href="https://imgchr.com/i/BGDfOO" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/29/BGDfOO.png" alt="BGDfOO.png" border="0"></a></p><p>数据预处理方面，论文通过带重启的随机漫步来为图中的每个顶点$v$获取固定大小$n$的中心网络$G_v^r$，接着使用$\text{DeepWalk}$来得到图中顶点的embedding，最后进行归一化。通过这几个步骤对图中的特征进行提取后，论文还进一步添加了几种人工提取的特征，包括用户是否活跃等等：</p><div align="center"><a href="https://imgchr.com/i/BGyXX6" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/29/BGyXX6.png" alt="BGyXX6.png" border="0" width="70%"></a></div><blockquote><p>摘要里说传统的影响力建模方法都是人工提取图中顶点及结构的特征，论文的出发点就是自动学习这种特征表示，结果在预处理的最后还是添加了几种人工提取的特征，这不是自相矛盾吗？</p></blockquote><p>经过上面的步骤后，最后得到包含所有用户特征的一个特征矩阵$H\in \mathbb{R}^{n\times F}$，每一行$h_i^T$表示一个用户的特征，$F$等同于$\text{DeepWalk}$长度加上人工特征长度。</p><h4 id="影响力计算"><a href="#影响力计算" class="headerlink" title="影响力计算"></a>影响力计算</h4><p>这一步纯粹是在套GAT的框架，没什么可以说的，计算如下：</p><script type="math/tex; mode=display">H'=\text{GAT}(H)=g(A_{\text{GAT}}(G)HW^T+b)\\A_{\text{GAT}}(G)=[a_{ij}]_{n\times n}</script><p>其中$W\in \mathbb{R}^{F’\times F}, b\in \mathbb{R}^{F’}$是模型的参数，$a_{ij}$的计算在GAT论文的笔记中有记录，不再赘述。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>OAG、Digg、Twitter、Weibo</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;KDD18一篇将GNN应用于社交网络中用户影响力预测任务的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>KGAT - Knowledge Graph Attention Network for Recommendation[KDD&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/KGAT%5BKDD19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/KGAT[KDD19]/</id>
    <published>2020-12-22T03:16:39.766Z</published>
    <updated>2020-12-22T03:18:37.048Z</updated>
    
    <content type="html"><![CDATA[<p>KDD19一篇将知识图谱与GNN融合的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在推荐系统中，如何将用户-物品交互信息与物品自身的属性相结合以做出更好的推荐，从另一个角度来说，即如何融合用户-物品交互图与知识图谱</p><div align="center"><a href="https://imgchr.com/i/BnaHGn" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/BnaHGn.png" alt="BnaHGn.png" border="0" width="65%"></a></div><p>以上面的图为例，在电影推荐场景中，用户对应于观众，物品对应于电影，实体Entities可以有多种含义，例如导演、演员、电影类别等，对应的就会有多种关系，对应图中的$r_1-r_4$。对于用户$u_1$，协同过滤更关注于他的相似用户，即同样看过$i_1$的$u_4$与$u_5$；而有监督学习方法例如因子分解机等会更关注物品之间的联系，例如$i_1$与$i_2$同样有着属性$e_1$，但它无法进一步建模更高阶的关系，例如图中黄色圈内的用户$u_2$与$u_3$观看了同一个导演$e_1$的电影$i_2$，而这名导演$e_1$又作为演员参演了灰色圈内的电影$i_3$与$i_4$。图中上半部分对应于用户-物品交互图，下半部分对应于知识图谱。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p><a href="https://imgchr.com/i/BnDu0f" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/BnDu0f.png" alt="BnDu0f.png" border="0"></a></p><h4 id="CKG-Embedding-Layer"><a href="#CKG-Embedding-Layer" class="headerlink" title="CKG Embedding Layer"></a>CKG Embedding Layer</h4><p>知识图谱的一般形式可以表示为三元组的集合$\{(h,r,t)\}$，表示头实体$h$与尾实体$t$之间有关系$r$，例如$\text{(Hugh Jackman,ActorOf,Logan)}$表示狼叔是电影罗根的演员，这是一种主动的关系，自然就有逆向的被动关系。而对于用户-物品交互信息来说，通常的表示形式为一个矩阵$R$，$R_{ui}$表示用户$u$与物品$i$的关系，有交互则值为1，否则为0。因此，为了统一两种表示形式，论文中将用户-物品交互信息同样改成三元组的集合$\text$，这样一来得到的统一后的新图称之为Collaborative Knowledge Graph(CKG)。</p><p>第一个步骤是对CKG做embedding，得到图中顶点和边的向量表示形式。论文使用了知识图谱中常用的一个方法$\text{TransR}$，即对于一个三元组$(h,r,t)$，目标为：</p><script type="math/tex; mode=display">e_h^r+e_r\approx e_t^r</script><p>其中$e_h,e_t\in \mathbb{R}d、e_r\in \mathbb{R}k$分别为$h、t、r$的embedding，而$e_h^r,e_t^r$为$e_h、e_t$在$r$所处空间中的投影，损失函数定义为：</p><script type="math/tex; mode=display">g(h,r,t)=||W_re_h+e_r-W_re_t||^2_2</script><p>值越小说明该三元组在知识图谱中更可能存在，即头实体$h$与尾实体$t$之间更可能有关系$r$。经过这一步骤之后，CKG中所有的顶点及边我们都得到了它们的embedding。</p><h4 id="Attentive-Embedding-Propagation-Layers"><a href="#Attentive-Embedding-Propagation-Layers" class="headerlink" title="Attentive Embedding Propagation Layers"></a>Attentive Embedding Propagation Layers</h4><p>第二个步骤直接用的GCN与GAT的想法，在一层embedding propagation layer中，利用图卷积网络在邻域中进行信息传播，利用注意力机制来衡量邻域中各邻居顶点的重要程度。再通过堆叠$l$层来聚合$l$阶邻居顶点的信息。</p><p>在每一层中，首先将顶点$h$的邻域以向量形式表示，系数$\pi(h,r,t)$还会进行$\text{softmax}$归一化：</p><script type="math/tex; mode=display">\begin{aligned}e_{N_h}&=\sum_{(h,r,t)\in N_h}\pi(h,r,t)e_t \\\pi(h,r,t)&=(W_re_t)^T\text{tanh}\big(W_re_h+e_r\big)\end{aligned}</script><p>通过堆叠$l$层来聚合$l$阶邻居顶点的信息：</p><script type="math/tex; mode=display">\begin{aligned}e_h^{(l)}&=f\big( e_h^{(l-1)},e_{N_h}^{(l-1)} \big) \\&=\text{LeakyReLU}\big( W_1(e_h+e_{N_h})\big)+\text{LeakyReLU}\big( W_2(e_h\odot e_{N_h})\big)\end{aligned}</script><p>论文中所使用的聚合函数$f$在GCN与GraphSage的基础上，还额外地引入了第二项中$e_h$与$e_{N_h}$的交互，这使得聚合的过程对于两者之间的相近程度更为敏感，会在更相似的顶点中传播更多的信息。</p><h4 id="Model-Prediction"><a href="#Model-Prediction" class="headerlink" title="Model Prediction"></a>Model Prediction</h4><p>在得到$L$层embedding propagation layer的表示后，使用JK-Net中的LSTM-attention进行聚合，在通过点积的形式给出预测分数：</p><script type="math/tex; mode=display">e_u^*=\text{LSTM-attention}(e_u^{(0)},e_u^{(L)})\\e_i^*=\text{LSTM-attention()}e_i^{(0)}||\dots||e_i^{(L)}\\\hat{y}(u,i)={e_u^*}^Te_i^*</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Amazon-book、Last-FM、Yelp2018</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;KDD19一篇将知识图谱与GNN融合的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Session-Based Recommendation with Graph Neural Networks[AAAI&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/SRGCN%5BAAAI19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/SRGCN[AAAI19]/</id>
    <published>2020-12-22T03:13:14.168Z</published>
    <updated>2020-12-22T03:13:29.818Z</updated>
    
    <content type="html"><![CDATA[<p>AAAI19一篇将gated GNN应用于序列推荐任务的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在序列推荐任务中，现有的方法很难在每条序列中取得准确的用户embedding，因为得到的序列数据往往是匿名的，且序列中记录的点击数据所透露出来的用户行为信息有限。同时，序列中物品间的关系虽然常被证实有效，但现有的方法往往只考虑一阶的前后连续关系，即对于$a\rightarrow b \rightarrow  c$，只考虑$a\rightarrow b$或者$b\rightarrow c$</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p><a href="https://imgchr.com/i/BF3uuT" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BF3uuT.png" alt="BF3uuT.png" border="0"></a></p><h4 id="Session-Graph-Modeling"><a href="#Session-Graph-Modeling" class="headerlink" title="Session Graph Modeling"></a>Session Graph Modeling</h4><p>将每条序列$s$表示成一个有向图，并对图中的边进行正则化，具体做法为边的出现次数除以边起始顶点的出度。以序列$s=[v_1,v_2,v_3,v_2,v_4]$为例构建一个有向图，得到邻接矩阵：</p><div align="center"><a href="https://imgchr.com/i/BF17nO" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BF17nO.png" alt="BF17nO.png" border="0" width="80%"></a></div><p>上面的邻接矩阵以考虑顶点的出边并以出度正则化，类似地可以考虑顶点的入边并以入度正则化，将得到的两种邻接矩阵进行拼接，得到论文中提到的连接矩阵$A_s\in \mathbb{R}^{n\times 2n}$，其中的一行$A_{s,i:}\in \mathbb{R}^{1\times 2n}$对应于所构建的有向图中的一个顶点$v_{s,i}$：</p><div align="center"><a href="https://imgchr.com/i/BFGCkQ" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BFGCkQ.png" alt="BFGCkQ.png" border="0" width="80%"></a></div><h4 id="Node-Representation-Learning"><a href="#Node-Representation-Learning" class="headerlink" title="Node Representation Learning"></a>Node Representation Learning</h4><p>论文使用gated GNN来学习图中顶点的表示，为了类比地说明各式的具体含义，首先对Gated Recurrent Units（GRU）进行介绍，它是循环神经网络中的一个概念。</p><h5 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h5><p>一个典型的GRU如下所示，输入为上一时刻的隐层表示$H_{t-1}$及当前时刻的表示$X_t$，包含一个重置门Reset Gate和一个更新门Update Gate：</p><div align="center"><a href="https://imgchr.com/i/BFaaAf" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BFaaAf.png" alt="BFaaAf.png" border="0" width="60%"></a></div><p>直观的来说，重置门决定有多少历史信息被保留，而更新门决定利用多少当前时刻$X_t$的信息。给定当前时刻输入$X_t\in \mathbb{R}^{n\times d}$，上一时刻隐层表示$H_{t-1}\in \mathbb{R}^{n\times h}$，重置门与更新门的输出由下式计算得到：</p><script type="math/tex; mode=display">R_t=\sigma(X_tW_{xr}+H_{t-1}W_{hr}+b_r)\\Z_t=\sigma(X_tW_{xz}+H_{t-1}W_{hz}+b_z)</script><p>式中的$W$与$b$分别为权重与偏置参数。</p><h5 id="Reset-Gate"><a href="#Reset-Gate" class="headerlink" title="Reset Gate"></a>Reset Gate</h5><p>传统RNN网络的隐式状态更新公式为：</p><script type="math/tex; mode=display">H_t=\tanh(X_tW_{xh}+H_{t-1}W_{hh}+b_h)</script><p>如果我们需要减少历史信息带来的影响，可以将$H_{t-1}$与$R_t$逐元素相乘。如果$R_t$中的元素接近于1，得到的结果就是传统的RNN，如果$R_t$中的结果接近于0，得到的结果就是以$X_t$作为输入的MLP，计算出来的$\tilde{H_t}$称为候选状态：</p><script type="math/tex; mode=display">\tilde{H_t}=\tanh(X_tW_{xh}+(R_t\odot{H_{t-1}})W_{hh}+b_h)</script><h5 id="Update-Gate"><a href="#Update-Gate" class="headerlink" title="Update Gate"></a>Update Gate</h5><p>更新门决定新的隐式状态$H_t$多大程度上与上一时刻$H_{t-1}$相同，以及重置门得到的候选状态$\tilde{H_t}$中有多少信息可以被利用，如果$Z_t$中的元素接近于1，将主要保留历史信息，当前时刻$X_t$的信息基本被忽略，这相当于跳过了时刻$t$；当$Z_t$中的元素接近于0时，$H_t$将主要由$\tilde{H_t}决定$：</p><script type="math/tex; mode=display">H_t=Z_t\odot H_{t-1}+(1-Z_t)\odot \tilde{H_t}</script><p>介绍完了GRU的基本概念，接下来是论文中的方法，可以类比地进行学习：</p><p><a href="https://imgchr.com/i/BkiNUU" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BkiNUU.png" alt="BkiNUU.png" border="0"></a></p><p>最主要的不同之处在公式$(1)$，它用于在连接矩阵$A_s$的约束下进行不同顶点间的信息传播，具体来说，它提取了邻域的隐向量并将它们作为GNN的输入。</p><h4 id="Session-Representation-Generation"><a href="#Session-Representation-Generation" class="headerlink" title="Session Representation Generation"></a>Session Representation Generation</h4><p>现有的做法都假设每条序列中的用户都有一个独特的隐式表示，而论文中提出的方法不对这个隐式向量做任何假设，相反，它用序列中顶点的表示来作为序列的表示，而顶点的表示正是上一步将所有序列构建的图送入gated GNN学习得到的。给定一个序列$\text{s}=[v_{s,1},v_{s,2},\dots,v_{s,n}]$，这一步的目的是得到它的embedding向量$s\in \mathbb{R}^d$。为了结合用户的长期偏好与当前兴趣，生成的embedding向量也有局部和全局两部分组成。</p><p>局部embedding向量的构造非常简单，就是最后一个点击过的物品的表示，因为最后一个点击过的物品就表明了用户当前的兴趣：</p><script type="math/tex; mode=display">s_l=v_n</script><p>全局embedding向量的构造需要将所有顶点的表示都聚合进来，论文的做法是做一个线性加权，权重使用$\text{soft-attention}$机制来计算得到：</p><script type="math/tex; mode=display">\begin{aligned}s_g&=\sum_{i=1}^{n}\alpha_iv_i\\\alpha_i&=q^T\sigma(W_1v_n+W_2v_i+c)\end{aligned}</script><p>最后使用一个$\text{Linear}$层来将局部与全局embedding向量进行结合得到最终的序列embedding向量：</p><script type="math/tex; mode=display">s_h=W_3[s_l;s_g]</script><h4 id="Making-Recommendation"><a href="#Making-Recommendation" class="headerlink" title="Making Recommendation"></a>Making Recommendation</h4><p>对于一个待推荐物品$v_i\in V$，计算它在序列$s$中作为下一个被点击物品的概率：</p><script type="math/tex; mode=display">\hat{y_i}=\text{softmax}(s_h^Tv_i)</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Yoochoose、Diginetica</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;AAAI19一篇将gated GNN应用于序列推荐任务的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Representation Learning on Graphs with Jumping Knowledge Networks[ICML&#39;18]</title>
    <link href="http://Bithub00.com/2020/12/22/JK-Net%5BICML18%5D/"/>
    <id>http://Bithub00.com/2020/12/22/JK-Net[ICML18]/</id>
    <published>2020-12-22T03:11:56.918Z</published>
    <updated>2020-12-22T03:13:51.003Z</updated>
    
    <content type="html"><![CDATA[<p>ICML18一篇解决GCN层数加深性能反而变差的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>当图卷积网络GCN的层数超过两层时模型的表现会变差，这使得GCN只能作为浅层模型使用，且在对邻域节点的信息进行聚合时，即使同样是采用$k$层网络来聚合$k$跳邻居的信息，有着不同局部结构的顶点获得的信息也可能完全不同，以下图为例：</p><div align="center"><a href="https://imgchr.com/i/BpCLz8" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/20/BpCLz8.jpg" alt="BpCLz8.jpg" border="0" width="70%"></a></div><p>图$(a)$中的顶点位于核心区域，因此采用$4$层网络把几乎整个图的信息都进行聚合了，而不是它的邻域，这会导致过度平滑，而图$(b)$中顶点位于图边缘的一个树状结构中，采取同样的$4$层网络只囊括了一小部分顶点的信息，只有在第$5$层囊括了核心顶点之后才有效地囊括了更多顶点的信息。</p><p>所以，对于处于核心区域的顶点，GCN中每多一层即每多一次卷积操作，节点的表达会更倾向全局，这导致核心区域的很多顶点的表示到最后没有区分性。对于这样的顶点应该减少GCN的层数来让顶点更倾向局部从而在表示上可以区分；而处于边缘的顶点，即使更新多次，聚合的信息也寥寥无几，对于这样的顶点应该增加GCN的层数，来学习到更充分的信息。因此，对于不同的顶点应该选取不同的层数，传统做法对于所有顶点都用一个值会带来偏差。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>理论部分，论文主要讨论的问题是，在一个$k$层的GCN中，顶点$x$对顶点$y$的影响程度，即顶点$x$输入特征的改变，会对顶点$y$在最后一层得到的表示产生多大的变化，也可以说是顶点$y$对于顶点$x$有多敏感。假设输入的特征为$X\in \mathbb{R}^{n\times f}$，输出的预测标签为$Z\in \mathbb{R}^{n\times c}$，其中$n$为图中顶点数目，$c$为类别数目，$f$为特征数目，则这种影响程度可以表示为$I(x,y)=\sum_i\sum_j\frac{\partial Z_{yi}}{\partial X_{xj}}$。</p><p>更特别地，论文证明了这个影响程度与从顶点$x$开始的$k$步随机漫步的分布有关，如果对$k$取极限$k\rightarrow \infty$，则随机漫步的分布会收敛到$P_{lim}(\rightarrow y)$。详细论证过程可见原文。这说明，结果与随机漫步的的起始顶点$x$没有关系，通过这种方法来得到$x$的邻域信息是不适用的。</p><p>另一种说法是，一个$k$层的图卷积网络等同于一个$k$阶的多项式过滤器，其中的系数是预先确定的<a href="https://arxiv.org/abs/2007.02133v1" target="_blank" rel="noopener">SDC</a>。这么一个过滤器与随机漫步类似，最终会收敛到一个静态向量，从而导致过度平滑。</p><p>实践部分，论文提出JK-Net，通过Layer aggregation来让顶点最后的表示自适应地聚合不同层的信息，局部还是全部，让模型自己来学习：</p><div align="center"><a href="https://imgchr.com/i/BpEvLT" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/20/BpEvLT.jpg" alt="BpEvLT.jpg" border="0" width="50%"></a></div><p>论文的重点在于最后的Layer aggregation层，可选的三种操作为：Concat、Max-pooing以及LSTM-attn。</p><ol><li><p>Concat</p><p>将各层的表示直接拼接在一起，送入Linear层。对于小数据集及结构单一的图这种聚合方式会更好，因为它们不需要顶点在聚合邻域的顶点信息时具有什么自适应性。</p></li><li><p>Max-pooling</p><p>选取各层的表示中包含信息量最多的作为顶点的最终表示，在多层结构中，低层聚合更多局部信息，而高层会聚合更多全局信息，因此对于核心区域内的顶点可能会选取高层表示而边缘顶点选取低层表示。</p></li><li><p>LSTM-attention</p><p>对于各层的表示，attention机制通过计算一个系数$s_v^{(l)}$来表示各层表示的重要性，其中$\sum_ls_v^{(l)}=1$，顶点最终的表示就是各层表示的一个加权和：$\sum_ls_v^{(l)}·h_v^{(l)}$。</p><blockquote><p>$s_v^{(l)}$的计算：将$k$层网络各层的表示$h_v^{(1)},\dots,h_v^{(k)}$输入一个双向LSTM中，同时生成各层$l$的前向LSTM与反向LSTM的隐式特征，分别表示为$f_v^{(l)}、b_v^{(l)}$，拼接后将$|f_v^{(l)}||b_v^{(l)}|$送入一个Linear层，将Linear层的结果进行Softmax归一化操作就得到了系数$s_v^{l}$。</p></blockquote></li></ol><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Citeseer、Cora、Reddit、PPI</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICML18一篇解决GCN层数加深性能反而变差的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Graph Attention Networks[ICLR&#39;18]</title>
    <link href="http://Bithub00.com/2020/12/22/GAT%5BICLR18%5D/"/>
    <id>http://Bithub00.com/2020/12/22/GAT[ICLR18]/</id>
    <published>2020-12-22T03:05:16.191Z</published>
    <updated>2020-12-22T03:14:01.743Z</updated>
    
    <content type="html"><![CDATA[<p>ICLR18一篇解决GCN聚合信息时无法区分信息重要性的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何将attention机制应用于图类型的数据上。</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="图卷积"><a href="#图卷积" class="headerlink" title="图卷积"></a>图卷积</h4><div align="center"><img src="https://s1.ax1x.com/2020/10/16/07O1IK.png" alt="1" border="0" width="60%"><img src="https://s1.ax1x.com/2020/10/16/07O8PO.png" alt="2" border="0" width="60%"></div><p>给定一个含$n$个顶点的图，其中顶点的特征构成的集合为$(\overrightarrow{h_1},\overrightarrow{h_2},\dots,\overrightarrow{h_n})$，$\overrightarrow{h_i}\in \mathbb{R}^F$且邻接矩阵为$A$。一个图卷积层根据已有的顶点特征和图的结构来计算一个新的特征集合$(\overrightarrow{h_1’},\overrightarrow{h_2’},\dots,\overrightarrow{h_n’})$，$\overrightarrow{h_i’}\in \mathbb{R}^{F’}$</p><p>每个图卷积层首先会进行特征转换，以特征矩阵$W$表示，$W\in \mathbb{R}^{F’\times F}$它将特征向量线性转换为$\overrightarrow{g_i}=W\overrightarrow{h_i}$，再将新得到的特征向量以某种方式进行结合。为了利用邻域的信息，一种典型的做法如下：</p><script type="math/tex; mode=display">\overrightarrow{h_i}'=\sigma\bigg(\sum_{j\in N_i}\alpha_{ij}\overrightarrow{g_j}\bigg)</script><p>其中$N_i$表示顶点$i$的邻域（典型的构造方式是选取直接相连的顶点，包括自身），$\alpha_{ij}$表示顶点$j$的特征对于顶点$i$的重要程度，也可以看成一种权重。</p><p>现有的做法都是显式地定义$\alpha_{ij}$，本文的创新之处在于使用attention机制隐式地定义$\alpha_{ij}$。所使用的attention机制定义为$a:R^{F’}\times \mathbb{R}^{F’} \rightarrow \mathbb{R}$，以一个权重向量$\overrightarrow{a}\in \mathbb{R}^{2F’}$表示，对应于论文中的self-attention。  </p><h4 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h4><ol><li>基于顶点的特征计算系数$e_{ij}$</li></ol><script type="math/tex; mode=display">e_{ij}=a(W\overrightarrow{h_i},W\overrightarrow{h_j})</script><ol><li>以顶点的邻域将上一步计算得到的系数正则化，这么做能引入图的结构信息：</li></ol><script type="math/tex; mode=display">\begin{aligned}\alpha_{ij}&=\text{softmax}_j(e_{ij})=\frac{\exp(e_{ij})}{\sum_{k\in N_i}\exp(e_{ik})}\\&=\frac{\exp(\text{LeakyReLU}(\overrightarrow{a}^T[W\overrightarrow{h}_i||W\overrightarrow{h}_j]))}{\sum_{k\in N_i}\exp(\text{LeakyReLU}(\overrightarrow{a}^T[W\overrightarrow{h}_i||W\overrightarrow{h}_k]))}\end{aligned}</script><p><img src="https://s1.ax1x.com/2020/10/16/0H5cX6.png" alt="0H5cX6.png" border="0" width="30%"></p><blockquote><p>次序不变性：给定$(i,j),(i,k),(i’,j),(i’,k)$表示两个顶点间的关系，可以为边或自环。$a$为对应的attention系数，如果$a_{ij}&gt;a_{ik}$，则有$a_{i’j}&gt;a_{i’k}$</p></blockquote><p>​    <a href="https://dl.acm.org/doi/10.1145/3219819.3220077" target="_blank" rel="noopener">DeepInf</a>中给出了证明：</p><p>​    将权重向量$\overrightarrow{a}\in \mathbb{R}^{2F’}$重写为$\overrightarrow{a}=[p^T，q^T]$，则有</p><script type="math/tex; mode=display">e_{ij}=\text{LeakyReLU}(p^TWh_i+q^TWh_j)</script><p>​    由softmax与LeakyReLU的单调性可知，因为$a_{ij}&gt;a_{ik}$，有$q^TWh_j&gt;q^TWh_k$，类似地就可以得到$a_{i’j}&gt;a_{i’k}$。</p><p>​    这意味着，即使每个顶点都只关注于自己的邻域，但得到的attention系数却具有全局性。</p><ol><li>以上一步得到的系数$\alpha_{ij}$作为顶点$j$的特征对顶点$i$的重要程度，将领域中各顶点的特征做一个线性组合以作为顶点$i$最终输出的特征表示：</li></ol><script type="math/tex; mode=display">\overrightarrow{h_i'}=\sigma\bigg(\sum_{j\in N_i}\alpha_{ij}W\overrightarrow{h_j}\bigg)</script><h4 id="Multi-head-attention"><a href="#Multi-head-attention" class="headerlink" title="Multi-head attention"></a>Multi-head attention</h4><p>为了稳定self-attention的学习过程，论文引入了multi-head attention，即由$K$个相互独立的self-attention得到各自的特征，再进行拼接：</p><p><img src="https://s1.ax1x.com/2020/10/16/0HbZlj.png" alt="0HbZlj.png" border="0" width="60%"></p><script type="math/tex; mode=display">\overrightarrow{h_i'}=\Vert_{k=1}^K\sigma\bigg(\sum_{j\in N_i}\alpha_{ij}^kW^k\overrightarrow{h_j}\bigg)</script><p>其中$\alpha_{ij}^k$是第$k$个attention机制$(a^k)$计算出来的正则化系数，$W^k$是对应的将输入进行线性转化的权重矩阵。论文选取的拼接操作为求平均：</p><script type="math/tex; mode=display">\overrightarrow{h_i'}=\sigma\bigg(\frac{1}{K}\sum_{k=1}^K\sum_{j\in N_i}\alpha_{ij}^kW^k\overrightarrow{h_j}\bigg)</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Cora、Citeseer、Pubmed、PPI</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICLR18一篇解决GCN聚合信息时无法区分信息重要性的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Learning Convolutional Neural Networks for Graphs[ICML&#39;16]</title>
    <link href="http://Bithub00.com/2020/12/22/Learning-Convolutional-Neural-Networks-for-Graphs%5BICML16%5D/"/>
    <id>http://Bithub00.com/2020/12/22/Learning-Convolutional-Neural-Networks-for-Graphs[ICML16]/</id>
    <published>2020-12-22T03:04:15.061Z</published>
    <updated>2020-12-22T03:14:11.624Z</updated>
    
    <content type="html"><![CDATA[<p>ICML16一篇将CNN应用到图数据上的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>卷积神经网络都是应用在图像数据上，如何将它有效地应用于图类型的数据上。</p><p>对于图像数据，应用一个卷积神经网络可以看成将receptive field（图中为$3\times3$）以固定的步长将图像遍历，因为图像中像素点的排列有一定的次序，receptive field的移动顺序总是从上到下，从左到右。这也唯一地决定了receptive field对一个像素点的遍历方式以及它如何被映射到向量空间中。</p><div align="center"><img src="https://s1.ax1x.com/2020/10/12/0WKA5n.png" alt="0WKA5n.png" border="0" width="65%"></div><p>然而对于图结构数据这种隐式的结构特征很多时候是缺失的，而且当给定不止一张图时，各个图之间的顶点没有必然的联系。因此，在将卷积神经网络应用在图数据上时，需要解决下面两个问题：</p><ol><li><p>决定邻域中顶点的产生次序</p></li><li><p>计算一个将图映射到向量空间的映射方法</p></li></ol><p><img src="https://s1.ax1x.com/2020/10/12/0W1Zo4.png" alt="0W1Zo4.png" border="0" width="80%"></p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>论文提出方法的流程如下：</p><p><img src="https://s1.ax1x.com/2020/10/12/0W3X5Q.png" alt="0W3X5Q.png" border="0" width="60%"></p><h4 id="Node-Sequence-Selection"><a href="#Node-Sequence-Selection" class="headerlink" title="Node Sequence Selection"></a>Node Sequence Selection</h4><p>从图中选取固定数量$w$的顶点，它类比于图像的宽度，而选出的顶点就是卷积操作中小矩形的中心顶点。$w$就是在这个图上所做的卷积操作的个数。如下图所示，$w=6$，代表需要从图中选择6个顶点做卷积操作。论文中选取顶点的方式为$\text{DFS}$，关键点在于图标签函数$l$，这个函数的作用是决定选取顶点的次序，可以选区的函数为between centrality与WL算法等等</p><p><img src="https://s1.ax1x.com/2020/10/12/0WGInP.png" alt="0WGInP.png" border="0"></p><p><img src="https://s1.ax1x.com/2020/10/12/0WyWOU.png" alt="0WyWOU.png" border="0"></p><h4 id="Neighborhood-Assembly"><a href="#Neighborhood-Assembly" class="headerlink" title="Neighborhood Assembly"></a>Neighborhood Assembly</h4><p>选取完顶点后，下一步是为它们构建receptive field，类似于第一张图中的$3\times3$矩阵。选取的方式为，以顶点$v$为中心，通过$\text{BFS}$添加领域顶点，直到满足receptive field长度$k$：</p><div align="center"><img src="https://s1.ax1x.com/2020/10/12/0WDBw9.png" alt="0WDBw9.png" border="0" width="60%"></div><p><img src="https://s1.ax1x.com/2020/10/12/0W6V0g.png" alt="0W6V0g.png" border="0" width="80%"></p><h4 id="Graph-Normalization"><a href="#Graph-Normalization" class="headerlink" title="Graph Normalization"></a>Graph Normalization</h4><p>在选取了满足数量的邻域顶点后，下一步是通过图标签函数$l$为这些顶点赋予一个次序，目的在于将无序的领域映射为一个有序的向量：</p><p><img src="https://s1.ax1x.com/2020/10/12/0Wy1dH.png" alt="0Wy1dH.png" border="0"></p><div align="center"><img src="https://s1.ax1x.com/2020/10/12/0W6rnO.png" alt="0W6rnO.png" border="0" width="60%"></div><h4 id="Convolutional-Architecture"><a href="#Convolutional-Architecture" class="headerlink" title="Convolutional Architecture"></a>Convolutional Architecture</h4><p>最后一步就是应用卷积层提取特征，顶点和边的属性对应于传统图像CNN中的channel：</p><p><img src="https://s1.ax1x.com/2020/10/13/0fpKeK.png" alt="0fpKeK.png" border="0" width="75%"></p><p>假设顶点特征的数目为$a_v$，边的特征个数为$a_e$，$w$为选取的顶点个数，$k$为receptive field中的顶点个数，则对于输入的一系列图中的每一个，可以得到两个张量维度分别为$(w,k,a_v)、(w,k,k,a_e)$，可以变换为$(wk,a_v)、(wk^2,a_e)$，其中$a_v$与$a_e$可以看成是传统图像卷积中channel的个数，对它们做一维的卷积操作，第一个的receptive field的大小为$k$，第二个的receptive field的大小为$k^2$。</p><p><img src="https://s1.ax1x.com/2020/10/13/0fpWwT.png" alt="0fpWwT.png" border="0" width="75%"></p><p>整体卷积结构：</p><p><img src="https://s1.ax1x.com/2020/10/13/0fpbOx.png" alt="0fpbOx.png" border="0" width="75%"></p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>MUTAG、PTC、NCI、D&amp;D</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICML16一篇将CNN应用到图数据上的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Inductive Representation Learning on Large Graphs[NIPS&#39;17]</title>
    <link href="http://Bithub00.com/2020/12/22/GraphSage%5BNIPS17%5D/"/>
    <id>http://Bithub00.com/2020/12/22/GraphSage[NIPS17]/</id>
    <published>2020-12-22T03:03:07.830Z</published>
    <updated>2020-12-22T03:14:22.897Z</updated>
    
    <content type="html"><![CDATA[<p>NIPS17一篇解决GCN不能泛化到未知顶点的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>对于学习图上顶点的embedding，现有的方法多为直推式学习，学习目标是直接生成当前顶点的embedding，不能泛化到未知顶点上</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>论文提出一种归纳式学习方法GrdaphSAGE，不为每个顶点学习单独的embedding，而是学习一种聚合函数$\text{AGGREGATE}$，从一个顶点的局部邻域聚合特征信息，为未知的顶点直接生成embedding，因此旧的顶点只要邻域发生变化也能得到一个新的embedding</p><blockquote><p>GCN不是归纳式，因为每次迭代会用到整个图的邻接矩阵$A$；而GraphSAGE可以对GCN做了精简，每次迭代只抽样取直接相连的邻居</p></blockquote><h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><ol><li>给定顶点$v$及其特征$x_v$,作为它的初始表示$h_v^0=x_v$。</li><li>计算邻域向量$h^k_{N(v)}=\text{AGGREGATE}({h_u^{(k-1)}}, \forall u\in N(v))$，当前层顶点的邻居从上一层采样，且邻居个数固定，非所有邻居，这样每个顶点和采样后邻居的个数都相同，可以直接拼成一个batch送到GPU中进行批训练</li><li>将邻域向量与自身上一层的表示拼接，通过非线性激活函数$\sigma$后作为这一层的表示$h_v^k=\sigma(W^k\text{CONCAT}(h_v^{(k-1)},h^k_{N(v)})$</li><li>标准化 $h_v^k=h_v^k/||h_v^k||_2$</li></ol><p><img src="https://s1.ax1x.com/2020/10/06/0tja9K.png" alt="0tja9K.png" border="0"></p><div align="center"><img src="https://s1.ax1x.com/2020/10/06/0tvRaR.jpg" alt="0tvRaR.jpg" width="50%" border="0"></div><h4 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h4><ol><li>MEAN</li></ol><script type="math/tex; mode=display">h_v^k=\sigma(W·\text{MEAN}(\{h_v^{k-1}\}\cup\{h_u^{k-1},\forall u\in N(v) \})</script><ol><li>LSTM</li><li>Pooling<br>GraphSAGE采用的max-pooling策略能够隐式地选取领域中重要的顶点：</li></ol><script type="math/tex; mode=display">\text{AGGREGATE}_k^{pool}=\text{max}(\{\sigma(W_{pool}h_u^k + b),\forall u\in N(v)\})</script><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>BioGRID、Reddit</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;NIPS17一篇解决GCN不能泛化到未知顶点的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Simplifying Graph Convolutional Networks[PMLR&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/SGCN%5BPMLR19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/SGCN[PMLR19]/</id>
    <published>2020-12-22T03:01:38.585Z</published>
    <updated>2020-12-22T03:14:33.774Z</updated>
    
    <content type="html"><![CDATA[<p>PMLR19一篇简化GCN架构的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>图卷积网络中可能引入了一些不必要的复杂性及冗余的计算</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p><img src="https://s1.ax1x.com/2020/10/04/0JtcnS.png" alt="0JtcnS.png" border="0">  </p><ol><li>移除图卷积网络各层之间的非线性关系，合并各层之间的权重矩阵</li></ol><h4 id="原始图卷积网络"><a href="#原始图卷积网络" class="headerlink" title="原始图卷积网络"></a>原始图卷积网络</h4><p>对于一个输入的图，图卷积网络利用多层网络为每个顶点的特征$x_i$学习一个新的特征表示，随即输入一个线性分类器。对第$k$层网络，输入为$H^{(k-1)}$，输出为$H^{(k)}$，其中$H^{(0)}=X$。一个$K$层的图卷积网络等价于对图中每个顶点的特征向量$x_i$应用一个$K$层感知机，不同之处在于顶点的隐层表示local averaging：</p><script type="math/tex; mode=display">h_i^{(k)}\leftarrow \frac{1}{d_i+1}h_i^{(k-1)}+\sum^n_{j=1}\frac{a_{ij}}{\sqrt{(d_i+1)(d_j+1)}}h_j^{(k-1)}</script><p>矩阵形式：</p><script type="math/tex; mode=display">S=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}</script><p>其中$A=A+I$，则隐层表示用矩阵的形式表示为：</p><script type="math/tex; mode=display">H^{(k)}\leftarrow SH^{(k-1)}</script><p>Local averaging：this step smoothes the hidden representations locally along the edges of the graph and ultimately encourages similar predictions among locally connected nodes  </p><p>$\Theta^{(k)}$为第$K$层网络的权重矩阵：</p><script type="math/tex; mode=display">H^{(k)}\leftarrow \text{ReLU}(H^{(k)}\Theta^{(k)})</script><p>$Y\in \mathbb{R}^{n\times C}$，$y_{ic}$表示第$i$个顶点属于类别$C$的概率</p><script type="math/tex; mode=display">Y_{GCN}=\text{softmax}(SH^{(K-1)}\Theta^{(K)})</script><h4 id="简化图卷积网络"><a href="#简化图卷积网络" class="headerlink" title="简化图卷积网络"></a>简化图卷积网络</h4><blockquote><p>在传统的多层感知机中，多层网络可以提高模型的表现力，是因为这样引入了特征之间的层级关系，例如第二层网络的特征是以第一层网络为基础构建的。而在图卷积网络中，这还有另外一层含义，在每一层中顶点的隐层表示都是以一跳的邻居进行平均，经过$K$层之后，一个顶点就能获得$K$跳邻居的特征信息。这类似于在卷积网路中网络的深度提升了特征的receptive field。</p></blockquote><p>保留local averaging，移除了非线性激活函数：</p><script type="math/tex; mode=display">Y=\text{softmax}(S^KX\Theta^{(1)}\dots \Theta^{(K)})</script><p>其中$S^K$可以预先进行计算，大大减少了模型的训练时间</p><p>论文中证明了简化后的图卷积网络等价于谱空间的一个低通滤波器，它通过的低频信号对应于图中平滑后的特征</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Cora、Citeseer、Pubmed、Reddit</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;PMLR19一篇简化GCN架构的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>LightGCN - Simplifying and Powering Graph Convolution Network for Recommendation[SIGIR&#39;20]</title>
    <link href="http://Bithub00.com/2020/12/22/LightGCN%5BSIGIR20%5D/"/>
    <id>http://Bithub00.com/2020/12/22/LightGCN[SIGIR20]/</id>
    <published>2020-12-22T03:00:34.998Z</published>
    <updated>2020-12-22T03:23:10.944Z</updated>
    
    <content type="html"><![CDATA[<p>SIGIR20一篇简化GCN架构的论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在协同过滤中，图卷积网络中的特征转换与非线性激活对提升模型表现贡献很小，甚至有负面影响。</p><blockquote><p>在半监督顶点分类问题中，每个顶点有充分的语义特征作为输入，例如一篇文章的标题与摘要词，这种情况下加入多层的非线性特征转换能够有助于学习特征。而在协同过滤任务中，每个顶点（用户或商品）没有这么充分的语义特征，因此没有多大的作用。</p></blockquote><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><div align="center"><img src="https://s1.ax1x.com/2020/09/29/0evf4P.png" alt="0evf4P.png" width="80%" border="0"></div><script type="math/tex; mode=display">\hat{y}_{ui}=e_u^Te_i \\e_u=\sum_{k=0}^K\alpha_ke_u^{(k)} \\e_i=\sum_{k=0}^K\alpha_ke_u^{(k)} \\e_u^{(k+1)}=\sum_{i\in N_u}\frac{1}{\sqrt{|N_u||N_i|}}e_i^{(k)} \\e_i^{(k+1)}=\sum_{i\in N_i}\frac{1}{\sqrt{|N_i||N_u|}}e_u^{(k)}</script><ol><li><p>仅考虑图卷积网络中的neighborhood aggregation，通过在用户-物品交互网络中线性传播来学习用户和物品的embedding，再通过加权和将各层学习的embedding作为最后的embedding</p></li><li><p>通过减少不必要的架构，相较于NGCF大大减少了需要训练的参数量。唯一需要训练的模型参数是第0层的embedding，即$e_u^{(0)}$与$e_i^{(0)}$，当它们两个给定后，后续层的embedding可以通过传播规则直接进行计算</p></li></ol><blockquote><p>以加权和的方式结合各层的embedding等价于带自连接的图卷积</p></blockquote><script type="math/tex; mode=display">\begin{aligned}E^{(K)}&=(A+I)E^{(K-1)}=(A+I)^KE^{(0)}\\&=C_K^0E^{(0)}+C_K^1AE^{(0)}+C_K^2A^2E^{(0)}+\dots+C_K^KA^KE^{(0)}\end{aligned}</script><ol><li>模型的可解释性更强，以二层网络为例:</li></ol><script type="math/tex; mode=display">e_u^{(2)}=\sum_{i\in N_u}\frac{1}{\sqrt{|N_u||N_i|}}e_i^{(1)}=\sum_{i\in N_u}\frac{1}{|N_i|}\sum_{v\in N_i}\frac{1}{\sqrt{|N_u||N_v|}}e_v^{(0)}</script><p>如果另一个用户$v$与目标用户$u$有关联，则影响以下面的系数表示：</p><script type="math/tex; mode=display">c_{v\rightarrow u}=\frac{1}{\sqrt{|N_u||N_v|}}\sum_{i\in N_u\cap N_v}\frac{1}{|N_i|}</script><p>可解释为:</p><ul><li>共同交互过的物品越多系数越大 $i\in N_u\cap N_v$</li><li>物品流行度越低系数越大$\frac{1}{|N_i|}$</li><li>用户$v$越不活跃系数越大$\frac{1}{|N_v|}$</li></ul><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Gowalla、Yelp2018、Amazon-Book</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SIGIR20一篇简化GCN架构的论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Neural Graph Collaborative Filtering[SIGIR&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/NGCF%5BSIGIR19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/NGCF[SIGIR19]/</id>
    <published>2020-12-22T02:59:24.118Z</published>
    <updated>2020-12-22T03:19:20.380Z</updated>
    
    <content type="html"><![CDATA[<p>SIGIR19年将神经网络与协同过滤结合的一篇论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在现有的推荐模型中，用户和物品的embedding只考虑了它们自身的特征，没有考虑用户-物品的交互信息</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><script type="math/tex; mode=display">\hat{y}_{NGCF}(u,i)={e^*_u}^Te^*_i \\e^*_u = e_u^{(0)}||\dotsb||e_u^{(L)} \\e^*_i = e_i^{(0)}||\dotsb||e_i^{(L)} \\e_u^{(l)}=LeakyReLU(m^{(l)}_{u\leftarrow u}+\sum_{i\in N_u}m^{(l)}_{u\leftarrow i}) \\\begin{cases}m^{(l)}_{u\leftarrow i}=p_{ui}(W_1^{(l)}e_i^{(l-1)}+W_2^{(l)}(e_i^{(l-1)}\odot e_u^{(l-1)})) \\\\m^{(l)}_{u\leftarrow u}=W_1^{(l)}e_u^{(l-1)}\end{cases} \\m_{u\leftarrow i}=\frac{1}{\sqrt{|N_u||N_i|}}(W_1e_i+W_2(e_i\odot e_u))</script><ol><li>通过堆叠$l$层embedding传播层，一个用户（物品）可以获得它的$l$跳邻居所传播的信息，如下图所示，通过这种方法来建模用户-物品交互信息中的高阶connectivity，下图展示的是一个三阶的例子:</li></ol><div align="center"><img src="https://s1.ax1x.com/2020/09/29/0ZY5mF.jpg" width="400" height="200" alt="0ZY5mF.jpg" border="0"><img src="https://s1.ax1x.com/2020/09/29/0ePimF.png" width="68%" alt="0ePimF.png" border="0"><img src="https://s1.ax1x.com/2020/09/29/0Z2M40.jpg" width="400" height="200" alt="0Z2M40.jpg" border="0"></div><ol><li><p>传统GCN推荐方法中，message embedding只考虑物品embedding$e_i$，论文中将用户embedding与物品embedding的交互也纳入考虑，解释为“This makes the message dependent on the affinity between $e_i$ and $e_u$, e.g., passing more messages from the similar items.”</p></li><li><p>两个层面上的dropout：message &amp; node dropout。前者表示在第$l$层传播层中，只有部分信息会对最后的表示有贡献；后者表示在第$l$层传播层中，随机地丢弃一些顶点。</p></li></ol><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Gowalla、Yelp2018、Amazon-book</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SIGIR19年将神经网络与协同过滤结合的一篇论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Semi-Supervised Classification with Graph Convolutional Network [ICLR&#39;17]</title>
    <link href="http://Bithub00.com/2020/12/22/GCN%5BICLR17%5D/"/>
    <id>http://Bithub00.com/2020/12/22/GCN[ICLR17]/</id>
    <published>2020-12-22T02:57:04.922Z</published>
    <updated>2020-12-22T03:26:43.534Z</updated>
    
    <content type="html"><![CDATA[<p>GCN的原始论文，发表于2017年的ICLR会议</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何将神经网络应用在图结构数据上？</p><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>给定以下输入：  </p><ol><li>图中顶点的特征矩阵$H\in \mathbb{R}^{n\times F}$，其中$n$为顶点数量，$F$为特征数量  </li><li>图的结构信息，如邻接矩阵$A$  </li></ol><p>输出：  </p><ol><li>图中顶点新的的特征表示$H’\in \mathbb{R}^{n\times F’}$，即</li></ol><script type="math/tex; mode=display">H'=\text{GCN(H)}=g(AHW^T+b)</script><p>如果套用神经网络模型，每一层可以用一个非线性函数进行表示：</p><script type="math/tex; mode=display">H^{(l+1)}=f(H^{(l)},A)</script><p>其中$H^{(0)}=X,H^{(L)}=Z$，问题在于如何选取函数$f(.,.)$</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>对于函数$f(.,.)$的选取，论文中提出了一种可能的函数形式：  </p><script type="math/tex; mode=display">f(H^{(l)},A)=\sigma(\hat{D}^{-\frac{1}{2}}\hat{A}\hat{D}^{-\frac{1}{2}}H^{(l)}W^{(l)}) \\</script><p>其中$\hat{A}=A+I$，因为与矩阵$A$相乘表示对于每个顶点，我们对除了自身外所有邻居顶点的特征向量进行求和，因此加上单位矩阵是为了引入自环。而正则化是避免与矩阵$A$相乘改变特征向量的规模。实际在论文中只使用两层网络就达到了很好的效果，表示为：</p><script type="math/tex; mode=display">Z_{\text{GCN}}=\text{softmax}\big(\hat{A'}\text{ReLU}\big(\hat{A'}XW_0\big)W_1\big)</script><p>其中$W_0、W_1$为这两层网络的参数，$\hat{A’}=\hat{D}^{-\frac{1}{2}}\hat{A}\hat{D}^{-\frac{1}{2}}$，$Z\in R\mathbb{R}{n\times c}$为预测的顶点标签，$c$为类别数目，毕竟论文解决的就是一个分类问题。</p><p>更一般地，使用邻域信息的图神经网络形式可以概括为：</p><script type="math/tex; mode=display">h_v^{(l)}=\sigma\bigg(W_l·\text{AGGREGATE}\bigg(\{h_u^{(l-1)},\forall u\in N(v)\} \bigg)\bigg)</script><p>其中$W_l$是第$l$层网络的权重矩阵，$\text{AGGREGATE}$是与特定模型相关的聚合函数，$h_v^{(l)}$是顶点$v$在第$l$层的隐层特征表示。论文中只是用了一个两层网络就达到了很好的效果。</p><p>将论文所提出的函数改写为上述形式，即为：</p><script type="math/tex; mode=display">h_v^{(l)}=\text{ReLU}\Big(W_l·\sum_{u\in N(v)}(deg(v)deg(u))^{-1/2}h_u^{(l-1)}\Big)</script><p>其中$deg(u)$为顶点$u$的度。</p><p><a href="https://papers.nips.cc/paper/2018/file/01eee509ee2f68dc6014898c309e86bf-Paper.pdf" target="_blank" rel="noopener">AS-GCN</a>中对这篇论文的模型形式描述如下：</p><script type="math/tex; mode=display">h_{v_i}^{(l)}=\sigma\Big(W_l·\sum_{j=1}^Na(v_i,u_j)·h_{u_j}^{(l-1)}\Big),i=1,\dots,N</script><p>这里$A=(a(v_i,u_j))\in \mathbb{R}^{N\times N}$对应前面一种写法的正则化邻接矩阵$\hat{A’}$，表面上看对于顶点$v_i$，需要考虑将图中剩下的所有顶点的上一时刻的隐层表示做加权和，来作为它当前时刻的隐层表示，因为$j$的取值范围为$[1,N]$，$N$就是图中顶点的数量。但实际上，大多数顶点因为与$v_i$并无边相连，所以邻接矩阵中对应的值为0，意味着在加权和中的权重为0，相当于加权和时只会考虑有边相连的顶点，这同样是考虑邻域，只不过跟上面那种写法不同。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;GCN的原始论文，发表于2017年的ICLR会议&lt;/p&gt;
    
    </summary>
    
    
      <category term="图神经网络" scheme="http://Bithub00.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Accelerating Exact Inner Product Retrieval by CPU-GPU Systems[SIGIR&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/GPUIR%5BSIGIR19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/GPUIR[SIGIR19]/</id>
    <published>2020-12-22T02:55:32.621Z</published>
    <updated>2020-12-22T03:19:39.414Z</updated>
    
    <content type="html"><![CDATA[<p>SIGIR19年有关GPU加速的一篇论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>FEXIPRO[SIGMOD’17]中的对IPR问题的求解较慢，可以使用GPU进行并行加速。</p><h4 id="IPR问题"><a href="#IPR问题" class="headerlink" title="IPR问题"></a>IPR问题</h4><p>给定一个用户矩阵$Q\in \mathbb{R}^{d\times m}$以及一个物品矩阵$P\in \mathbb{R}^{d\times n}$，对于$Q$中的每一个用户$q$，返回内积$q^TP$中的前k个$q^Tp$对应的物品列表$p$</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="行文逻辑"><a href="#行文逻辑" class="headerlink" title="行文逻辑"></a>行文逻辑</h4><p>作者首先画出四个数据集上，SeqScan与FEXIPRO中两个步骤（内积计算与Top-k物品获取）的运行时间占比，发现内积计算占了总开销的90%以上，促使他提出方法加速这一步骤。接下来介绍GPU加速CPU程序的流程，提出了第一个改进方法，即分batch将矩阵送入GPU并行地计算内积。下一步同样地画出它各个步骤的运行时间占比，发现现在top-k物品的获取以及将内积结果从GPU内存复制到CPU内存这两个步骤变成了时间开销的大头。于是顺着分析结果提出了两个改进方法针对性地减小这两个步骤的时间开销。</p><h4 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h4><p>前后提出了三个改进方法：GPU-IP、GPU-IPR、GPU-IPRO，分别为：<br>GPU-IP：1<br>GPU-IPR：1+2<br>GPU-IRPO：1+2+3</p><ol><li><p>并行计算$Q^TP$，并且提出了一种新的矩阵分割方法以充分利用GPU内存，从而加速内积的计算  </p><blockquote><p>给定GPU内存为$M$，各自选取用户矩阵与物品矩阵的子集$Q_s\in Q,P_s\in P$使得$Size(Q_s^TP_s)\le M$，论文的做法是取$Q_s=Q$，通过$Size(Q^TP_s)=M$来选取$P_s$的大小</p></blockquote></li><li><p>为每一个用户指定最佳的内积数量$g_s$为1024，从这1024个计算结果中返回top-k，减少了待排序的数据规模</p><blockquote><p>内积数量会严重影响下一步的Bitonic排序的性能。选取的依据是它应该满足每一个线程组的共享内存大小因为它会在GPU缓存层级关系中带来最小的缓存访问延迟(The size of $g_s$ should fit in the shared<br>memory of each threads group as it incurs minimum cache access latency in GPU cache hierarchy.)</p></blockquote></li><li><p>提出了一种剪枝方法来提前结束计算进程，减少了许多内积计算<br>假设用户$u$与其第$k$大的物品的内积为$S_k$，且$||q||\cdot||p||\le S_k$，则有  $q^Tp \le ||q||\cdot||p||\le S_k$，因为目的是得到top-k物品，满足上述不等式的物品已经被排除在top-k之外，不需要送入下一次迭代进行内积计算</p><blockquote><p>使用这种剪枝方法后，在四个数据集的前10次迭代中，分别减少了98.88%、76.61%、88.69%以及1.57%的用户数量。</p></blockquote></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SIGIR19年有关GPU加速的一篇论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="数据库" scheme="http://Bithub00.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>ARROW - Approximating Reachability using Random walks Over Web-scale Graphs[ICDE&#39;19]</title>
    <link href="http://Bithub00.com/2020/12/22/ARROW%5BICDE19%5D/"/>
    <id>http://Bithub00.com/2020/12/22/ARROW[ICDE19]/</id>
    <published>2020-12-22T02:54:21.766Z</published>
    <updated>2020-12-22T03:18:45.172Z</updated>
    
    <content type="html"><![CDATA[<p>ICDE19年的一篇论文</p><a id="more"></a><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>给定一个有向图$G=(V,E)$以及一系列顶点对$(u,v)$,判断两个顶点之间是否连通，对应两种查询情况：  </p><ul><li>Chained Queries：查询路径上每条边开始于上一条边结束，并且总时间在规定的范围内</li><li>Snapshot Queries：对于一个动态变化的图，在给定的时间范围内至少在$c$个快闪图中存在连通</li></ul><h3 id="创新之处"><a href="#创新之处" class="headerlink" title="创新之处"></a>创新之处</h3><ol><li>以起始顶点和目的顶点各自进行多次固定长度的随机漫步构建两个集合，两个集合的交集非空说明连通</li><li>对于随机漫步的长度及次数的选取给出了理论证明<br>2.1 随机漫步的长度：有向图中最长的最短路径的长度，通过10次的深度优先搜索得到<br>2.2 随机漫步的次数：类比于扔球问题，给定$n$个篮子和数量相等的红球与蓝球，需要扔多少个球来保证有一个篮子中同时有红球与蓝球的概率高？红球可以看作起始顶点$u$可以到达的顶点，蓝球可以看作目的顶点$v$可以到达的顶点</li><li>模型的一个假设前提是构建的两个反向的随机漫步的平稳分布应尽可能接近，这对应于正向随机漫步选定一个出边的概率与反向随机漫步选定一个入边的概率相等，而这个概率恰等于顶点度的倒数。使用同配性(assortativity)作为这两个平稳分布接近程度的指标。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICDE19年的一篇论文&lt;/p&gt;
    
    </summary>
    
    
      <category term="数据库" scheme="http://Bithub00.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>论文学习</title>
    <link href="http://Bithub00.com/2020/09/25/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/"/>
    <id>http://Bithub00.com/2020/09/25/论文学习/</id>
    <published>2020-09-25T00:27:51.106Z</published>
    <updated>2021-01-10T03:25:51.626Z</updated>
    
    <content type="html"><![CDATA[<p>对看过的论文做一个记录</p><a id="more"></a><h1 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h1><h2 id="ARROW-Approximating-Reachability-using-Random-walks-Over-Web-scale-Graphs-ICDE’19"><a href="#ARROW-Approximating-Reachability-using-Random-walks-Over-Web-scale-Graphs-ICDE’19" class="headerlink" title="ARROW: Approximating Reachability using Random walks Over Web-scale Graphs[ICDE’19]"></a>ARROW: Approximating Reachability using Random walks Over Web-scale Graphs[ICDE’19]</h2><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>给定一个有向图$G=(V,E)$以及一系列顶点对$(u,v)$,判断两个顶点之间是否连通，对应两种查询情况：  </p><ul><li>Chained Queries：查询路径上每条边开始于上一条边结束，并且总时间在规定的范围内</li><li>Snapshot Queries：对于一个动态变化的图，在给定的时间范围内至少在$c$个快闪图中存在连通</li></ul><h3 id="创新之处"><a href="#创新之处" class="headerlink" title="创新之处"></a>创新之处</h3><ol><li>以起始顶点和目的顶点各自进行多次固定长度的随机漫步构建两个集合，两个集合的交集非空说明连通</li><li>对于随机漫步的长度及次数的选取给出了理论证明<br> 2.1 随机漫步的长度：有向图中最长的最短路径的长度，通过10次的深度优先搜索得到<br> 2.2 随机漫步的次数：类比于扔球问题，给定$n$个篮子和数量相等的红球与蓝球，需要扔多少个球来保证有一个篮子中同时有红球与蓝球的概率高？红球可以看作起始顶点$u$可以到达的顶点，蓝球可以看作目的顶点$v$可以到达的顶点</li><li>模型的一个假设前提是构建的两个反向的随机漫步的平稳分布应尽可能接近，这对应于正向随机漫步选定一个出边的概率与反向随机漫步选定一个入边的概率相等，而这个概率恰等于顶点度的倒数。使用同配性(assortativity)作为这两个平稳分布接近程度的指标。</li></ol><h2 id="Accelerating-Exact-Inner-Product-Retrieval-by-CPU-GPU-Systems-SIGIR’19"><a href="#Accelerating-Exact-Inner-Product-Retrieval-by-CPU-GPU-Systems-SIGIR’19" class="headerlink" title="Accelerating Exact Inner Product Retrieval by CPU-GPU Systems[SIGIR’19]"></a>Accelerating Exact Inner Product Retrieval by CPU-GPU Systems[SIGIR’19]</h2><h3 id="解决的问题-1"><a href="#解决的问题-1" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>FEXIPRO[SIGMOD’17]中的对IPR问题的求解较慢，可以使用GPU进行并行加速。</p><h4 id="IPR问题"><a href="#IPR问题" class="headerlink" title="IPR问题"></a>IPR问题</h4><p>给定一个用户矩阵$Q\in \mathbb{R}^{d\times m}$以及一个物品矩阵$P\in \mathbb{R}^{d\times n}$，对于$Q$中的每一个用户$q$，返回内积$q^TP$中的前k个$q^Tp$对应的物品列表$p$</p><h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="行文逻辑"><a href="#行文逻辑" class="headerlink" title="行文逻辑"></a>行文逻辑</h4><p>作者首先画出四个数据集上，SeqScan与FEXIPRO中两个步骤（内积计算与Top-k物品获取）的运行时间占比，发现内积计算占了总开销的90%以上，促使他提出方法加速这一步骤。接下来介绍GPU加速CPU程序的流程，提出了第一个改进方法，即分batch将矩阵送入GPU并行地计算内积。下一步同样地画出它各个步骤的运行时间占比，发现现在top-k物品的获取以及将内积结果从GPU内存复制到CPU内存这两个步骤变成了时间开销的大头。于是顺着分析结果提出了两个改进方法针对性地减小这两个步骤的时间开销。</p><h4 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h4><p>前后提出了三个改进方法：GPU-IP、GPU-IPR、GPU-IPRO，分别为：<br>GPU-IP：1<br>GPU-IPR：1+2<br>GPU-IRPO：1+2+3</p><ol><li><p>并行计算$Q^TP$，并且提出了一种新的矩阵分割方法以充分利用GPU内存，从而加速内积的计算  </p><blockquote><p>给定GPU内存为$M$，各自选取用户矩阵与物品矩阵的子集$Q_s\in Q,P_s\in P$使得$Size(Q_s^TP_s)\le M$，论文的做法是取$Q_s=Q$，通过$Size(Q^TP_s)=M$来选取$P_s$的大小</p></blockquote></li><li>为每一个用户指定最佳的内积数量$g_s$为1024，从这1024个计算结果中返回top-k，减少了待排序的数据规模<blockquote><p>内积数量会严重影响下一步的Bitonic排序的性能。选取的依据是它应该满足每一个线程组的共享内存大小因为它会在GPU缓存层级关系中带来最小的缓存访问延迟(The size of $g_s$ should fit in the shared<br>memory of each threads group as it incurs minimum cache access latency in GPU cache hierarchy.)</p></blockquote></li><li><p>提出了一种剪枝方法来提前结束计算进程，减少了许多内积计算<br>假设用户$u$与其第$k$大的物品的内积为$S_k$，且$||q||\cdot||p||\le S_k$，则有  $q^Tp \le ||q||\cdot||p||\le S_k$，因为目的是得到top-k物品，满足上述不等式的物品已经被排除在top-k之外，不需要送入下一次迭代进行内积计算</p><blockquote><p>使用这种剪枝方法后，在四个数据集的前10次迭代中，分别减少了98.88%、76.61%、88.69%以及1.57%的用户数量。</p></blockquote></li></ol><h1 id="图神经网络"><a href="#图神经网络" class="headerlink" title="图神经网络"></a>图神经网络</h1><h2 id="Semi-Supervised-Classification-with-Graph-Convolutional-Network-ICLR’17"><a href="#Semi-Supervised-Classification-with-Graph-Convolutional-Network-ICLR’17" class="headerlink" title="Semi-Supervised Classification with Graph Convolutional Network [ICLR’17]"></a>Semi-Supervised Classification with Graph Convolutional Network [ICLR’17]</h2><h3 id="解决的问题-2"><a href="#解决的问题-2" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何将神经网络应用在图结构数据上？</p><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>给定以下输入：  </p><ol><li>图中顶点的特征矩阵$H\in \mathbb{R}^{n\times F}$，其中$n$为顶点数量，$F$为特征数量  </li><li>图的结构信息，如邻接矩阵$A$  </li></ol><p>输出：  </p><ol><li>图中顶点新的的特征表示$H’\in \mathbb{R}^{n\times F’}$，即</li></ol><script type="math/tex; mode=display">H'=\text{GCN(H)}=g(AHW^T+b)</script><p>如果套用神经网络模型，每一层可以用一个非线性函数进行表示：</p><script type="math/tex; mode=display">H^{(l+1)}=f(H^{(l)},A)</script><p>其中$H^{(0)}=X,H^{(L)}=Z$，问题在于如何选取函数$f(.,.)$</p><h3 id="做法及创新-1"><a href="#做法及创新-1" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>对于函数$f(.,.)$的选取，论文中提出了一种可能的函数形式：  </p><script type="math/tex; mode=display">f(H^{(l)},A)=\sigma(\hat{D}^{-\frac{1}{2}}\hat{A}\hat{D}^{-\frac{1}{2}}H^{(l)}W^{(l)}) \\</script><p>其中$\hat{A}=A+I$，因为与矩阵$A$相乘表示对于每个顶点，我们对除了自身外所有邻居顶点的特征向量进行求和，因此加上单位矩阵是为了引入自环。而正则化是避免与矩阵$A$相乘改变特征向量的规模。实际在论文中只使用两层网络就达到了很好的效果，表示为：</p><script type="math/tex; mode=display">Z_{\text{GCN}}=\text{softmax}\big(\hat{A'}\text{ReLU}\big(\hat{A'}XW_0\big)W_1\big)</script><p>其中$W_0、W_1$为这两层网络的参数，$\hat{A’}=\hat{D}^{-\frac{1}{2}}\hat{A}\hat{D}^{-\frac{1}{2}}$，$Z\in R\mathbb{R}{n\times c}$为预测的顶点标签，$c$为类别数目，毕竟论文解决的就是一个分类问题。</p><p>更一般地，使用邻域信息的图神经网络形式可以概括为：</p><script type="math/tex; mode=display">h_v^{(l)}=\sigma\bigg(W_l·\text{AGGREGATE}\bigg(\{h_u^{(l-1)},\forall u\in N(v)\} \bigg)\bigg)</script><p>其中$W_l$是第$l$层网络的权重矩阵，$\text{AGGREGATE}$是与特定模型相关的聚合函数，$h_v^{(l)}$是顶点$v$在第$l$层的隐层特征表示。论文中只是用了一个两层网络就达到了很好的效果。</p><p>将论文所提出的函数改写为上述形式，即为：</p><script type="math/tex; mode=display">h_v^{(l)}=\text{ReLU}\Big(W_l·\sum_{u\in N(v)}(deg(v)deg(u))^{-1/2}h_u^{(l-1)}\Big)</script><p>其中$deg(u)$为顶点$u$的度。</p><p><a href="https://papers.nips.cc/paper/2018/file/01eee509ee2f68dc6014898c309e86bf-Paper.pdf" target="_blank" rel="noopener">AS-GCN</a>中对这篇论文的模型形式描述如下：</p><script type="math/tex; mode=display">h_{v_i}^{(l)}=\sigma\Big(W_l·\sum_{j=1}^Na(v_i,u_j)·h_{u_j}^{(l-1)}\Big),i=1,\dots,N</script><p>这里$A=(a(v_i,u_j))\in \mathbb{R}^{N\times N}$对应前面一种写法的正则化邻接矩阵$\hat{A’}$，表面上看对于顶点$v_i$，需要考虑将图中剩下的所有顶点的上一时刻的隐层表示做加权和，来作为它当前时刻的隐层表示，因为$j$的取值范围为$[1,N]$，$N$就是图中顶点的数量。但实际上，大多数顶点因为与$v_i$并无边相连，所以邻接矩阵中对应的值为0，意味着在加权和中的权重为0，相当于加权和时只会考虑有边相连的顶点，这同样是考虑邻域，只不过跟上面那种写法不同。</p><h2 id="Neural-Graph-Collaborative-Filtering-SIGIR’19"><a href="#Neural-Graph-Collaborative-Filtering-SIGIR’19" class="headerlink" title="Neural Graph Collaborative Filtering[SIGIR’19]"></a>Neural Graph Collaborative Filtering[SIGIR’19]</h2><h3 id="解决的问题-3"><a href="#解决的问题-3" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在现有的推荐模型中，用户和物品的embedding只考虑了它们自身的特征，没有考虑用户-物品的交互信息</p><h3 id="做法及创新-2"><a href="#做法及创新-2" class="headerlink" title="做法及创新"></a>做法及创新</h3><script type="math/tex; mode=display">\hat{y}_{NGCF}(u,i)={e^*_u}^Te^*_i \\e^*_u = e_u^{(0)}||\dotsb||e_u^{(L)} \\e^*_i = e_i^{(0)}||\dotsb||e_i^{(L)} \\e_u^{(l)}=LeakyReLU(m^{(l)}_{u\leftarrow u}+\sum_{i\in N_u}m^{(l)}_{u\leftarrow i}) \\\begin{cases}m^{(l)}_{u\leftarrow i}=p_{ui}(W_1^{(l)}e_i^{(l-1)}+W_2^{(l)}(e_i^{(l-1)}\odot e_u^{(l-1)})) \\\\m^{(l)}_{u\leftarrow u}=W_1^{(l)}e_u^{(l-1)}\end{cases} \\m_{u\leftarrow i}=\frac{1}{\sqrt{|N_u||N_i|}}(W_1e_i+W_2(e_i\odot e_u))</script><ol><li><p>通过堆叠$l$层embedding传播层，一个用户（物品）可以获得它的$l$跳邻居所传播的信息，如下图所示，通过这种方法来建模用户-物品交互信息中的高阶connectivity，下图展示的是一个三阶的例子:</p><div align="center"><img src="https://s1.ax1x.com/2020/09/29/0ZY5mF.jpg" width="400" height="200" alt="0ZY5mF.jpg" border="0"><img src="https://s1.ax1x.com/2020/09/29/0ePimF.png" width="68%" alt="0ePimF.png" border="0"><img src="https://s1.ax1x.com/2020/09/29/0Z2M40.jpg" width="400" height="200" alt="0Z2M40.jpg" border="0"></div></li><li><p>传统GCN推荐方法中，message embedding只考虑物品embedding$e_i$，论文中将用户embedding与物品embedding的交互也纳入考虑，解释为“This makes the message dependent on the affinity between $e_i$ and $e_u$, e.g., passing more messages from the similar items.”</p></li><li><p>两个层面上的dropout：message &amp; node dropout。前者表示在第$l$层传播层中，只有部分信息会对最后的表示有贡献；后者表示在第$l$层传播层中，随机地丢弃一些顶点。</p></li></ol><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Gowalla、Yelp2018、Amazon-book</p><h2 id="LightGCN-Simplifying-and-Powering-Graph-Convolution-Network-for-Recommendation-SIGIR’20"><a href="#LightGCN-Simplifying-and-Powering-Graph-Convolution-Network-for-Recommendation-SIGIR’20" class="headerlink" title="LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation[SIGIR’20]"></a>LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation[SIGIR’20]</h2><h3 id="解决的问题-4"><a href="#解决的问题-4" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在协同过滤中，图卷积网络中的特征转换与非线性激活对提升模型表现贡献很小，甚至有负面影响。</p><blockquote><p>在半监督顶点分类问题中，每个顶点有充分的语义特征作为输入，例如一篇文章的标题与摘要词，这种情况下加入多层的非线性特征转换能够有助于学习特征。而在协同过滤任务中，每个顶点（用户或商品）没有这么充分的语义特征，因此没有多大的作用。</p></blockquote><h3 id="做法及创新-3"><a href="#做法及创新-3" class="headerlink" title="做法及创新"></a>做法及创新</h3><div align="center"><img src="https://s1.ax1x.com/2020/09/29/0evf4P.png" alt="0evf4P.png" width="80%" border="0"></div><script type="math/tex; mode=display">\hat{y}_{ui}=e_u^Te_i \\e_u=\sum_{k=0}^K\alpha_ke_u^{(k)} \\e_i=\sum_{k=0}^K\alpha_ke_u^{(k)} \\e_u^{(k+1)}=\sum_{i\in N_u}\frac{1}{\sqrt{|N_u||N_i|}}e_i^{(k)} \\e_i^{(k+1)}=\sum_{i\in N_i}\frac{1}{\sqrt{|N_i||N_u|}}e_u^{(k)}</script><ol><li><p>仅考虑图卷积网络中的neighborhood aggregation，通过在用户-物品交互网络中线性传播来学习用户和物品的embedding，再通过加权和将各层学习的embedding作为最后的embedding</p></li><li><p>通过减少不必要的架构，相较于NGCF大大减少了需要训练的参数量。唯一需要训练的模型参数是第0层的embedding，即$e_u^{(0)}$与$e_i^{(0)}$，当它们两个给定后，后续层的embedding可以通过传播规则直接进行计算</p><blockquote><p>以加权和的方式结合各层的embedding等价于带自连接的图卷积</p></blockquote></li></ol><script type="math/tex; mode=display">\begin{aligned}E^{(K)}&=(A+I)E^{(K-1)}=(A+I)^KE^{(0)}\\&=C_K^0E^{(0)}+C_K^1AE^{(0)}+C_K^2A^2E^{(0)}+\dots+C_K^KA^KE^{(0)}\end{aligned}</script><ol><li>模型的可解释性更强，以二层网络为例:</li></ol><script type="math/tex; mode=display">e_u^{(2)}=\sum_{i\in N_u}\frac{1}{\sqrt{|N_u||N_i|}}e_i^{(1)}=\sum_{i\in N_u}\frac{1}{|N_i|}\sum_{v\in N_i}\frac{1}{\sqrt{|N_u||N_v|}}e_v^{(0)}</script><p>如果另一个用户$v$与目标用户$u$有关联，则影响以下面的系数表示：</p><script type="math/tex; mode=display">c_{v\rightarrow u}=\frac{1}{\sqrt{|N_u||N_v|}}\sum_{i\in N_u\cap N_v}\frac{1}{|N_i|}</script><p>可解释为:</p><ul><li>共同交互过的物品越多系数越大 $i\in N_u\cap N_v$</li><li>物品流行度越低系数越大$\frac{1}{|N_i|}$</li><li>用户$v$越不活跃系数越大$\frac{1}{|N_v|}$</li></ul><h3 id="数据集-1"><a href="#数据集-1" class="headerlink" title="数据集"></a>数据集</h3><p>Gowalla、Yelp2018、Amazon-Book</p><h2 id="Simplifying-Graph-Convolutional-Networks-PMLR’19"><a href="#Simplifying-Graph-Convolutional-Networks-PMLR’19" class="headerlink" title="Simplifying Graph Convolutional Networks[PMLR’19]"></a>Simplifying Graph Convolutional Networks[PMLR’19]</h2><h3 id="解决的问题-5"><a href="#解决的问题-5" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>图卷积网络中可能引入了一些不必要的复杂性及冗余的计算</p><h3 id="做法及创新-4"><a href="#做法及创新-4" class="headerlink" title="做法及创新"></a>做法及创新</h3><p><img src="https://s1.ax1x.com/2020/10/04/0JtcnS.png" alt="0JtcnS.png" border="0">  </p><ol><li>移除图卷积网络各层之间的非线性关系，合并各层之间的权重矩阵</li></ol><h4 id="原始图卷积网络"><a href="#原始图卷积网络" class="headerlink" title="原始图卷积网络"></a>原始图卷积网络</h4><p>对于一个输入的图，图卷积网络利用多层网络为每个顶点的特征$x_i$学习一个新的特征表示，随即输入一个线性分类器。对第$k$层网络，输入为$H^{(k-1)}$，输出为$H^{(k)}$，其中$H^{(0)}=X$。一个$K$层的图卷积网络等价于对图中每个顶点的特征向量$x_i$应用一个$K$层感知机，不同之处在于顶点的隐层表示local averaging：</p><script type="math/tex; mode=display">h_i^{(k)}\leftarrow \frac{1}{d_i+1}h_i^{(k-1)}+\sum^n_{j=1}\frac{a_{ij}}{\sqrt{(d_i+1)(d_j+1)}}h_j^{(k-1)}</script><p>矩阵形式：</p><script type="math/tex; mode=display">S=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}</script><p>其中$A=A+I$，则隐层表示用矩阵的形式表示为：</p><script type="math/tex; mode=display">H^{(k)}\leftarrow SH^{(k-1)}</script><p>Local averaging：this step smoothes the hidden representations locally along the edges of the graph and ultimately encourages similar predictions among locally connected nodes  </p><p>$\Theta^{(k)}$为第$K$层网络的权重矩阵：</p><script type="math/tex; mode=display">H^{(k)}\leftarrow \text{ReLU}(H^{(k)}\Theta^{(k)})</script><p>$Y\in \mathbb{R}^{n\times C}$，$y_{ic}$表示第$i$个顶点属于类别$C$的概率</p><script type="math/tex; mode=display">Y_{GCN}=\text{softmax}(SH^{(K-1)}\Theta^{(K)})</script><h4 id="简化图卷积网络"><a href="#简化图卷积网络" class="headerlink" title="简化图卷积网络"></a>简化图卷积网络</h4><blockquote><p>在传统的多层感知机中，多层网络可以提高模型的表现力，是因为这样引入了特征之间的层级关系，例如第二层网络的特征是以第一层网络为基础构建的。而在图卷积网络中，这还有另外一层含义，在每一层中顶点的隐层表示都是以一跳的邻居进行平均，经过$K$层之后，一个顶点就能获得$K$跳邻居的特征信息。这类似于在卷积网路中网络的深度提升了特征的receptive field。</p></blockquote><p>保留local averaging，移除了非线性激活函数：</p><script type="math/tex; mode=display">Y=\text{softmax}(S^KX\Theta^{(1)}\dots \Theta^{(K)})</script><p>其中$S^K$可以预先进行计算，大大减少了模型的训练时间</p><p>论文中证明了简化后的图卷积网络等价于谱空间的一个低通滤波器，它通过的低频信号对应于图中平滑后的特征</p><h3 id="数据集-2"><a href="#数据集-2" class="headerlink" title="数据集"></a>数据集</h3><p>Cora、Citeseer、Pubmed、Reddit</p><h2 id="Inductive-Representation-Learning-on-Large-Graphs-NIPS’17"><a href="#Inductive-Representation-Learning-on-Large-Graphs-NIPS’17" class="headerlink" title="Inductive Representation Learning on Large Graphs[NIPS’17]"></a>Inductive Representation Learning on Large Graphs[NIPS’17]</h2><h3 id="解决的问题-6"><a href="#解决的问题-6" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>对于学习图上顶点的embedding，现有的方法多为直推式学习，学习目标是直接生成当前顶点的embedding，不能泛化到未知顶点上</p><h3 id="做法及创新-5"><a href="#做法及创新-5" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>论文提出一种归纳式学习方法GrdaphSAGE，不为每个顶点学习单独的embedding，而是学习一种聚合函数$\text{AGGREGATE}$，从一个顶点的局部邻域聚合特征信息，为未知的顶点直接生成embedding，因此旧的顶点只要邻域发生变化也能得到一个新的embedding</p><blockquote><p>GCN不是归纳式，因为每次迭代会用到整个图的邻接矩阵$A$；而GraphSAGE可以对GCN做了精简，每次迭代只抽样取直接相连的邻居</p></blockquote><h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><ol><li>给定顶点$v$及其特征$x_v$,作为它的初始表示$h_v^0=x_v$。</li><li>计算邻域向量$h^k_{N(v)}=\text{AGGREGATE}({h_u^{(k-1)}}, \forall u\in N(v))$，当前层顶点的邻居从上一层采样，且邻居个数固定，非所有邻居，这样每个顶点和采样后邻居的个数都相同，可以直接拼成一个batch送到GPU中进行批训练</li><li>将邻域向量与自身上一层的表示拼接，通过非线性激活函数$\sigma$后作为这一层的表示$h_v^k=\sigma(W^k\text{CONCAT}(h_v^{(k-1)},h^k_{N(v)})$</li><li>标准化 $h_v^k=h_v^k/||h_v^k||_2$</li></ol><p><img src="https://s1.ax1x.com/2020/10/06/0tja9K.png" alt="0tja9K.png" border="0"></p><div align="center"><img src="https://s1.ax1x.com/2020/10/06/0tvRaR.jpg" alt="0tvRaR.jpg" width="50%" border="0"></div><h4 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h4><ol><li>MEAN</li></ol><script type="math/tex; mode=display">h_v^k=\sigma(W·\text{MEAN}(\{h_v^{k-1}\}\cup\{h_u^{k-1},\forall u\in N(v) \})</script><ol><li>LSTM</li><li>Pooling<br>GraphSAGE采用的max-pooling策略能够隐式地选取领域中重要的顶点：</li></ol><script type="math/tex; mode=display">\text{AGGREGATE}_k^{pool}=\text{max}(\{\sigma(W_{pool}h_u^k + b),\forall u\in N(v)\})</script><h3 id="数据集-3"><a href="#数据集-3" class="headerlink" title="数据集"></a>数据集</h3><p>BioGRID、Reddit</p><h2 id="Learning-Convolutional-Neural-Networks-for-Graphs-ICML’16"><a href="#Learning-Convolutional-Neural-Networks-for-Graphs-ICML’16" class="headerlink" title="Learning Convolutional Neural Networks for Graphs[ICML’16]"></a>Learning Convolutional Neural Networks for Graphs[ICML’16]</h2><h3 id="解决的问题-7"><a href="#解决的问题-7" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>卷积神经网络都是应用在图像数据上，如何将它有效地应用于图类型的数据上。</p><p>对于图像数据，应用一个卷积神经网络可以看成将receptive field（图中为$3\times3$）以固定的步长将图像遍历，因为图像中像素点的排列有一定的次序，receptive field的移动顺序总是从上到下，从左到右。这也唯一地决定了receptive field对一个像素点的遍历方式以及它如何被映射到向量空间中。</p><div align="center"><img src="https://s1.ax1x.com/2020/10/12/0WKA5n.png" alt="0WKA5n.png" border="0" width="65%"></div><p>然而对于图结构数据这种隐式的结构特征很多时候是缺失的，而且当给定不止一张图时，各个图之间的顶点没有必然的联系。因此，在将卷积神经网络应用在图数据上时，需要解决下面两个问题：</p><ol><li><p>决定邻域中顶点的产生次序</p></li><li><p>计算一个将图映射到向量空间的映射方法</p></li></ol><p><img src="https://s1.ax1x.com/2020/10/12/0W1Zo4.png" alt="0W1Zo4.png" border="0" width="80%"></p><h3 id="做法及创新-6"><a href="#做法及创新-6" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>论文提出方法的流程如下：</p><p><img src="https://s1.ax1x.com/2020/10/12/0W3X5Q.png" alt="0W3X5Q.png" border="0" width="60%"></p><h4 id="Node-Sequence-Selection"><a href="#Node-Sequence-Selection" class="headerlink" title="Node Sequence Selection"></a>Node Sequence Selection</h4><p>从图中选取固定数量$w$的顶点，它类比于图像的宽度，而选出的顶点就是卷积操作中小矩形的中心顶点。$w$就是在这个图上所做的卷积操作的个数。如下图所示，$w=6$，代表需要从图中选择6个顶点做卷积操作。论文中选取顶点的方式为$\text{DFS}$，关键点在于图标签函数$l$，这个函数的作用是决定选取顶点的次序，可以选区的函数为between centrality与WL算法等等</p><p><img src="https://s1.ax1x.com/2020/10/12/0WGInP.png" alt="0WGInP.png" border="0"></p><p><img src="https://s1.ax1x.com/2020/10/12/0WyWOU.png" alt="0WyWOU.png" border="0"></p><h4 id="Neighborhood-Assembly"><a href="#Neighborhood-Assembly" class="headerlink" title="Neighborhood Assembly"></a>Neighborhood Assembly</h4><p>选取完顶点后，下一步是为它们构建receptive field，类似于第一张图中的$3\times3$矩阵。选取的方式为，以顶点$v$为中心，通过$\text{BFS}$添加领域顶点，直到满足receptive field长度$k$：</p><div align="center"><img src="https://s1.ax1x.com/2020/10/12/0WDBw9.png" alt="0WDBw9.png" border="0" width="60%"></div><p><img src="https://s1.ax1x.com/2020/10/12/0W6V0g.png" alt="0W6V0g.png" border="0" width="80%"></p><h4 id="Graph-Normalization"><a href="#Graph-Normalization" class="headerlink" title="Graph Normalization"></a>Graph Normalization</h4><p>在选取了满足数量的邻域顶点后，下一步是通过图标签函数$l$为这些顶点赋予一个次序，目的在于将无序的领域映射为一个有序的向量：</p><p><img src="https://s1.ax1x.com/2020/10/12/0Wy1dH.png" alt="0Wy1dH.png" border="0"></p><div align="center"><img src="https://s1.ax1x.com/2020/10/12/0W6rnO.png" alt="0W6rnO.png" border="0" width="60%"></div><h4 id="Convolutional-Architecture"><a href="#Convolutional-Architecture" class="headerlink" title="Convolutional Architecture"></a>Convolutional Architecture</h4><p>最后一步就是应用卷积层提取特征，顶点和边的属性对应于传统图像CNN中的channel：</p><p><img src="https://s1.ax1x.com/2020/10/13/0fpKeK.png" alt="0fpKeK.png" border="0" width="75%"></p><p>假设顶点特征的数目为$a_v$，边的特征个数为$a_e$，$w$为选取的顶点个数，$k$为receptive field中的顶点个数，则对于输入的一系列图中的每一个，可以得到两个张量维度分别为$(w,k,a_v)、(w,k,k,a_e)$，可以变换为$(wk,a_v)、(wk^2,a_e)$，其中$a_v$与$a_e$可以看成是传统图像卷积中channel的个数，对它们做一维的卷积操作，第一个的receptive field的大小为$k$，第二个的receptive field的大小为$k^2$。</p><p><img src="https://s1.ax1x.com/2020/10/13/0fpWwT.png" alt="0fpWwT.png" border="0" width="75%"></p><p>整体卷积结构：</p><p><img src="https://s1.ax1x.com/2020/10/13/0fpbOx.png" alt="0fpbOx.png" border="0" width="75%"></p><h3 id="数据集-4"><a href="#数据集-4" class="headerlink" title="数据集"></a>数据集</h3><p>MUTAG、PTC、NCI、D&amp;D</p><h2 id="Graph-Attention-Networks-ICLR’18"><a href="#Graph-Attention-Networks-ICLR’18" class="headerlink" title="Graph Attention Networks[ICLR’18]"></a>Graph Attention Networks[ICLR’18]</h2><h3 id="解决的问题-8"><a href="#解决的问题-8" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何将attention机制应用于图类型的数据上。</p><h3 id="做法及创新-7"><a href="#做法及创新-7" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="图卷积"><a href="#图卷积" class="headerlink" title="图卷积"></a>图卷积</h4><div align="center"><img src="https://s1.ax1x.com/2020/10/16/07O1IK.png" alt="1" border="0" width="60%"><img src="https://s1.ax1x.com/2020/10/16/07O8PO.png" alt="2" border="0" width="60%"></div><p>给定一个含$n$个顶点的图，其中顶点的特征构成的集合为$(\overrightarrow{h_1},\overrightarrow{h_2},\dots,\overrightarrow{h_n})$，$\overrightarrow{h_i}\in \mathbb{R}^F$且邻接矩阵为$A$。一个图卷积层根据已有的顶点特征和图的结构来计算一个新的特征集合$(\overrightarrow{h_1’},\overrightarrow{h_2’},\dots,\overrightarrow{h_n’})$，$\overrightarrow{h_i’}\in \mathbb{R}^{F’}$</p><p>每个图卷积层首先会进行特征转换，以特征矩阵$W$表示，$W\in \mathbb{R}^{F’\times F}$它将特征向量线性转换为$\overrightarrow{g_i}=W\overrightarrow{h_i}$，再将新得到的特征向量以某种方式进行结合。为了利用邻域的信息，一种典型的做法如下：</p><script type="math/tex; mode=display">\overrightarrow{h_i}'=\sigma\bigg(\sum_{j\in N_i}\alpha_{ij}\overrightarrow{g_j}\bigg)</script><p>其中$N_i$表示顶点$i$的邻域（典型的构造方式是选取直接相连的顶点，包括自身），$\alpha_{ij}$表示顶点$j$的特征对于顶点$i$的重要程度，也可以看成一种权重。</p><p>现有的做法都是显式地定义$\alpha_{ij}$，本文的创新之处在于使用attention机制隐式地定义$\alpha_{ij}$。所使用的attention机制定义为$a:R^{F’}\times \mathbb{R}^{F’} \rightarrow \mathbb{R}$，以一个权重向量$\overrightarrow{a}\in \mathbb{R}^{2F’}$表示，对应于论文中的self-attention。  </p><h4 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h4><ol><li>基于顶点的特征计算系数$e_{ij}$</li></ol><script type="math/tex; mode=display">e_{ij}=a(W\overrightarrow{h_i},W\overrightarrow{h_j})</script><ol><li>以顶点的邻域将上一步计算得到的系数正则化，这么做能引入图的结构信息：</li></ol><script type="math/tex; mode=display">\begin{aligned}\alpha_{ij}&=\text{softmax}_j(e_{ij})=\frac{\exp(e_{ij})}{\sum_{k\in N_i}\exp(e_{ik})}\\&=\frac{\exp(\text{LeakyReLU}(\overrightarrow{a}^T[W\overrightarrow{h}_i||W\overrightarrow{h}_j]))}{\sum_{k\in N_i}\exp(\text{LeakyReLU}(\overrightarrow{a}^T[W\overrightarrow{h}_i||W\overrightarrow{h}_k]))}\end{aligned}</script><p><img src="https://s1.ax1x.com/2020/10/16/0H5cX6.png" alt="0H5cX6.png" border="0" width="30%"></p><blockquote><p>次序不变性：给定$(i,j),(i,k),(i’,j),(i’,k)$表示两个顶点间的关系，可以为边或自环。$a$为对应的attention系数，如果$a_{ij}&gt;a_{ik}$，则有$a_{i’j}&gt;a_{i’k}$</p></blockquote><p>​    <a href="https://dl.acm.org/doi/10.1145/3219819.3220077" target="_blank" rel="noopener">DeepInf</a>中给出了证明：</p><p>​    将权重向量$\overrightarrow{a}\in \mathbb{R}^{2F’}$重写为$\overrightarrow{a}=[p^T，q^T]$，则有</p><script type="math/tex; mode=display">e_{ij}=\text{LeakyReLU}(p^TWh_i+q^TWh_j)</script><p>​    由softmax与LeakyReLU的单调性可知，因为$a_{ij}&gt;a_{ik}$，有$q^TWh_j&gt;q^TWh_k$，类似地就可以得到$a_{i’j}&gt;a_{i’k}$。</p><p>​    这意味着，即使每个顶点都只关注于自己的邻域，但得到的attention系数却具有全局性。</p><ol><li>以上一步得到的系数$\alpha_{ij}$作为顶点$j$的特征对顶点$i$的重要程度，将领域中各顶点的特征做一个线性组合以作为顶点$i$最终输出的特征表示：</li></ol><script type="math/tex; mode=display">\overrightarrow{h_i'}=\sigma\bigg(\sum_{j\in N_i}\alpha_{ij}W\overrightarrow{h_j}\bigg)</script><h4 id="Multi-head-attention"><a href="#Multi-head-attention" class="headerlink" title="Multi-head attention"></a>Multi-head attention</h4><p>为了稳定self-attention的学习过程，论文引入了multi-head attention，即由$K$个相互独立的self-attention得到各自的特征，再进行拼接：</p><p><img src="https://s1.ax1x.com/2020/10/16/0HbZlj.png" alt="0HbZlj.png" border="0" width="60%"></p><script type="math/tex; mode=display">\overrightarrow{h_i'}=\Vert_{k=1}^K\sigma\bigg(\sum_{j\in N_i}\alpha_{ij}^kW^k\overrightarrow{h_j}\bigg)</script><p>其中$\alpha_{ij}^k$是第$k$个attention机制$(a^k)$计算出来的正则化系数，$W^k$是对应的将输入进行线性转化的权重矩阵。论文选取的拼接操作为求平均：</p><script type="math/tex; mode=display">\overrightarrow{h_i'}=\sigma\bigg(\frac{1}{K}\sum_{k=1}^K\sum_{j\in N_i}\alpha_{ij}^kW^k\overrightarrow{h_j}\bigg)</script><h3 id="数据集-5"><a href="#数据集-5" class="headerlink" title="数据集"></a>数据集</h3><p>Cora、Citeseer、Pubmed、PPI</p><h2 id="Representation-Learning-on-Graphs-with-Jumping-Knowledge-Networks-ICML’18"><a href="#Representation-Learning-on-Graphs-with-Jumping-Knowledge-Networks-ICML’18" class="headerlink" title="Representation Learning on Graphs with Jumping Knowledge Networks[ICML’18]"></a>Representation Learning on Graphs with Jumping Knowledge Networks[ICML’18]</h2><h3 id="解决的问题-9"><a href="#解决的问题-9" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>当图卷积网络GCN的层数超过两层时模型的表现会变差，这使得GCN只能作为浅层模型使用，且在对邻域节点的信息进行聚合时，即使同样是采用$k$层网络来聚合$k$跳邻居的信息，有着不同局部结构的顶点获得的信息也可能完全不同，以下图为例：</p><div align="center"><a href="https://imgchr.com/i/BpCLz8" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/20/BpCLz8.jpg" alt="BpCLz8.jpg" border="0" width="70%"></a></div><p>图$(a)$中的顶点位于核心区域，因此采用$4$层网络把几乎整个图的信息都进行聚合了，而不是它的邻域，这会导致过度平滑，而图$(b)$中顶点位于图边缘的一个树状结构中，采取同样的$4$层网络只囊括了一小部分顶点的信息，只有在第$5$层囊括了核心顶点之后才有效地囊括了更多顶点的信息。</p><p>所以，对于处于核心区域的顶点，GCN中每多一层即每多一次卷积操作，节点的表达会更倾向全局，这导致核心区域的很多顶点的表示到最后没有区分性。对于这样的顶点应该减少GCN的层数来让顶点更倾向局部从而在表示上可以区分；而处于边缘的顶点，即使更新多次，聚合的信息也寥寥无几，对于这样的顶点应该增加GCN的层数，来学习到更充分的信息。因此，对于不同的顶点应该选取不同的层数，传统做法对于所有顶点都用一个值会带来偏差。</p><h3 id="做法及创新-8"><a href="#做法及创新-8" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>理论部分，论文主要讨论的问题是，在一个$k$层的GCN中，顶点$x$对顶点$y$的影响程度，即顶点$x$输入特征的改变，会对顶点$y$在最后一层得到的表示产生多大的变化，也可以说是顶点$y$对于顶点$x$有多敏感。假设输入的特征为$X\in \mathbb{R}^{n\times f}$，输出的预测标签为$Z\in \mathbb{R}^{n\times c}$，其中$n$为图中顶点数目，$c$为类别数目，$f$为特征数目，则这种影响程度可以表示为$I(x,y)=\sum_i\sum_j\frac{\partial Z_{yi}}{\partial X_{xj}}$。</p><p>更特别地，论文证明了这个影响程度与从顶点$x$开始的$k$步随机漫步的分布有关，如果对$k$取极限$k\rightarrow \infty$，则随机漫步的分布会收敛到$P_{lim}(\rightarrow y)$。详细论证过程可见原文。这说明，结果与随机漫步的的起始顶点$x$没有关系，通过这种方法来得到$x$的邻域信息是不适用的。</p><p>另一种说法是，一个$k$层的图卷积网络等同于一个$k$阶的多项式过滤器，其中的系数是预先确定的<a href="https://arxiv.org/abs/2007.02133v1" target="_blank" rel="noopener">SDC</a>。这么一个过滤器与随机漫步类似，最终会收敛到一个静态向量，从而导致过度平滑。</p><p>实践部分，论文提出JK-Net，通过Layer aggregation来让顶点最后的表示自适应地聚合不同层的信息，局部还是全部，让模型自己来学习：</p><div align="center"><a href="https://imgchr.com/i/BpEvLT" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/20/BpEvLT.jpg" alt="BpEvLT.jpg" border="0" width="50%"></a></div><p>论文的重点在于最后的Layer aggregation层，可选的三种操作为：Concat、Max-pooing以及LSTM-attn。</p><ol><li><p>Concat</p><p>将各层的表示直接拼接在一起，送入Linear层。对于小数据集及结构单一的图这种聚合方式会更好，因为它们不需要顶点在聚合邻域的顶点信息时具有什么自适应性。</p></li><li><p>Max-pooling</p><p>选取各层的表示中包含信息量最多的作为顶点的最终表示，在多层结构中，低层聚合更多局部信息，而高层会聚合更多全局信息，因此对于核心区域内的顶点可能会选取高层表示而边缘顶点选取低层表示。</p></li><li><p>LSTM-attention</p><p>对于各层的表示，attention机制通过计算一个系数$s_v^{(l)}$来表示各层表示的重要性，其中$\sum_ls_v^{(l)}=1$，顶点最终的表示就是各层表示的一个加权和：$\sum_ls_v^{(l)}·h_v^{(l)}$。</p><blockquote><p>$s_v^{(l)}$的计算：将$k$层网络各层的表示$h_v^{(1)},\dots,h_v^{(k)}$输入一个双向LSTM中，同时生成各层$l$的前向LSTM与反向LSTM的隐式特征，分别表示为$f_v^{(l)}、b_v^{(l)}$，拼接后将$|f_v^{(l)}||b_v^{(l)}|$送入一个Linear层，将Linear层的结果进行Softmax归一化操作就得到了系数$s_v^{l}$。</p></blockquote></li></ol><h3 id="数据集-6"><a href="#数据集-6" class="headerlink" title="数据集"></a>数据集</h3><p>Citeseer、Cora、Reddit、PPI</p><h2 id="Session-Based-Recommendation-with-Graph-Neural-Networks-AAAI’19"><a href="#Session-Based-Recommendation-with-Graph-Neural-Networks-AAAI’19" class="headerlink" title="Session-Based Recommendation with Graph Neural Networks[AAAI’19]"></a>Session-Based Recommendation with Graph Neural Networks[AAAI’19]</h2><h3 id="解决的问题-10"><a href="#解决的问题-10" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在序列推荐任务中，现有的方法很难在每条序列中取得准确的用户embedding，因为得到的序列数据往往是匿名的，且序列中记录的点击数据所透露出来的用户行为信息有限。同时，序列中物品间的关系虽然常被证实有效，但现有的方法往往只考虑一阶的前后连续关系，即对于$a\rightarrow b \rightarrow  c$，只考虑$a\rightarrow b$或者$b\rightarrow c$</p><h3 id="做法及创新-9"><a href="#做法及创新-9" class="headerlink" title="做法及创新"></a>做法及创新</h3><p><a href="https://imgchr.com/i/BF3uuT" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BF3uuT.png" alt="BF3uuT.png" border="0"></a></p><h4 id="Session-Graph-Modeling"><a href="#Session-Graph-Modeling" class="headerlink" title="Session Graph Modeling"></a>Session Graph Modeling</h4><p>将每条序列$s$表示成一个有向图，并对图中的边进行正则化，具体做法为边的出现次数除以边起始顶点的出度。以序列$s=[v_1,v_2,v_3,v_2,v_4]$为例构建一个有向图，得到邻接矩阵：</p><div align="center"><a href="https://imgchr.com/i/BF17nO" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BF17nO.png" alt="BF17nO.png" border="0" width="80%"></a></div><p>上面的邻接矩阵以考虑顶点的出边并以出度正则化，类似地可以考虑顶点的入边并以入度正则化，将得到的两种邻接矩阵进行拼接，得到论文中提到的连接矩阵$A_s\in \mathbb{R}^{n\times 2n}$，其中的一行$A_{s,i:}\in \mathbb{R}^{1\times 2n}$对应于所构建的有向图中的一个顶点$v_{s,i}$：</p><div align="center"><a href="https://imgchr.com/i/BFGCkQ" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BFGCkQ.png" alt="BFGCkQ.png" border="0" width="80%"></a></div><h4 id="Node-Representation-Learning"><a href="#Node-Representation-Learning" class="headerlink" title="Node Representation Learning"></a>Node Representation Learning</h4><p>论文使用gated GNN来学习图中顶点的表示，为了类比地说明各式的具体含义，首先对Gated Recurrent Units（GRU）进行介绍，它是循环神经网络中的一个概念。</p><h5 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h5><p>一个典型的GRU如下所示，输入为上一时刻的隐层表示$H_{t-1}$及当前时刻的表示$X_t$，包含一个重置门Reset Gate和一个更新门Update Gate：</p><div align="center"><a href="https://imgchr.com/i/BFaaAf" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BFaaAf.png" alt="BFaaAf.png" border="0" width="60%"></a></div><p>直观的来说，重置门决定有多少历史信息被保留，而更新门决定利用多少当前时刻$X_t$的信息。给定当前时刻输入$X_t\in \mathbb{R}^{n\times d}$，上一时刻隐层表示$H_{t-1}\in \mathbb{R}^{n\times h}$，重置门与更新门的输出由下式计算得到：</p><script type="math/tex; mode=display">R_t=\sigma(X_tW_{xr}+H_{t-1}W_{hr}+b_r)\\Z_t=\sigma(X_tW_{xz}+H_{t-1}W_{hz}+b_z)</script><p>式中的$W$与$b$分别为权重与偏置参数。</p><h5 id="Reset-Gate"><a href="#Reset-Gate" class="headerlink" title="Reset Gate"></a>Reset Gate</h5><p>传统RNN网络的隐式状态更新公式为：</p><script type="math/tex; mode=display">H_t=\tanh(X_tW_{xh}+H_{t-1}W_{hh}+b_h)</script><p>如果我们需要减少历史信息带来的影响，可以将$H_{t-1}$与$R_t$逐元素相乘。如果$R_t$中的元素接近于1，得到的结果就是传统的RNN，如果$R_t$中的结果接近于0，得到的结果就是以$X_t$作为输入的MLP，计算出来的$\tilde{H_t}$称为候选状态：</p><script type="math/tex; mode=display">\tilde{H_t}=\tanh(X_tW_{xh}+(R_t\odot{H_{t-1}})W_{hh}+b_h)</script><h5 id="Update-Gate"><a href="#Update-Gate" class="headerlink" title="Update Gate"></a>Update Gate</h5><p>更新门决定新的隐式状态$H_t$多大程度上与上一时刻$H_{t-1}$相同，以及重置门得到的候选状态$\tilde{H_t}$中有多少信息可以被利用，如果$Z_t$中的元素接近于1，将主要保留历史信息，当前时刻$X_t$的信息基本被忽略，这相当于跳过了时刻$t$；当$Z_t$中的元素接近于0时，$H_t$将主要由$\tilde{H_t}决定$：</p><script type="math/tex; mode=display">H_t=Z_t\odot H_{t-1}+(1-Z_t)\odot \tilde{H_t}</script><p>介绍完了GRU的基本概念，接下来是论文中的方法，可以类比地进行学习：</p><p><a href="https://imgchr.com/i/BkiNUU" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/22/BkiNUU.png" alt="BkiNUU.png" border="0"></a></p><p>最主要的不同之处在公式$(1)$，它用于在连接矩阵$A_s$的约束下进行不同顶点间的信息传播，具体来说，它提取了邻域的隐向量并将它们作为GNN的输入。</p><h4 id="Session-Representation-Generation"><a href="#Session-Representation-Generation" class="headerlink" title="Session Representation Generation"></a>Session Representation Generation</h4><p>现有的做法都假设每条序列中的用户都有一个独特的隐式表示，而论文中提出的方法不对这个隐式向量做任何假设，相反，它用序列中顶点的表示来作为序列的表示，而顶点的表示正是上一步将所有序列构建的图送入gated GNN学习得到的。给定一个序列$\text{s}=[v_{s,1},v_{s,2},\dots,v_{s,n}]$，这一步的目的是得到它的embedding向量$s\in \mathbb{R}^d$。为了结合用户的长期偏好与当前兴趣，生成的embedding向量也有局部和全局两部分组成。</p><p>局部embedding向量的构造非常简单，就是最后一个点击过的物品的表示，因为最后一个点击过的物品就表明了用户当前的兴趣：</p><script type="math/tex; mode=display">s_l=v_n</script><p>全局embedding向量的构造需要将所有顶点的表示都聚合进来，论文的做法是做一个线性加权，权重使用$\text{soft-attention}$机制来计算得到：</p><script type="math/tex; mode=display">\begin{aligned}s_g&=\sum_{i=1}^{n}\alpha_iv_i\\\alpha_i&=q^T\sigma(W_1v_n+W_2v_i+c)\end{aligned}</script><p>最后使用一个$\text{Linear}$层来将局部与全局embedding向量进行结合得到最终的序列embedding向量：</p><script type="math/tex; mode=display">s_h=W_3[s_l;s_g]</script><h4 id="Making-Recommendation"><a href="#Making-Recommendation" class="headerlink" title="Making Recommendation"></a>Making Recommendation</h4><p>对于一个待推荐物品$v_i\in V$，计算它在序列$s$中作为下一个被点击物品的概率：</p><script type="math/tex; mode=display">\hat{y_i}=\text{softmax}(s_h^Tv_i)</script><h3 id="数据集-7"><a href="#数据集-7" class="headerlink" title="数据集"></a>数据集</h3><p>Yoochoose、Diginetica</p><h2 id="KGAT-Knowledge-Graph-Attention-Network-for-Recommendation-KDD’19"><a href="#KGAT-Knowledge-Graph-Attention-Network-for-Recommendation-KDD’19" class="headerlink" title="KGAT: Knowledge Graph Attention Network for Recommendation[KDD’19]"></a>KGAT: Knowledge Graph Attention Network for Recommendation[KDD’19]</h2><h3 id="解决的问题-11"><a href="#解决的问题-11" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在推荐系统中，如何将用户-物品交互信息与物品自身的属性相结合以做出更好的推荐，从另一个角度来说，即如何融合用户-物品交互图与知识图谱</p><div align="center"><a href="https://imgchr.com/i/BnaHGn" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/BnaHGn.png" alt="BnaHGn.png" border="0" width="65%"></a></div><p>以上面的图为例，在电影推荐场景中，用户对应于观众，物品对应于电影，实体Entities可以有多种含义，例如导演、演员、电影类别等，对应的就会有多种关系，对应图中的$r_1-r_4$。对于用户$u_1$，协同过滤更关注于他的相似用户，即同样看过$i_1$的$u_4$与$u_5$；而有监督学习方法例如因子分解机等会更关注物品之间的联系，例如$i_1$与$i_2$同样有着属性$e_1$，但它无法进一步建模更高阶的关系，例如图中黄色圈内的用户$u_2$与$u_3$观看了同一个导演$e_1$的电影$i_2$，而这名导演$e_1$又作为演员参演了灰色圈内的电影$i_3$与$i_4$。图中上半部分对应于用户-物品交互图，下半部分对应于知识图谱。</p><h3 id="做法及创新-10"><a href="#做法及创新-10" class="headerlink" title="做法及创新"></a>做法及创新</h3><p><a href="https://imgchr.com/i/BnDu0f" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/BnDu0f.png" alt="BnDu0f.png" border="0"></a></p><h4 id="CKG-Embedding-Layer"><a href="#CKG-Embedding-Layer" class="headerlink" title="CKG Embedding Layer"></a>CKG Embedding Layer</h4><p>知识图谱的一般形式可以表示为三元组的集合$\{(h,r,t)\}$，表示头实体$h$与尾实体$t$之间有关系$r$，例如$\text{(Hugh Jackman,ActorOf,Logan)}$表示狼叔是电影罗根的演员，这是一种主动的关系，自然就有逆向的被动关系。而对于用户-物品交互信息来说，通常的表示形式为一个矩阵$R$，$R_{ui}$表示用户$u$与物品$i$的关系，有交互则值为1，否则为0。因此，为了统一两种表示形式，论文中将用户-物品交互信息同样改成三元组的集合$\text$，这样一来得到的统一后的新图称之为Collaborative Knowledge Graph(CKG)。</p><p>第一个步骤是对CKG做embedding，得到图中顶点和边的向量表示形式。论文使用了知识图谱中常用的一个方法$\text{TransR}$，即对于一个三元组$(h,r,t)$，目标为：</p><script type="math/tex; mode=display">e_h^r+e_r\approx e_t^r</script><p>其中$e_h,e_t\in \mathbb{R}d、e_r\in \mathbb{R}k$分别为$h、t、r$的embedding，而$e_h^r,e_t^r$为$e_h、e_t$在$r$所处空间中的投影，损失函数定义为：</p><script type="math/tex; mode=display">g(h,r,t)=||W_re_h+e_r-W_re_t||^2_2</script><p>值越小说明该三元组在知识图谱中更可能存在，即头实体$h$与尾实体$t$之间更可能有关系$r$。经过这一步骤之后，CKG中所有的顶点及边我们都得到了它们的embedding。</p><h4 id="Attentive-Embedding-Propagation-Layers"><a href="#Attentive-Embedding-Propagation-Layers" class="headerlink" title="Attentive Embedding Propagation Layers"></a>Attentive Embedding Propagation Layers</h4><p>第二个步骤直接用的GCN与GAT的想法，在一层embedding propagation layer中，利用图卷积网络在邻域中进行信息传播，利用注意力机制来衡量邻域中各邻居顶点的重要程度。再通过堆叠$l$层来聚合$l$阶邻居顶点的信息。</p><p>在每一层中，首先将顶点$h$的邻域以向量形式表示，系数$\pi(h,r,t)$还会进行$\text{softmax}$归一化：</p><script type="math/tex; mode=display">\begin{aligned}e_{N_h}&=\sum_{(h,r,t)\in N_h}\pi(h,r,t)e_t \\\pi(h,r,t)&=(W_re_t)^T\text{tanh}\big(W_re_h+e_r\big)\end{aligned}</script><p>通过堆叠$l$层来聚合$l$阶邻居顶点的信息：</p><script type="math/tex; mode=display">\begin{aligned}e_h^{(l)}&=f\big( e_h^{(l-1)},e_{N_h}^{(l-1)} \big) \\&=\text{LeakyReLU}\big( W_1(e_h+e_{N_h})\big)+\text{LeakyReLU}\big( W_2(e_h\odot e_{N_h})\big)\end{aligned}</script><p>论文中所使用的聚合函数$f$在GCN与GraphSage的基础上，还额外地引入了第二项中$e_h$与$e_{N_h}$的交互，这使得聚合的过程对于两者之间的相近程度更为敏感，会在更相似的顶点中传播更多的信息。</p><h4 id="Model-Prediction"><a href="#Model-Prediction" class="headerlink" title="Model Prediction"></a>Model Prediction</h4><p>在得到$L$层embedding propagation layer的表示后，使用JK-Net中的LSTM-attention进行聚合，在通过点积的形式给出预测分数：</p><script type="math/tex; mode=display">e_u^*=\text{LSTM-attention}(e_u^{(0)},e_u^{(L)})\\e_i^*=\text{LSTM-attention()}e_i^{(0)}||\dots||e_i^{(L)}\\\hat{y}(u,i)={e_u^*}^Te_i^*</script><h3 id="数据集-8"><a href="#数据集-8" class="headerlink" title="数据集"></a>数据集</h3><p>Amazon-book、Last-FM、Yelp2018</p><h2 id="DeepInf-Social-Influence-Prediction-with-Deep-Learning-KDD’18"><a href="#DeepInf-Social-Influence-Prediction-with-Deep-Learning-KDD’18" class="headerlink" title="DeepInf: Social Influence Prediction with Deep Learning[KDD’18]"></a>DeepInf: Social Influence Prediction with Deep Learning[KDD’18]</h2><h3 id="解决的问题-12"><a href="#解决的问题-12" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>如何在图结构的社交数据中预测顶点的影响力。</p><p>在图中，给定顶点$v$与它的邻域以及一个时间段，通过对开始时各顶点的状态进行建模，来对结束时顶点$v$的状态进行预测（是否被激活）。</p><h4 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h4><ul><li>邻域：给定图$G=(V,E)$，顶点$v$的邻域定义为$N_v^r=\{u:d(u,v)\le r\}$，是一个顶点集合，不包含顶点$v$自身</li><li>中心网络：由邻域中的顶点及边所组成的网络，以$G_v^r$表示</li><li>用户行为：以$s_v^t$表示，用户对应于图中的顶点，对于一个时刻$t$，如果顶点$v$有产生动作，例如转发、引用等，则$s_v^t=1$</li></ul><p>给定用户$v$的中心网络、邻域中用户的行为集合$S_v^t=\{s_i^t:i\in N_v^r\}$，论文想解决的问题是，在一段时间$Δt$后，对用户$v$的行为的预测：</p><script type="math/tex; mode=display">P(s_v^{t+Δt}|G_v^r,S_v^t)</script><h3 id="做法及创新-11"><a href="#做法及创新-11" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><p><a href="https://imgchr.com/i/BGDfOO" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/29/BGDfOO.png" alt="BGDfOO.png" border="0"></a></p><p>数据预处理方面，论文通过带重启的随机漫步来为图中的每个顶点$v$获取固定大小$n$的中心网络$G_v^r$，接着使用$\text{DeepWalk}$来得到图中顶点的embedding，最后进行归一化。通过这几个步骤对图中的特征进行提取后，论文还进一步添加了几种人工提取的特征，包括用户是否活跃等等：</p><div align="center"><a href="https://imgchr.com/i/BGyXX6" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/29/BGyXX6.png" alt="BGyXX6.png" border="0" width="70%"></a></div><blockquote><p>摘要里说传统的影响力建模方法都是人工提取图中顶点及结构的特征，论文的出发点就是自动学习这种特征表示，结果在预处理的最后还是添加了几种人工提取的特征，这不是自相矛盾吗？</p></blockquote><p>经过上面的步骤后，最后得到包含所有用户特征的一个特征矩阵$H\in \mathbb{R}^{n\times F}$，每一行$h_i^T$表示一个用户的特征，$F$等同于$\text{DeepWalk}$长度加上人工特征长度。</p><h4 id="影响力计算"><a href="#影响力计算" class="headerlink" title="影响力计算"></a>影响力计算</h4><p>这一步纯粹是在套GAT的框架，没什么可以说的，计算如下：</p><script type="math/tex; mode=display">H'=\text{GAT}(H)=g(A_{\text{GAT}}(G)HW^T+b)\\A_{\text{GAT}}(G)=[a_{ij}]_{n\times n}</script><p>其中$W\in \mathbb{R}^{F’\times F}, b\in \mathbb{R}^{F’}$是模型的参数，$a_{ij}$的计算在GAT论文的笔记中有记录，不再赘述。</p><h3 id="数据集-9"><a href="#数据集-9" class="headerlink" title="数据集"></a>数据集</h3><p>OAG、Digg、Twitter、Weibo</p><h2 id="Predict-then-Propagate-Graph-Neural-Networks-meet-Personalized-PageRank-ICLR’19"><a href="#Predict-then-Propagate-Graph-Neural-Networks-meet-Personalized-PageRank-ICLR’19" class="headerlink" title="Predict then Propagate Graph Neural Networks meet Personalized PageRank[ICLR’19]"></a>Predict then Propagate Graph Neural Networks meet Personalized PageRank[ICLR’19]</h2><h3 id="解决的问题-13"><a href="#解决的问题-13" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>GCN层数增加后性能反而变差，如何加深GCN的层数。</p><p>根据GCN的定义，每一层网络用来捕获一跳邻居的信息，例如一个三层的GCN网络捕获的就是一个顶点三跳邻居以内的信息，而现在如果只能用浅层模型，表示只能捕获有限跳内的邻域信息，而有时候要多几跳才能捕获到有用的信息，例如<a href="#Representation Learning on Graphs with Jumping Knowledge Networks[ICML&#39;18]">JK-Net</a>中的例子。</p><h3 id="做法及创新-12"><a href="#做法及创新-12" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>这一篇论文的工作其实是接着JK-Net继续往下，在那篇论文中，作者分析了GCN中信息传递这个过程与随机漫步之间的关系，论证了当层数加深之后，GCN会收敛到这个随机漫步的极限分布，而这个极限分布只与图的全局属性有关，没有把随机漫步的起始顶点，或者说是GCN中从邻域中传递和聚合信息的根顶点考虑在内，这么一来，层数加深之后每个顶点聚合出来的样子都差不多，无法区分从而导致性能变差，另一个看待的角度是，因为原始GCN是对所有聚合的信息做平均操作，层数加深之后各个顶点的邻域都变得跟整张图差不多，既然每个顶点的邻域都变得差不多，做的又是平均操作，每个顶点聚合出来的样子就会都差不多。</p><p>论文提出的解决办法是引入PageRank的思想，这也是从JK-Net中的结论观察出来的。JK-Net中所说的GCN会收敛到的极限分布的计算方法如下：</p><script type="math/tex; mode=display">\pi_{lim}=\hat{A}\pi_{lim}</script><p>而PageRank的计算方法如下：</p><script type="math/tex; mode=display">\pi_{pr}=A_{rw}\pi_{pr}</script><p>其中$A_{rw}=AD^{-1}$，两个计算方法明显地相似，区别在于，PageRank中邻接矩阵$A$没有考虑根顶点自身，而极限分布的计算里$\hat{A}$是引入了自环的。而Personalized PageRank通过引入自环而考虑了根顶点自身，论文的想法就是将随机漫步的极限分布用Personalized PageRank来代替，它的计算方法为：</p><script type="math/tex; mode=display">\pi_{ppr}(i_x)=(1-\alpha)\hat{A}\pi_{ppr}(i_x)+\alpha i_x \\\rightarrow \pi_{ppr}(i_x)=\alpha\Big(I_n-(1-\alpha)\hat{A}\Big)^{-1}i_x</script><p>其中$i_x$是一个one_hot指示向量，用来从根顶点重新启动。</p><blockquote><p>Personalized PageRank算法的目标是要计算所有节点相对于用户u的相关度。从用户u对应的节点开始游走，每到一个节点都以α的概率停止游走并从u重新开始，或者以1-α的概率继续游走，从当前节点指向的节点中按照均匀分布随机选择一个节点往下游走。这样经过很多轮游走之后，每个顶点被访问到的概率也会收敛趋于稳定，这个时候我们就可以用概率来进行排名了。</p></blockquote><p>相较于原始的GCN模型，现在根顶点$x$对顶点$y$的影响程度$I(x,y)$，变得与$\pi_{ppr}(i_x)$中的第$y$个元素相关，这个影响程度对于每个根顶点都有不同的取值：</p><script type="math/tex; mode=display">\require{cancel}I(x,y)\propto \prod_{ppr}^{(yx)},\prod_{ppr}^{(yx)}=\alpha\Big(I_n-(1-\alpha)\hat{A}\Big)^{-1}\cancel{I_{n}}</script><h4 id="PPNP"><a href="#PPNP" class="headerlink" title="PPNP"></a>PPNP</h4><p>经过上面的铺垫与介绍，论文提出的模型PPNP可以表示为：</p><script type="math/tex; mode=display">Z_{PPNP}=\text{softmax}\Big(\alpha\Big(I_n-(1-\alpha)\hat{A}\Big)^{-1}H\Big),H_{i,:}=f_{\theta}(X_i,:)</script><p>其中$X$为特征矩阵，$f_{\theta}$是一个参数为$\theta$的神经网络，用来产生预测类别$H\in \mathbb{R}^{n\times c}$。</p><div align="center"><a href="https://imgchr.com/i/ravXN9" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/20/ravXN9.png" alt="ravXN9.png" border="0" width="90%"></a></div>由公式和图中都可以看到，PPNP其实是由两部分组成，左边的神经网络与右边的信息传递网络，神经网络部分就类似于在[GCN](#Semi-Supervised Classification with Graph Convolutional Network [ICLR'17])中介绍的，输入顶点特征与图的结构信息（邻接矩阵），输出顶点新的特征表示。信息传递网络部分，在PPNP中通过它来得到预测标签，而原始GCN的做法是$Z_{GCN}=\text{softmax}(\hat{A}HW)$，其中$W$是每层网络的参数。#### APPNP从前面的构造方式可以看到，矩阵$\prod_{ppr}$将会有$\mathbb{R}^{n\times n}$大小，会带来时间和空间上的复杂度。因此论文提出了一种近似的计算方法APPNP，计算方式如下：$$\begin{aligned}Z^{(0)}&=H=f_{\theta}(X) \\Z^{(k+1)}&=(1-\alpha)\hat{A}Z^{(k)}+\alpha H \\Z^{(K)}&=\text{softmax}\Big((1-\alpha)\hat{A}Z^{(K-1)}+\alpha H\Big)\end{aligned}$$其中$K$为信息传递的跳数或者说是随机漫步的步数，$k\in[0,K-2]$，这样一来就不用构造一个$\mathbb{R}^{n\times n}$的矩阵了。（不知道为什么...）  ### 数据集Citeseer、Cora-ML、Pubmed、MS Academic  ## Graph Neural Networks for Social Recommendation[WWW'19]### 解决的问题如何将GNN应用于社会化推荐任务上。面临的挑战有三点：1. 在一个社会化推荐任务中，输入的数据包括社会关系图和用户-物品交互图，将两张图的信息都聚合才能得到用户更好的一个表示，而此前的GNN只是在同一张图上对邻域内的信息聚合。2. 在用户-物品交互图中，顶点与顶点之间的边也包含更多的信息，除了表示是否交互，还能表示用户对一个物品的偏好（喜爱还是厌恶），而此前的GNN只是将边用来表示是否交互。3. 社会关系图中用户之间的纽带有强有弱，显然地，一个用户更可能与强纽带的其它用户有类似的喜好。如果将所有纽带关系都看成一样，会有偏差。### 做法及创新创新：* 在不同图(user-user graph和user-item graph)上进行信息传递与聚合* 除了捕获user-item间的交互关系，还利用了user对item的评分* 用attention机制表示社交关系的重要性，用户纽带的强与弱<div align="center"><a href="https://imgchr.com/i/r0xT1A" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/r0xT1A.png" alt="r0xT1A.png" border="0" width="90%"></a></div>整个GraphRec框架由三个部分组成，分别为user modeling、item modeling和rating prediction。其中user modeling用来学习用户的特征表示，学习的方式是两个聚合：item aggregation和social aggregation，类似地item modeling用来学习物品的特征表示，学习的方式是一个聚合：user aggregation。#### User Modeling##### item aggregation<div align="center"><a href="https://imgchr.com/i/rBuFzt" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/rBuFzt.png" alt="rBuFzt.png" border="0" width="40%"></a></div><p>item aggregation的目的是通过用户交互过的物品以及对这些物品的倾向，来学习物品侧的用户特征表示，数学表示为：</p><script type="math/tex; mode=display">h_i^I=\sigma(W·Aggre_{items}(\{x_{ia},\forall a\in C(i)\})+b)</script><p>$C(i)$就表示用户交互过的物品的一个集合。这里的$x_{ia}$是一个表示向量，它应该能够同时表示交互关系和用户倾向。论文中的做法是通过一个MLP来结合物品的embedding和倾向的embedding，两者分别用$q_a$和$e_r$表示。倾向的embedding可能很难理解，以五分制评分为例，倾向的embedding表示为$e_r\in \mathbb{R}^d$，其中$r\in \{1,2,3,4,5\}$。</p><script type="math/tex; mode=display">x_{ia}=g_v([q_a\oplus e_r])</script><p>定义好$x_{ia}$后，下一步就是如何选取聚合函数$Aggre$了。论文中使用的是attention机制，来源于<a href="#Graph Attention Networks[ICLR&#39;18]">GAT</a>：</p><script type="math/tex; mode=display">\begin{aligned}h_i^I&=\sigma(W·\Big\{\sum_{a\in C(i)}\alpha_{ia}x_{ia}\Big\}+b) \\\alpha_{ia}'&=w_2^T·\sigma(W_1·[x_{ia}\oplus p_i]+b_1)+b_2 \\\alpha_{ia}&=\frac{\exp(\alpha_{ia}')}{\sum_{a\in C(i)}\exp(\alpha_{ia}')}\end{aligned}</script><p>这里的权重$\alpha_{ia}$考虑了$x_{ia}$和用户$u_i$的embedding $p_i$，使得权重能够与当前用户相关。</p><h5 id="social-aggregation"><a href="#social-aggregation" class="headerlink" title="social aggregation"></a>social aggregation</h5><div align="center"><a href="https://imgchr.com/i/rBK7g1" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/rBK7g1.png" alt="rBK7g1.png" border="0" width="40%"></a></div>social aggregation中，同样地使用了attention机制，通过attention机制来选取强纽带的其它用户（表现为聚合时权重更大）并聚合他们的信息，聚合的就是物品侧的用户特征表示。$$\begin{aligned}h_i^S&=\sigma(W·\Big\{\sum_{o\in N(i)}\beta_{io}h_o^I\Big\}+b) \\\beta_{io}'&=w_2^T·\sigma(W_1·[h_o^I\oplus p_i]+b_1)+b_2 \\\beta_{io}&=\frac{\exp(\beta_{io}')}{\sum_{o\in N(i)}\exp(\beta_{io}')}\end{aligned}$$这里跟item aggregation基本一模一样，就不多介绍了。得到物品侧的用户特征表示$h_i^I$和社交侧的用户特征表示$h_i^S$后，用一个MLP将它们结合，得到用户最终的特征表示：$$\begin{aligned}c_1&=[h_i^I\oplus h_i^S] \\c_2&=\sigma(W_2·c_1+b_2) \\&······ \\h_i&=\sigma(W_l·c_{l-1}+b_l)\end{aligned}$$#### Item Modeling##### user aggregation<div align="center"><a href="https://imgchr.com/i/rBYtjH" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/21/rBYtjH.png" alt="rBYtjH.png" border="0" width="50%"></a></div>Item modeling与User modeling的做法基本一模一样...公式都是一一对应的：$$\begin{aligned}f_{jt}&=g_u([p_t\oplus e_r]) \\z_j&=\sigma(W·\Big\{\sum_{t\in B(j)}\mu_{jt}f_{jt}\Big\}+b) \\\mu_{jt}'&=w_2^T·\sigma(W_1·[f_{jt}\oplus q_j]+b_1)+b_2 \\\mu_{jt}&=\frac{\exp(\mu_{jt}')}{\sum_{a\in C(i)}\exp(\mu_{jt}')}\end{aligned}$$#### Rating Prediction最后来到评分预测部分，由上面两个部分我们得到了用户特征表示$h_i$与物品特征表示$z_j$，产生评分用的也是一个MLP：$$\begin{aligned}g_1&=[h_i\oplus z_j] \\g_2&=\sigma(W_2·g_1+b_2) \\&······ \\g_{l-1}&=\sigma(W_l·g_{l-1}+b_l) \\r_{ij}&=w^T·g_{l-1}\end{aligned}$$### 数据集Ciao、Epinions## Graph Convolutional Matrix Completion[KDD'18]### 解决的问题如何将图卷积网络应用于矩阵补全问题。具体地，这篇论文做的是推荐系统方向下的矩阵补全问题，给定一个评分矩阵，如何根据已有的评分记录来预测用户对其他物品的评分。如果将评分矩阵转换为一张图，转换方法在下面有进行介绍，这时矩阵补全问题也可以看成图上的边预测问题。要预测用户对一个物品的评分，就是预测图上两个对应顶点之间相连的边的权重。### 做法及创新论文通过一个编码器-解码器的架构来实现从已有评分到特征表示再到预测评分的过程。<div align="center"><a href="https://imgchr.com/i/sQUdAS" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQUdAS.png" alt="sQUdAS.png" border="0" width="70%"></a></div><h4 id="Bipartite-Graph-Construction"><a href="#Bipartite-Graph-Construction" class="headerlink" title="Bipartite Graph Construction"></a>Bipartite Graph Construction</h4><p>首先是将推荐任务里的评分数据转化为一张图，具体做法是将用户和物品都看作图中的顶点，交互记录看作边，分数作为边的权重，如图所示：</p><div align="center"><a href="https://imgchr.com/i/su9fr4" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/08/su9fr4.png" alt="su9fr4.png" border="0" width="60%"></a></div><h4 id="Graph-Convolutional-Encoder"><a href="#Graph-Convolutional-Encoder" class="headerlink" title="Graph Convolutional Encoder"></a>Graph Convolutional Encoder</h4><p>上一步所构建的图的输入形式为邻接矩阵$A\in \mathbb{R}^{n\times n}$与图中顶点的特征矩阵$X\in \mathbb{R}^{n\times d}$。编码器在这一步的作用就是得到用户与物品的特征表示$A,X^u,X^v\rightarrow U,V$。</p><p>具体编码时，论文将不同的评分水平分开考虑$r\in \{1,2,3,4,5\}$，我的理解是它们类似于处理图像数据时的多个channel。以一个评分水平$r$为例，说明编码得到特征表示的过程。假设用户$u_i$对电影$v_j$评分为$r$，而这部电影的特征向量为$x_j$，那么这部电影对这个用户特征表示的贡献可以表示为下面的式子(1)，相当于对特征向量进行了一个线性变换。</p><div align="center"><a href="https://imgchr.com/i/sQUHnx" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQUHnx.png" alt="sQUHnx.png" border="0" width="80%"></a></div>对当前评分水平下所有评过分的电影进行求和，再对所有评分水平求和拼接，经过一个非线性变换，就得到了用户$u_i$的特征表示$h_{u_i}$，物品的做法相同。<div align="center"><a href="https://imgchr.com/i/sQdv6A" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQdv6A.png" alt="sQdv6A.png" border="0" width="80%"></a></div><div align="center"><a href="https://imgchr.com/i/sQwmmq" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/09/sQwmmq.png" alt="sQwmmq.png" border="0" width="80%"></a></div><h4 id="Bilinear-Decoder"><a href="#Bilinear-Decoder" class="headerlink" title="Bilinear Decoder"></a>Bilinear Decoder</h4><p>在分别得到用户与物品的特征表示$U$与$V$后，解码器计算出用户对物品评分为$r$的概率，再对每个评分的概率进行求和，得到最终预测的评分。</p><script type="math/tex; mode=display">\begin{aligned}(P_r)_{ij}&=\frac{\exp(u_i^TQ_rv_j)}{\sum_{s\in R}\exp(u_i^TQ_sv_j)} \\\hat{M}&=\sum_{r\in R}rP_r\end{aligned}</script><h3 id="数据集-10"><a href="#数据集-10" class="headerlink" title="数据集"></a>数据集</h3><p>Flixster、Douban、YahooMusic、MovieLens</p><h2 id="Variational-Graph-Auto-Encoders-NIPS’16"><a href="#Variational-Graph-Auto-Encoders-NIPS’16" class="headerlink" title="Variational Graph Auto-Encoders[NIPS’16]"></a>Variational Graph Auto-Encoders[NIPS’16]</h2><h3 id="解决的问题-14"><a href="#解决的问题-14" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>在图结构数据上如何使用变分自编码器</p><h3 id="做法及创新-13"><a href="#做法及创新-13" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>将已知的图进行编码（图卷积）得到图中顶点向量表示的一个分布，在分布中采样得到顶点的向量表示，然后进行解码重新构建图。</p><h4 id="变分自编码器"><a href="#变分自编码器" class="headerlink" title="变分自编码器"></a>变分自编码器</h4><p>因为这篇论文做的是一个迁移的工作，变分自编码器的背景对于理解这篇论文来说十分重要，首先进行介绍。</p><p>变分自编码器是自编码器的一种，一个自编码器由编码器和解码器构成，编码器将输入数据转换为低维向量表示，解码器通过得到的低维向量表示进行重构。</p><div align="center"><a href="https://imgchr.com/i/sl9ZxP" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/sl9ZxP.jpg" alt="sl9ZxP.jpg" border="0" width="80%"></a><a href="https://imgchr.com/i/sl9G2q" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/sl9G2q.jpg" alt="sl9G2q.jpg" border="0" width="65%"></a></div><p>这种结构的不足之处在于，只能产生与输入数据相似的样本，而无法产生新的样本，低维向量表示必须是有真实样本通过编码器得到的，随机产生的低维向量经过重构几乎不可能得到近似真实的样本。而变分自编码器可以解决这个问题。</p><p>变分自编码器将输入数据编码为一个分布，而不是一个个低维向量表示，然后从这个分布中随机采样来得到低维向量表示。一般假设这个分布为正态分布，因此编码器的任务就是从输入数据中得到均值$\mu$与方差$\sigma^2$。</p><div align="center"><a href="https://imgchr.com/i/slCW60" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slCW60.jpg" alt="slCW60.jpg" border="0" width="80%"></a><a href="https://imgchr.com/i/slPZB8" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slPZB8.jpg" alt="slPZB8.jpg" border="0" width="80%"></a></div><p>然而，如果是将所有输入数据编码到同一个分布里，从这个分布中随机采样的样本$Z_i$无法与输入样本$X_i$一一对应，会影响模型的学习效果。所以，实际的变分自编码器结构如下图所示，为每一个输入样本学习一个正态分布：</p><div align="center"><a href="https://imgchr.com/i/slPgED" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slPgED.jpg" alt="slPgED.jpg" border="0" width="80%"></a></div><p>采样时常用”重参数”技巧(reparameterization trick)，从分布$N(\mu,\sigma^2)$中采样一个$Z$相当于从$N(0,1)$中采样一个$\epsilon$使得$Z=\mu+\sigma*\epsilon$。</p><h4 id="图变分自编码器"><a href="#图变分自编码器" class="headerlink" title="图变分自编码器"></a>图变分自编码器</h4><p>介绍完传统的变分自编码器，接下来就是介绍这篇论文的工作，如何将变分自编码器的思想迁移到图上。</p><p>针对图这个数据结构，输入的数据变为图的邻接矩阵$A$与特征矩阵$X$：<br>邻接矩阵$A$：</p><div align="center"><a href="https://imgchr.com/i/slFHhQ" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slFHhQ.jpg" alt="slFHhQ.jpg" border="0" width="60%"></a></div><p>特征矩阵$X$：</p><div align="center"><a href="https://imgchr.com/i/slFz7T" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slFz7T.jpg" alt="slFz7T.jpg" border="0" width="60%"></a></div><p>接下来的工作与变分自编码器相同，通过编码器（图卷积）学习图中顶点低维向量表示分布的均值$\mu$与方差$\sigma^2$，再通过解码器生成图。</p><div align="center"><a href="https://imgchr.com/i/slk1gA" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2021/01/10/slk1gA.jpg" alt="slk1gA.jpg" border="0" width="80%"></a></div><p>编码器采用两层结构的图卷积网络，第一层产生一个低维的特征矩阵：</p><script type="math/tex; mode=display">\bar{X}=\text{GCN}(X,A)=\text{ReLU}(\tilde{A}XW_0)\\\tilde{A}=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}</script><p>第二层得到分布的均值$\mu$与方差$\sigma^2$：</p><script type="math/tex; mode=display">\mu=\text{GCN}_{\mu}(X,A)=\tilde{A}\bar{X}W_1\\\log\sigma^2=\text{GCN}_{\sigma}(X,A)=\tilde{A}\bar{X}W_1</script><p>将两层网络的表达式合并可以得到编码器的表达式：</p><script type="math/tex; mode=display">\text{GCN}(X,A)=\tilde{A}\text{ReLU}(\tilde{A}XW_0)W_1</script><p>同样地使用重参数技巧来得到低维向量表示$Z=\mu+\sigma*\epsilon$。</p><p>编码器重构出图的邻接矩阵，从而得到一个新的图。之所以使用点积的形式来得到邻接矩阵，原因在于我们希望学习到每个顶点的低维向量表示$z$的相似程度，来更好地重构邻接矩阵。而点积可以计算两个向量之间的cosine相似度，这种距离度量方式不受量纲的影响。因此，重构的邻接矩阵可以学习到各个顶点之间的相似程度。</p><script type="math/tex; mode=display">\hat{A}=\sigma(zz^T)</script><p>损失函数用于衡量生草样本与真是样本之间的差异，但如果只用距离度量作为损失函数，为了让编码器的效果最佳，模型会将方差的值学为0，这样从正态分布中采样出来的就是定值，有利于减小生成样本和真实样本之间的差异。但这样一来，就退化成了普通的自编码器，因此在构建损失函数时，往往还会加入各独立正态分布与标准正态分布的KL散度，来使得各个正态分布逼近标准正态分布：</p><script type="math/tex; mode=display">L=E_{q(Z|X,A)}[\log p(A|Z)]-\text{KL}[q(Z|X,A)||p(Z)],\quad where\quad p(Z)=N(0,1)</script><h3 id="数据集-11"><a href="#数据集-11" class="headerlink" title="数据集"></a>数据集</h3><p>Cora、Citeseer、Pubmed</p><h1 id="知识图谱"><a href="#知识图谱" class="headerlink" title="知识图谱"></a>知识图谱</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对看过的论文做一个记录&lt;/p&gt;
    
    </summary>
    
    
      <category term="推荐系统" scheme="http://Bithub00.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>d2l学习笔记</title>
    <link href="http://Bithub00.com/2020/08/25/d2l/"/>
    <id>http://Bithub00.com/2020/08/25/d2l/</id>
    <published>2020-08-25T04:07:04.464Z</published>
    <updated>2020-09-29T07:23:19.267Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/d2l-ai/d2l-en" target="_blank" rel="noopener">Dive into Deep Learning</a>学习笔记</p><a id="more"></a><h1 id="d2l学习记录"><a href="#d2l学习记录" class="headerlink" title="d2l学习记录"></a>d2l学习记录</h1><h2 id="第二章-Preliminaries"><a href="#第二章-Preliminaries" class="headerlink" title="第二章 Preliminaries"></a>第二章 Preliminaries</h2><ol><li>用with torch.no_grad()将不想被追踪的操作代码块包裹起来，这种方法在评估模型的时候很常用，因为在评估模型时，我们并不需要计算可训练参数（requires_grad=True）的梯度。</li><li>grad在反向传播过程中是累加的(accumulated)，这意味着每一次运行反向传播，梯度都会累加之前的梯度，所以一般在反向传播之前需把梯度清零。</li><li>在y.backward()时，如果y是标量，则不需要为backward()传入任何参数；否则，需要传入一个与y同形的Tensor。</li><li>view()返回的新Tensor与源Tensor虽然可能有不同的size，但是是共享data的，也即更改其中的一个，另外一个也会跟着改变。</li><li>在测试模型时，我们为了拿到更加确定性的结果，一般需要关闭dropout。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> isinstance(net, torch.nn.Module):</span><br><span class="line">            net.eval() <span class="comment"># 评估模式, 这会关闭dropout</span></span><br><span class="line">            acc_sum += (net(X).argmax(dim=<span class="number">1</span>) == y).float().sum().item()</span><br><span class="line">            net.train() <span class="comment"># 改回训练模式</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="第三章-Linear-Neural-Networks"><a href="#第三章-Linear-Neural-Networks" class="headerlink" title="第三章 Linear Neural Networks"></a>第三章 Linear Neural Networks</h2><h3 id="cross-entropy-loss"><a href="#cross-entropy-loss" class="headerlink" title="cross-entropy loss"></a>cross-entropy loss</h3><p>给定含n个样本的数据集$\{X,Y\}$，我们可以通过将模型的预测标签与实际标签进行比较来查看模型的效果，即最大化$P(Y|X)=\prod_{i=1}^nP(y^{(i)}|x^{(i)})$，根据最大似然准则，这等同于最小化负的对数似然函数：</p><script type="math/tex; mode=display">-\log P(Y|X)=\sum_{i=1}^{n}-\log P(y^{(i)}|x^{(i)})=\sum_{i=1}^{n}l(y^{(i)}|\hat{y}^{(i)})</script><p>假设数据集中共有q个类别，则给定真实标签$y$与模型预测标签$\hat{y}$，损失函数l为所谓的交叉熵：</p><script type="math/tex; mode=display">l(y,\hat{y})=-\sum^q_{j=1}y_j\log\hat{y_j}</script><p>代入softmax的表达式：</p><script type="math/tex; mode=display">\begin{aligned}l(y,\hat{y})&= -\sum_{j=1}^qy_j\log \frac{\exp(o_j)}{\sum^q_{k=1}\exp(o_k)} \\&= \sum^q_{j=1}y_j\log \sum^q_{k=1}\exp (o_k)-\sum^q_{k=1}y_j\log \exp (o_j) \\&= \log \sum^q_{k=1}\exp (o_k)-\sum^q_{j=1}y_jo_j\end{aligned}</script><p>softmax可以看作是一个单层神经网络：<br><img src="https://s1.ax1x.com/2020/09/13/wBP7xf.png" alt="wBP7xf.png"></p><p>将损失函数对任意一个$o_j$求导，得到：</p><script type="math/tex; mode=display">\partial_{o_j}l(y,\hat{y}) = \frac{\exp(o_j)}{\sum^q_{k=1}\exp(o_k)} - y_j = softmax(o)_j-y_j</script><p>这表示模型预测标签与真实标签之间的差距。在任意指数族模型中，对数似然函数的梯度都是这样的形式。</p><p>对交叉熵的形式做更深入的理解，给定一个分布p，信息论指出，该分布的熵为  </p><script type="math/tex; mode=display">H[p]=\sum_j-p(j)\log p(j)</script><p>给定一个需要压缩的数据流，如果数据流中的数据是完全一致的，则预测下一个数据和对数据进行压缩是非常简单的。当我们不能准确预测下一个数据j，预测结果与实际结果之间的差别会带来所谓的surprisal，用数学形式表达为$\log \frac{1}{P(j)}=-\log P(j)$。<br>The cross-entropy from p to q, denoted H(p,q), is the expected surprisal of an observer with subjective probabilities p.</p><h2 id="第五章-Deep-Learning-Computation"><a href="#第五章-Deep-Learning-Computation" class="headerlink" title="第五章 Deep Learning Computation"></a>第五章 Deep Learning Computation</h2><ol><li><p>如果一个Tensor是Parameter，那么它会自动被添加到模型的参数列表里。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></span><br><span class="line">        super(MyModel, self).__init__(**kwargs)</span><br><span class="line">        self.weight1 = nn.Parameter(torch.rand(<span class="number">20</span>, <span class="number">20</span>))</span><br><span class="line">        self.weight2 = torch.rand(<span class="number">20</span>, <span class="number">20</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">n = MyModel()</span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> n.named_parameters():</span><br><span class="line">    print(name)</span><br><span class="line"></span><br><span class="line">weight1</span><br></pre></td></tr></table></figure></li><li><p>共享参数，如果我们传入Sequential的模块是同一个Module实例的话参数也是共享的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FancyMLP</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></span><br><span class="line">        super(FancyMLP, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">        self.rand_weight = torch.rand((<span class="number">20</span>, <span class="number">20</span>), requires_grad=<span class="keyword">False</span>) <span class="comment"># 不可训练参数（常数参数）</span></span><br><span class="line">        self.linear = nn.Linear(<span class="number">20</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.linear(x)</span><br><span class="line">        <span class="comment"># 使用创建的常数参数，以及nn.functional中的relu函数和mm函数</span></span><br><span class="line">        x = nn.functional.relu(torch.mm(x, self.rand_weight.data) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 复用全连接层。等价于两个全连接层共享参数</span></span><br><span class="line">        x = self.linear(x)</span><br><span class="line">        <span class="comment"># 控制流，这里我们需要调用item函数来返回标量进行比较</span></span><br><span class="line">        <span class="keyword">while</span> x.norm().item() &gt; <span class="number">1</span>:</span><br><span class="line">            x /= <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> x.norm().item() &lt; <span class="number">0.8</span>:</span><br><span class="line">            x *= <span class="number">10</span></span><br><span class="line">        <span class="keyword">return</span> x.sum()</span><br></pre></td></tr></table></figure></li><li><p>如果一个Tensor是Parameter，那么它会自动被添加到模型的参数列表里。所以在自定义含模型参数的层时，我们应该将参数定义成Parameter。</p></li><li>PyTorch中保存和加载训练模型推荐保存和加载state_dict。state_dict是一个从参数名称隐射到参数Tesnor的字典对象。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(MLP, self).__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        self.act = nn.ReLU()</span><br><span class="line">        self.output = nn.Linear(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        a = self.act(self.hidden(x))</span><br><span class="line">        <span class="keyword">return</span> self.output(a)</span><br><span class="line"></span><br><span class="line">net = MLP()</span><br><span class="line">net.state_dict()</span><br><span class="line"></span><br><span class="line">OrderedDict([(<span class="string">'hidden.weight'</span>, tensor([[ <span class="number">0.2448</span>,  <span class="number">0.1856</span>, <span class="number">-0.5678</span>],</span><br><span class="line">                      [ <span class="number">0.2030</span>, <span class="number">-0.2073</span>, <span class="number">-0.0104</span>]])),</span><br><span class="line">             (<span class="string">'hidden.bias'</span>, tensor([<span class="number">-0.3117</span>, <span class="number">-0.4232</span>])),</span><br><span class="line">             (<span class="string">'output.weight'</span>, tensor([[<span class="number">-0.4556</span>,  <span class="number">0.4084</span>]])),</span><br><span class="line">             (<span class="string">'output.bias'</span>, tensor([<span class="number">-0.3573</span>]))])</span><br><span class="line"><span class="comment"># 只有具有可学习参数的层(卷积层、线性层等)才有state_dict中的条目。优化器(optim)也有一个state_dict，其中包含关于优化器状态以及所使用的超参数的信息。</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="第八章-Recurrent-Neural-Networks"><a href="#第八章-Recurrent-Neural-Networks" class="headerlink" title="第八章 Recurrent Neural Networks"></a>第八章 Recurrent Neural Networks</h2><ol><li><p>scatter() 一般可以用来对标签进行 one-hot 编码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># self[i][ index[i][j][k] ][k] = src[i][j][k]  # if dim == 1</span></span><br><span class="line"></span><br><span class="line">class_num = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">label = torch.LongTensor(batch_size, <span class="number">1</span>).random_() % class_num</span><br><span class="line"><span class="comment">#tensor([[6],</span></span><br><span class="line"><span class="comment">#        [0],</span></span><br><span class="line"><span class="comment">#        [3],</span></span><br><span class="line"><span class="comment">#        [2]])</span></span><br><span class="line">torch.zeros(batch_size, class_num).scatter_(<span class="number">1</span>, label, <span class="number">1</span>)</span><br><span class="line"><span class="comment">#tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])</span></span><br></pre></td></tr></table></figure></li><li><p>在随机采样中，每个样本是原始序列上任意截取的一段序列。相邻的两个随机小批量在原始序列上的位置不一定相毗邻。因此，我们无法用一个小批量最终时间步的隐藏状态来初始化下一个小批量的隐藏状态。在训练模型时，每次随机采样前都需要重新初始化隐藏状态。</p></li><li>另一方面，当多个相邻小批量通过传递隐藏状态串联起来时，模型参数的梯度计算将依赖所有串联起来的小批量序列。同一迭代周期中，随着迭代次数的增加，梯度的计算开销会越来越大。 为了使模型参数的梯度计算只依赖一次迭代读取的小批量序列，我们可以在每次读取小批量前将隐藏状态从计算图中分离出来。</li><li>torch.view等方法操作需要连续的Tensor，transpose、permute 操作虽然没有修改底层一维数组，但是新建了一份Tensor元信息，并在新的元信息中的 重新指定 stride。torch.view 方法约定了不修改数组本身，只是使用新的形状查看数据。如果我们在 transpose、permute 操作后执行 view，Pytorch 会报错。<blockquote><p>Tensor多维数组底层实现是使用一块连续内存的1维数组（行优先顺序存储，下文描述），Tensor在元信息里保存了多维数组的形状，在访问元素时，通过多维度索引转化成1维数组相对于数组起始位置的偏移量即可找到对应的数据。某些Tensor操作（如transpose、permute、narrow、expand）与原Tensor是共享内存中的数据，不会改变底层数组的存储，但原来在语义上相邻、内存里也相邻的元素在执行这样的操作后，在语义上相邻，但在内存不相邻，即不连续了（is not contiguous）。</p></blockquote></li></ol><h2 id="第十一章-Optimization-Algorithms"><a href="#第十一章-Optimization-Algorithms" class="headerlink" title="第十一章 Optimization Algorithms"></a>第十一章 Optimization Algorithms</h2><h3 id="动量法"><a href="#动量法" class="headerlink" title="动量法"></a>动量法</h3><p>如果同一位置上，目标函数在竖直方向($x_2$轴方向）比在水平方向（$x_1$轴方向）的斜率的绝对值更大，则给定学习率，梯度下降迭代自变量时会使自变量在竖直方向比在水平方向移动幅度更大。那么，我们需要一个较小的学习率从而避免自变量在竖直方向上越过目标函数最优解。然而，这会造成自变量在水平方向上朝最优解移动变慢。  </p><p>动量法看作是对最近$1/(1−γ)$个时间步的$x_t$值的加权平均，而且离当前时间步$t$越近的$x_t$值获得的权重越大。动量法在每个时间步的自变量更新量近似于将最近1/(1−γ)个时间步的普通更新量（即学习率乘以梯度）做了指数加权移动平均后再除以1−γ。所以，在动量法中，自变量在各个方向上的移动幅度不仅取决当前梯度，还取决于过去的各个梯度在各个方向上是否一致。</p><h3 id="AdaGrad和RMSProp"><a href="#AdaGrad和RMSProp" class="headerlink" title="AdaGrad和RMSProp"></a>AdaGrad和RMSProp</h3><p>如果目标函数有关自变量中某个元素的偏导数一直都较大，那么该元素的学习率将下降较快；反之，如果目标函数有关自变量中某个元素的偏导数一直都较小，那么该元素的学习率将下降较慢。然而，由于$s_t$一直在累加按元素平方的梯度，自变量中每个元素的学习率在迭代过程中一直在降低（或不变）。所以，当学习率在迭代早期降得较快且当前解依然不佳时，AdaGrad算法在迭代后期由于学习率过小，可能较难找到一个有用的解。  </p><p>不同于AdaGrad算法里状态变量$s_t$是截至时间步$t$所有小批量随机梯度$g_t$按元素平方和，RMSProp算法将这些梯度按元素平方做指数加权移动平均。$s_t$所以可以看作是最近1/(1−γ)个时间步的小批量随机梯度平方项的加权平均。如此一来，自变量每个元素的学习率在迭代过程中就不再一直降低（或不变）。</p><p>Adam算法在RMSProp算法基础上对小批量随机梯度也做了指数加权移动平均。</p><h2 id="第十四章-自然语言处理"><a href="#第十四章-自然语言处理" class="headerlink" title="第十四章 自然语言处理"></a>第十四章 自然语言处理</h2><ol><li>求类比词问题可以定义为：对于类比关系中的4个词 $a:b::c:d$，给定前3个词$a、b和c，求d$。设词$w$的词向量为$vec(w)$，求类比词的思路是，搜索与$vec(c)+vec(b)-vec(a)$的结果向量最相似的词向量。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/d2l-ai/d2l-en&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Dive into Deep Learning&lt;/a&gt;学习笔记&lt;/p&gt;
    
    </summary>
    
    
      <category term="深度学习" scheme="http://Bithub00.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>CUDA学习笔记</title>
    <link href="http://Bithub00.com/2020/07/15/CUDA%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    <id>http://Bithub00.com/2020/07/15/CUDA学习记录/</id>
    <published>2020-07-15T13:04:08.623Z</published>
    <updated>2020-10-10T01:22:12.231Z</updated>
    
    <content type="html"><![CDATA[<p>CUDA编程的学习笔记以及踩过的一些坑<br><a id="more"></a></p><h1 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h1><h2 id="CUDA程序的执行流程："><a href="#CUDA程序的执行流程：" class="headerlink" title="CUDA程序的执行流程："></a>CUDA程序的执行流程：</h2><ol><li>分配host内存，并进行数据初始化；</li><li>分配device内存，并从host将数据拷贝到device上；</li><li>调用CUDA的核函数在device上完成指定的运算；</li><li>将device上的运算结果拷贝到host上；</li><li>释放device和host上分配的内存。</li></ol><p>上面流程中最重要的一个过程是调用CUDA的核函数来执行并行计算，核函数用<strong>global</strong>符号声明，它在device上执行时实际上是启动很多线程，一个kernel所启动的所有线程称为一个网格（grid），同一个网格上的线程共享相同的全局内存空间，而网格又可以分为很多线程块（block），一个线程块里面包含很多线程。这构成了两层结构。</p><p><img src="https://s1.ax1x.com/2020/07/15/U0Mzd0.png" alt=""></p><h2 id="CUDA内存模型"><a href="#CUDA内存模型" class="headerlink" title="CUDA内存模型"></a>CUDA内存模型</h2><p>每个线程有自己的私有本地内存（Local Memory），而每个线程块（Block）有包含共享内存（Shared Memory）,可以被线程块中所有线程共享，其生命周期与线程块一致。此外，所有的线程都可以访问全局内存（Global Memory）。还可以访问一些只读内存块：常量内存（Constant Memory）和纹理内存（Texture Memory）</p><h2 id="如何使用CUDA对程序进行优化"><a href="#如何使用CUDA对程序进行优化" class="headerlink" title="如何使用CUDA对程序进行优化"></a>如何使用CUDA对程序进行优化</h2><ol><li>使用共享内存减少全局内存读取次数；从常量内存（Constant Memory）中读取数据相较于全局内存会更节省内存带宽，因为常量内存是缓存的，从相同的地址中连续读取数据不会带来额外的内存读取开销。</li><li>流并行；通过多个流（stream）进行操作时，应该将所做的操作尽可能广地安排在各个流中，而不是尽可能地深，例如将内存拷贝和计算并行，其中的原理是：同一时刻cuda程序可以同时进行一个计算和数据传输。<br><img src="https://s1.ax1x.com/2020/07/15/U01S8U.png" alt="Stream1"><br><img src="https://s1.ax1x.com/2020/07/15/U01p2F.png" alt="Stream2"></li><li>合并访问；线程块内相邻的线程访问相邻的数据。因为半束(16)线程的访问16字节的数据可以合为一个访问指令。</li><li>使用零复制、锁页内存；零复制（zero copy）是一种特殊形式的内存映射，它允许你将host内存直接映射到device内存空间上。其实就是device可以通过直接内存访问（direct memory access，DMA）方式来访问host的锁页内存。 <blockquote><p>现代操作系统都支持虚拟内存，操作系统实现虚拟内存的主要方法就是通过分页机制。将内存中暂时不使用的内容换出到外存（硬盘等大容量存储）上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。锁页（page-locked host memory）就是将内存页面标记为不可被操作系统换出的内存。所以device可以使用页面的物理地址直接访问内存（DMA），从而避免从外存到内存的复制操作。在GPU上分配的内存默认都是锁页内存，这是因为GPU不支持将内存交换到磁盘上。在CPU上分配的内存默认都是可分页。</p></blockquote></li></ol><h2 id="重构时的问题及解决"><a href="#重构时的问题及解决" class="headerlink" title="重构时的问题及解决"></a>重构时的问题及解决</h2><ol><li><p>论文中涉及的数据结构较为复杂，在使用GPU进行并行计算时需要先将数据复制到GPU上，复制的步骤十分繁琐，容易出现内存访问出错的问题。</p><blockquote><p>CUDA6.0引入了统一内存的概念，大大简化了数据从CPU传到GPU这一步骤，只需要在host端分配好空间，写入数据，直接作为参数传入device端的核函数即可，CUDA会自动完成复制工作。</p></blockquote></li><li><p>c++中的std在CUDA中不被支持，例如std::vector、std::sort等都无法使用。</p><blockquote><p>CUDA提供了Thrust库作为替代，提供了sort、host_vector、device_vector等，然而这些都是host端的实现，在device端无法调用。</p></blockquote></li><li><p>Thrust作为host端的实现在device端无法调用，原数据结构中的类成员有vector<edge*>，在device端无法访问其中的数据。</edge*></p><blockquote><p>在后续CUDA版本中，thrust::sort可以在device端运行，只需加入参数thrust::sort(thrust::device, XX, XX)。vector在<strong>device</strong>函数中的访问仍不被支持，因此将原类成员vector<edge*>改成Edge **二维指针数组形式，vector读取完数据后，再复制到二维指针数组中，此时device端就可以访问其中的数据了。</edge*></p></blockquote></li><li><p>调试时nvcc编译带上-g参数，使用cuda-gdb运行程序，可以在cu文件中设置断点，发生段错误后可以使用where命令来查明是哪一行导致的错误。</p></li><li><p>addKernel&lt;&lt;<60,1>&gt;&gt;(devA, devB, devC);这里的&lt;&lt;<60,501>&gt;&gt;的意思是，调用函数的时候，开出60个线程格，每个线程格包含501个线程。在global函数中通过代码int i = threadIdx.x + blockIdx.x*blockDim.x;得到当前线程是第几个线程。</60,501></60,1></p></li><li><p>Host调用完kernel函数需要进行线程同步,而在kernel或global函数只需要在必要的地方__syncthreads()即可:</p></li><li><p>这时dev_b会保存一个指向GPU内存的指针,但是CPU是无法访问GPU上面的数据,所以利用这个指针做任何获取数据或者赋值都是会出错的,理解这点对传递数据很重要 </p> <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> *dev_b = <span class="number">0</span></span><br><span class="line">cudaMalloc((<span class="keyword">void</span>**)&amp;dev_b, size * <span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br></pre></td></tr></table></figure></li></ol><p>实用问答：</p><ul><li><a href="https://stackoverflow.com/questions/14790999/how-to-pass-a-c-class-with-array-of-pointers-to-cuda" target="_blank" rel="noopener">https://stackoverflow.com/questions/14790999/how-to-pass-a-c-class-with-array-of-pointers-to-cuda</a></li><li><a href="https://stackoverflow.com/questions/9309195/copying-a-struct-containing-pointers-to-cuda-device" target="_blank" rel="noopener">https://stackoverflow.com/questions/9309195/copying-a-struct-containing-pointers-to-cuda-device</a></li><li><a href="https://developer.nvidia.com/blog/unified-memory-in-cuda-6/" target="_blank" rel="noopener">统一内存</a></li><li><a href="https://www.jianshu.com/p/7e1e0e2bde79" target="_blank" rel="noopener">教你一步步写一个cuda path tracer：cuda与类</a></li><li><a href="https://zhuanlan.zhihu.com/p/55855479" target="_blank" rel="noopener">CUDA值得注意的特性(坑)</a></li><li><a href="https://stackoverflow.com/questions/11874667/cuda-allocation-of-an-array-of-structs-inside-a-struct" target="_blank" rel="noopener">https://stackoverflow.com/questions/11874667/cuda-allocation-of-an-array-of-structs-inside-a-struct</a></li><li><a href="https://forums.developer.nvidia.com/t/how-to-cudamalloc-two-dimensional-array/4042/9" target="_blank" rel="noopener">https://forums.developer.nvidia.com/t/how-to-cudamalloc-two-dimensional-array/4042/9</a></li><li><a href="https://stackoverflow.com/questions/40682163/cuda-copy-inherited-class-object-to-device" target="_blank" rel="noopener">https://stackoverflow.com/questions/40682163/cuda-copy-inherited-class-object-to-device</a></li><li><a href="https://stackoverflow.com/questions/16024087/copy-an-object-to-device" target="_blank" rel="noopener">https://stackoverflow.com/questions/16024087/copy-an-object-to-device</a></li><li><a href="https://stackoverflow.com/questions/6929626/cuda-copy-to-array-within-array-of-objects" target="_blank" rel="noopener">https://stackoverflow.com/questions/6929626/cuda-copy-to-array-within-array-of-objects</a></li><li><a href="https://stackoverflow.com/questions/5510715/thrust-inside-user-written-kernels" target="_blank" rel="noopener">https://stackoverflow.com/questions/5510715/thrust-inside-user-written-kernels</a></li><li><a href="https://stackoverflow.com/questions/14284964/cuda-how-to-allocate-memory-for-data-member-of-a-class" target="_blank" rel="noopener">https://stackoverflow.com/questions/14284964/cuda-how-to-allocate-memory-for-data-member-of-a-class</a></li><li><a href="https://forums.developer.nvidia.com/t/how-to-measure-total-time-for-cpu-and-gpu/28234/2" target="_blank" rel="noopener">https://forums.developer.nvidia.com/t/how-to-measure-total-time-for-cpu-and-gpu/28234/2</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CUDA编程的学习笔记以及踩过的一些坑&lt;br&gt;
    
    </summary>
    
    
      <category term="CUDA" scheme="http://Bithub00.com/tags/CUDA/"/>
    
  </entry>
  
</feed>
