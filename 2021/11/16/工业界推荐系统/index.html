<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="推荐系统," />





  <link rel="alternate" href="/atom.xml" title="原力小站" type="application/atom+xml" />






<meta name="description" content="借这篇博客记录看工业界推荐系统论文的心得。">
<meta name="keywords" content="推荐系统">
<meta property="og:type" content="article">
<meta property="og:title" content="工业界推荐系统小综述">
<meta property="og:url" content="http://Bithub00.com/2021/11/16/工业界推荐系统/index.html">
<meta property="og:site_name" content="原力小站">
<meta property="og:description" content="借这篇博客记录看工业界推荐系统论文的心得。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://s4.ax1x.com/2021/12/07/oc1Tij.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BqpB6.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BOiSH.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BzKQe.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4DSqNq.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4D9nzT.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/25/4skSbT.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/25/4rJKYR.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/25/4rtbWR.png">
<meta property="og:image" content="https://s4.ax1x.com/2021/12/06/os5zsP.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/25/4skFPJ.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/25/4sk3RA.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/11/16/IWxx1O.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/11/18/IobKZd.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/11/18/ITm75R.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/11/25/oFhlFI.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/11/25/oFhlFI.jpg">
<meta property="og:updated_time" content="2021-12-16T15:05:06.524Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="工业界推荐系统小综述">
<meta name="twitter:description" content="借这篇博客记录看工业界推荐系统论文的心得。">
<meta name="twitter:image" content="https://s4.ax1x.com/2021/12/07/oc1Tij.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://Bithub00.com/2021/11/16/工业界推荐系统/"/>





  <title>工业界推荐系统小综述 | 原力小站</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?43ca6a51990599ac3de948cb708d3909";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://github.com/BitHub00" 
      class="github-corner" 
      aria-label="View source on Github">
      <svg width="80" height="80" viewBox="0 0 250 250" 
      style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" 
      aria-hidden="true">
      <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
      <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
      <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path>
      </svg>
    </a>
      <style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}
      </style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">原力小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">扎导的原版正联出了吗？</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://Bithub00.com/2021/11/16/工业界推荐系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.shuan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="原力小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">工业界推荐系统小综述</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-11-16T17:54:46+08:00">
                2021-11-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2021/11/16/工业界推荐系统/" class="leancloud_visitors" data-flag-title="工业界推荐系统小综述">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  14,589
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>借这篇博客记录看工业界推荐系统论文的心得。</p>
<a id="more"></a>
<p>[TOC]</p>
<h3 id="问题与挑战"><a href="#问题与挑战" class="headerlink" title="问题与挑战"></a>问题与挑战</h3><ul>
<li><strong>列表展示中的正负样本选择</strong>：物品曝光，并不代表用户注意到了。因此选择用户在推荐列表最下面的一个点击位置以上的曝光作为负样本区域。例如以下展示列表和点击动作情况（最下一个点击位为7），使用3、7为正样本，1、2、4、5、6为负样本。而8、9、10等位置虽然曝光但用户可能并未看到，丢弃该数据。</li>
</ul>
<div align="center">
  <a href="https://imgtu.com/i/oc1Tij" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2021/12/07/oc1Tij.png" alt="oc1Tij.png" border="0"></a>
</div>
* **样本冲突**：物品可以重复推荐，这样就存在用户选择前后矛盾的情况，即对于同一个物品上次用户选择点击，而这次选择不点击，或者反过来上次选择不点击，这次选择点击。对于一个时效性要求较高的系统，将这两种情况的数据都作为样本加入系统，可以增加模型对时效性特征的理解。24小时之内，存在正负样本冲突的，仅保留正样本。同时如果24小时之内有多个负样本，仅保留最后也就是最新的负样本。

* **数据穿透**：特征数据一定要选取样本发生时刻之前的，如果选取了样本时刻之后的特征，相当于在学习阶段，让模型知道了标准答案，使得模型仅学会了对答案进行抄袭，而在上线预测时，标准答案还存在于尚未发生的未来的，模型此时得不到标准答案，预测结果就很差。

  由于CTR预估对实时性要求高，实际过程中存在另外一种数据穿透的情况，线上数据延迟带来的穿透。即，在离线训练阶段，如果选取样本时刻之前的所有特征，这些特征本来是没有穿透的，但是上线阶段，由于前端、后台、数据系统等等存在一些延迟，最近时间的一些特征在预测时并没有流入推荐系统，导致线上预测阶段，模型拿到的是残缺的数据。这样会导致模型离线阶段效果还不错，线上阶段预测效果就不好的情况。

  面对这个问题，在算法离线训练阶段，就不考虑样本最近一段时间的特征数据，即让模型只使用残缺的数据学习，逼迫模型从残缺的数据中发掘数据关联，即不依赖线上容易发生延迟的数据部分。这个处理会使得线下AUC指标降低，即降低了算法上限，但在数据延迟的情况下有更好的健壮性。

## Logistics Regression

本节主要参考[刘启林的推荐系统](https://zhuanlan.zhihu.com/p/151036015)

逻辑回归是推荐领域的经典模型之一，回归是指将值回归到[0,1]区间。

### 做法及创新

#### 核心思想

LR将线性回归模型与Sigmoid函数相结合，线性回归模型的常见形式为$y=w^Tx+b$，为了表达形式上的统一，常将$w_0=b,x_0=1$，则有下图的$y=\sum_{i=0}^nw_ix_i=w^Tx$：

[![4BEwJs.jpg](https://z3.ax1x.com/2021/09/24/4BEwJs.jpg)](https://imgtu.com/i/4BEwJs)

LR按照输出y的取值可以分为$y\in\{0,1\}、y\in\{-1,1\}$两种形式：

* CTR预估（0：曝光后未被点击，1：曝光后被点击）

  > 伯努利分布：随机变量X只能取0和1两个值：
  > $$
  > P(X=k)=p^k(1-p)^{1-k},~k={0,1}
  > $$

  [![4BVanK.jpg](https://z3.ax1x.com/2021/09/24/4BVanK.jpg)](https://imgtu.com/i/4BVanK)

* 分类预估（-1：负类，1：正类）

  [![4BVNX6.jpg](https://z3.ax1x.com/2021/09/24/4BVNX6.jpg)](https://imgtu.com/i/4BVNX6)

#### 损失函数

[![4BZZUe.jpg](https://z3.ax1x.com/2021/09/24/4BZZUe.jpg)](https://imgtu.com/i/4BZZUe)

[![4BZnCd.jpg](https://z3.ax1x.com/2021/09/24/4BZnCd.jpg)](https://imgtu.com/i/4BZnCd)
[![4BZVED.jpg](https://z3.ax1x.com/2021/09/24/4BZVED.jpg)](https://imgtu.com/i/4BZVED)

[![4BZgPJ.jpg](https://z3.ax1x.com/2021/09/24/4BZgPJ.jpg)](https://imgtu.com/i/4BZgPJ)
[![4BZ654.jpg](https://z3.ax1x.com/2021/09/24/4BZ654.jpg)](https://imgtu.com/i/4BZ654)

[![4Besyt.jpg](https://z3.ax1x.com/2021/09/24/4Besyt.jpg)](https://imgtu.com/i/4Besyt)
[![4BerQI.jpg](https://z3.ax1x.com/2021/09/24/4BerQI.jpg)](https://imgtu.com/i/4BerQI)
[![4BeDSA.jpg](https://z3.ax1x.com/2021/09/24/4BeDSA.jpg)](https://imgtu.com/i/4BeDSA)

#### 特征工程

* 适合离散特征；增加、减少特征容易，易于拟合、快速迭代
* 特征空间大，容易过拟合；
* 去掉高度相关特征；

## Wide & Deep Learning for Recommender Systems[DLRS'16]

### 解决的问题

解决推荐时Memorization和Generalization无法兼顾的问题。

#### Memorization

面对拥有大规模离散sparse特征的CTR预估问题时，可以通过将特征之间进行叉乘来捕捉特征之间的相关性，典型代表如LR模型，使用原始sparse特征和叉乘特征作为输入。但缺点是特征的叉乘需要人工进行设计，而且对于训练数据中未曾出现过的特征对，模型中对应项的权重也会为0.

#### Generalization

Generalization为sparse特征学习低维的dense embeddings来捕获相关性，它相较于Memorization涉及更少的人工设计以及更好的泛化能力，即使训练数据中未曾出现的特征对，对应的权重也会因为各自的dense embeddings而非零。但缺点也是会带来过度泛化，当user-item矩阵非常稀疏时，例如小众爱好的user和冷门商品，这时大部分user-item应该是没有关联的，但dense embedding还是能得到非零预测，导致推荐不怎么相关的商品，这时Memorization更好，因为它可以记忆这些特殊的特征组合。

Memorization根据历史行为数据，产生的推荐通常和用户已有行为的物品直接相关的物品。而Generalization会学习新的特征组合，提高推荐物品的多样性。 论文作者结合两者的优点，提出了一个新的学习算法——Wide & Deep Learning，其中Wide & Deep分别对应Memorization & Generalization。

[![4KtfW8.png](https://z3.ax1x.com/2021/09/17/4KtfW8.png)](https://imgtu.com/i/4KtfW8)

### 做法及创新

#### 网络结构

**Wide**部分是一个广义线性模型，其中$x$和$\phi(x)$表示原始特征和叉乘特征：
$$
y=w^T[x,\phi(x)]+b
$$
原始特征$x=[x_1,x_2,\cdots,x_d]$有$d$维，叉乘特征的构造方式为：$\phi_k(x)=\Pi_{i=1}^dx_i^{c_{ki}},~c_{ki}\in\{0,1\}$

其实就是用一个布尔变量来标示哪些特征进行了叉乘。

**Deep**部分是前馈神经网络，它会对一些sparse特征（如ID类特征）学习一个dense embeddings，维度在O(10)到O(100)之间。
$$
a^{l+1}=f(W^la^l+b^l)
$$
**损失函数**选取的是logistic损失函数，模型最后的预测输出为，其中$a^{l_f}$是神经网络最后一层的激活值：
$$
p(y=1|x)=\sigma(w^T_{wide}[x,\phi(x)]+w^T_{deep}a^{l_f}+b)
$$
**联合训练**时Wide部分只需要做一小部分的特征叉乘来弥补Deep部分的不足，不需要一个完整的Wide模型。优化方法使用的是mini-batch随机梯度下降，Wide部分是带L1正则的FTRL算法，Deep部分是AdaGrad算法。

[![4KB1ts.png](https://z3.ax1x.com/2021/09/17/4KB1ts.png)](https://imgtu.com/i/4KB1ts)

实验部分采取的模型设置如上图所示，其中的细节为：

* 连续型特征会被归一化到[0,1]之间
* 离散型特征映射到32维embeddings，与原始连续特征共1200维作为网络输入
* Wide部分只有一组特征叉乘，被推荐的App×用户下载的App，希望Wide部分能发现这样的规则：用户安装了应用A，此时曝光应用B，用户安装的B概率大。
* 线上模型更新时，用上次的embeddings和模型参数进行”热启动“

#### 实践细节

1. 为什么Wide部分要用L1 FTRL训练？

   FTRL的介绍可见[文章](https://github.com/wzhe06/Ad-papers/blob/master/Optimization%20Method/%E5%9C%A8%E7%BA%BF%E6%9C%80%E4%BC%98%E5%8C%96%E6%B1%82%E8%A7%A3(Online%20Optimization)-%E5%86%AF%E6%89%AC.pdf)。这种方式注重模型的稀疏性，能让Wide部分变得更加稀疏，大部分权重都为0。

2. 为什么Deep部分不考虑稀疏性的问题？

   Deep部分的输入，要么是Age，App Installs这些数值类特征，要么是已经降维并稠密化的Embeddings向量。所以Deep部分不存在严重的特征稀疏问题，自然可以使用精度更好，更适用于深度学习训练的AdaGrad去训练。



## Factorization Machines

本节内容主要参考[刘启林的推荐系统](https://zhuanlan.zhihu.com/p/145436595)

### 解决的问题

因子分解机在线性回归模型中加入了特征的交互，来建模特征的相关性，并且解决数据的稀疏性以及特征空间维度过高的问题。

对于常见的categorical特征，经过one-hot编码以后，样本的数据就会变得很稀疏。举例来说，假设淘宝或者京东上的item为100万，如果对item这个维度进行one-hot编码，光这一个维度数据的稀疏度就是百万分之一。将item进行one-hot编码以后，样本空间有一个categorical变为了百万维的数值特征，特征空间也会一下子暴增一百万。

### 做法及创新

#### 核心思想

线性回归模型假设特征之间相互独立：
$$
y=w_0+\sum_{i=1}^nw_ix_i
$$
而现实场景中，特征之间是有相关性的，例如<程序员>与<计算机类书籍>，因此需要在线性回归模型中加入特征组合项。最简单的组合方式是两两组合，变为二阶多项式回归模型，多出$\frac{n(n-1)}{2}$项：
$$
y=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^n\sum_{j\ge i}^nw_{ij}x_ix_j
$$
这样做的局限是对于样本中没出现过交互的特征组合，就无法对相应的参数进行估计，而且时间复杂度上升到了$O(n^2)$。

上式中的二项式参数$w_{ij}$可以组成一个对称矩阵$W$，根据Cholesky分解可以分解成：

> Cholesky分解：将一个对称正定矩阵化为一个下三角矩阵与其共轭转置矩阵的积

$$
W=VV^T
$$

二次项参数转化为$w_{ij}=<v_i,v_j>=\sum_{f=1}^kv_{i,f}v_{j,f}$，此时隐向量的特征维度$k$一般远小于原始特征维度$n$。$v_i\in \mathbb{R}^k$是特征i的嵌入向量。FM的假设是，特征两两相关。

#### 计算化简

FM的计算复杂度可以化简为线性复杂度：

[![4ahAk6.jpg](https://z3.ax1x.com/2021/09/23/4ahAk6.jpg)](https://imgtu.com/i/4ahAk6)

[![4ahMnA.jpg](https://z3.ax1x.com/2021/09/23/4ahMnA.jpg)](https://imgtu.com/i/4ahMnA)

[![4ahhH1.jpg](https://z3.ax1x.com/2021/09/23/4ahhH1.jpg)](https://imgtu.com/i/4ahhH1)

#### 损失函数

FM模型可用于回归（Regression）、二分类（Binary classification）、排名（Ranking）任务，其对应的损失函数如下：

[![4a4d2D.jpg](https://z3.ax1x.com/2021/09/23/4a4d2D.jpg)](https://imgtu.com/i/4a4d2D)

[![4a5Uwn.jpg](https://z3.ax1x.com/2021/09/23/4a5Uwn.jpg)](https://imgtu.com/i/4a5Uwn)

以随机梯度下降训练为例：

[![4aIt1O.jpg](https://z3.ax1x.com/2021/09/23/4aIt1O.jpg)](https://imgtu.com/i/4aIt1O)

[![4aovQS.jpg](https://z3.ax1x.com/2021/09/23/4aovQS.jpg)](https://imgtu.com/i/4aovQS)

#### 特征工程

FM模型对特征两两自动组合，不需要人工参与，类别特征One-Hot化，以一个电影数据集为例：

[![4aT2wj.jpg](https://z3.ax1x.com/2021/09/23/4aT2wj.jpg)](https://imgtu.com/i/4aT2wj)

[![4aTRTs.jpg](https://z3.ax1x.com/2021/09/23/4aTRTs.jpg)](https://imgtu.com/i/4aTRTs)

[![4aTIpV.jpg](https://z3.ax1x.com/2021/09/23/4aTIpV.jpg)](https://imgtu.com/i/4aTIpV)



## Field-aware Factorization Machines for CTR Prediction[RecSys'16]

本节主要参考[深入FFM原理与实践](https://tech.meituan.com/2016/03/03/deep-understanding-of-ffm-principles-and-practices.html)、[FFM模型理论和实践](https://www.jianshu.com/p/781cde3d5f3d)

### 解决的问题

FM在遇到one-hot类型的特征时遇到的数据稀疏性问题。

### 做法及创新

#### 核心思想

FFM模型中引入了域（field）的概念，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个域，包括用户国籍，广告类型，日期等等，以一条CTR点击数据为例，说明FFM与FM的区别：

| Clicked | Publisher(P) | Advertiser(A) | Gender(G) |
| :-----: | :----------: | :-----------: | :-------: |
|   Yes   |     ESPN     |     Nike      |   Male    |

对于FM，只会考虑二次交叉项：
$$
\phi_{FM}=V_{ESPN}\cdot V_{Nike}+V_{ESPN}\cdot V_{Male}+V_{Nike}\cdot V_{Male}
$$
因为Nike与Male显然属于不同的field，所以（ESPN，Nike）和（ESPN，Male）的隐含含义也可能是不同的，而FM只用一个隐向量$V_{ESPN}$来统一表示ESPN与Nike和Maled的交互作用，不够准确。而在FFM中，域之间的交互作用是不同的，每个特征有k个隐向量个数，k为其余特征field的个数：
$$
\phi_{FFM}=V_{ESPN,A}\cdot V_{Nike,P}+V_{ESPN,G}\cdot V_{Male,P}+V_{Nike,G}\cdot V_{Male,A}
$$
所以FFM的数学表达式为：
$$
\phi_{FFM}(w,x)=\sum_{i=1}^n\sum_{j\ge i}^nw_{i,f_j}\cdot w_{j,f_i}x_ix_j
$$
FFM的参数个数为kfn，FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型。值得注意的是，由于隐向量与field相关，所以FFM中的二次项不能够化简，它的时间复杂度为$O(kn^2)$。

#### 实践细节

1. 样本归一化。FFM默认是进行样本数据的归一化，否则容易造成数据inf溢出，进而引起梯度计算的nan错误。因此，样本层面的数据是推荐进行归一化的。
2. 特征归一化。CTR/CVR模型采用了多种类型的源特征，包括数值型和categorical类型等。但是，categorical类编码后的特征取值只有0或1，较大的数值型特征会造成样本归一化后categorical类生成特征的值非常小，没有区分性。例如，一条用户-商品记录，用户为“男”性，商品的销量是5000个（假设其它特征的值为零），那么归一化后特征“sex=male”（性别为男）的值略小于0.0002，而“volume”（销量）的值近似为1。特征“sex=male”在这个样本中的作用几乎可以忽略不计，这是相当不合理的。因此，将源数值型特征的值归一化到[0,1]是非常必要的。
3. 省略零值特征。零值特征对模型完全没有贡献。包含零值特征的一次项和组合项均为零，对于训练模型参数或者目标值预估是没有作用的。因此，可以省去零值特征，提高FFM模型训练和预测的速度，这也是稀疏样本采用FFM的显著优势。



## DeepFM: A Factorization-Machine based Neural Network for CTR Prediction[IJCAI'17]

本节主要参考[深度学习在推荐的技术进展及微博的应用](https://static001.geekbang.org/con/33/pdf/1511951900/file/%E6%9C%80%E7%BB%88%E7%89%88-%E5%BC%A0%E4%BF%8A%E6%9E%97-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%9A%84%E6%8A%80%E6%9C%AF%E8%BF%9B%E5%B1%95%E5%8F%8A%E5%BE%AE%E5%8D%9A%E7%9A%84%E5%BA%94%E7%94%A8.pdf)、[DeepFM模型理论与实践](https://www.jianshu.com/p/6f1c2643d31b)

### 解决的问题

对于一个基于CTR预估的推荐系统，最重要的是学习到用户点击行为背后隐含的特征组合。举例来说，在主流的app市场上，我们发现，用户喜欢在用餐时间下载送餐app， 说明二阶交叉特征“app类别-时间戳” 可以作为CTR预估的重要特征。另一个发现， 男青年喜欢射击游戏和RPG游戏，因此，三阶交叉特征“app类别-用户性别-用户年龄”也可以作为CTR预估的一个特征。但是这种交叉特征往往需要专家知识，类似“尿布-啤酒”这种经典的例子。

前面提到的FM虽然理论上来讲可以对高阶特征组合进行建模，但实际上因为计算复杂度的原因一般都只用到了二阶特征组合。而多层神经网络能够学习复杂的交叉特征。

### 做法及创新

#### DNN与高维特征

虽然DNN能够学习复杂的特征组合，但直接应用于CTR预告等问题上时会在离散型特征上遇到阻碍，对于离散型特征典型的做法是进行one-hot编码，这会导致输入的数据维度非常高：

[![4wrxln.png](https://z3.ax1x.com/2021/09/23/4wrxln.png)](https://imgtu.com/i/4wrxln)

[![4wsVp9.png](https://z3.ax1x.com/2021/09/23/4wsVp9.png)](https://imgtu.com/i/4wsVp9)

类似于FFM中将特征按域来进行分类，可以将输入的one-hot数据按照域形成对应的dense vector，来避免数据稀疏性的问题：

[![4wsmOx.png](https://z3.ax1x.com/2021/09/23/4wsmOx.png)](https://imgtu.com/i/4wsmOx)

[![4wsGpd.png](https://z3.ax1x.com/2021/09/23/4wsGpd.png)](https://imgtu.com/i/4wsGpd)

[![4wscXq.png](https://z3.ax1x.com/2021/09/23/4wscXq.png)](https://imgtu.com/i/4wscXq)

[![4wyp3d.png](https://z3.ax1x.com/2021/09/23/4wyp3d.png)](https://imgtu.com/i/4wyp3d)

也就是希望能将DNN与FM进行一个融合，而融合的形式总的来说分为串行与并行，本节介绍的DeepFM以及前面介绍过的Wide&Deep都为典型的并行结构。

[![40FPt1.png](https://z3.ax1x.com/2021/09/23/40FPt1.png)](https://imgtu.com/i/40FPt1)

#### 核心思想

[![40AJoj.png](https://z3.ax1x.com/2021/09/23/40AJoj.png)](https://imgtu.com/i/40AJoj)

首先来看DeepFM的结构，FM与DNN分别负责提取低阶与高阶特征，这两部分**共享输入**，即Embedding：

[![40Eihn.png](https://z3.ax1x.com/2021/09/23/40Eihn.png)](https://imgtu.com/i/40Eihn)

DeepFM与Wide & Deep的不同之处在于，DeepFM中的wide部分使用FM来进行特征的自动交叉，而Wide & Deep中的wide部分需要人工设计特征交叉。

FM部分与标准的FM并无不同，而DNN部分，在进入第一层隐藏层之前，首先通过一个嵌入层来将输入的高维特征压缩到低维稠密向量。这一部分的两个特点为：

1. 尽管不同域的特征维度不同，在经过压缩后的维度均为k。
2. FM部分的隐向量V现在作为DNN的嵌入层权重。这样一来就不需要通过FM对隐向量V进行预训练之后对DNN的嵌入层进行初始化，而是在训练DNN时对V一起进行学习，做到端到端。

#### 实践细节



## Deep Neural Networks for YouTube Recommendations[RecSys'16]

本节要介绍的是Youtube出品的经典工业界论文，主要内容参考[王喆的机器学习笔记1](https://zhuanlan.zhihu.com/p/52169807)、[王喆的机器学习笔记2](https://zhuanlan.zhihu.com/p/61827629)、[深度学习遇上推荐系统](https://www.jianshu.com/p/8fa4dcbd5588)。

### 解决的问题

作为全球最大的UGC的视频网站，Youtube需要在百万量级的视频规模下进行个性化推荐。由于候选视频集合过大，考虑online系统延迟问题，不宜用复杂网络直接进行推荐，所以Youtube采取了两层深度网络完成整个推荐过程：

1. 第一层是**Candidate Generation Model**完成候选视频的快速筛选，这一步候选视频集合由百万降低到了百的量级（粗排）。
2. 第二层是用**Ranking Model**完成几百个候选视频的排序（精排）。

<div align="center">
<a href="https://imgtu.com/i/4BqpB6" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BqpB6.png" alt="4BqpB6.png" border="0" width="75%"></a>
</div>

<h4 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h4><h4 id="粗排模型"><a href="#粗排模型" class="headerlink" title="粗排模型"></a>粗排模型</h4><div align="center">
<a href="https://imgtu.com/i/4BOiSH" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BOiSH.png" alt="4BOiSH.png" border="0" width="65%/"></a>
</div>

<p>自底向上看粗排模型的结构，最底层的输入是用户观看过的video的embedding向量，以及搜索词的embedding向量，由word2vec得到。特别地，历史搜索的query分词后的token的embedding向量进行平均，能够反映用户的整体搜索历史状态。其它的特征向量还包括了用户的地理位置的embedding，年龄，性别等。然后把所有这些特征concatenate起来，输入上层的ReLU神经网络。</p>
<p><strong>引入fresh content的bias的作用？</strong></p>
<p>这里比较特别的一个特征是”example age“。每一秒中，YouTube都有大量视频被上传，推荐这些最新视频对于YouTube来说是极其重要的。同时，通过观察历史数据发现，用户更倾向于推荐相关度不高但最新（fresh）的视频。视频的点击率实际上都会受fresh的影响，训练的时候加入example age ，为的就是“显式”的告诉模型example age对点击的影响。在预测的时候，example age置0，就排除了这个特征对模型的影响。类似于广告，广告在展示列表中的位置，对广告的点击概率有非常大影响，排名越靠前的广告，越容易被点击，在产生训练样本的时候，把展示位置作为特征放在样本里面，并且在使用模型的时候，把展示位置特征统一置为0。</p>
<p>假设一个视频是十天前发布的，许多用户在当前观看了该视频，那么在当天会产生许多Sample Log，而在后面的九天里，观看记录不多，Sample Log也很少。如果我们没有加入Example Age这个特征的话，无论何时训练模型，这个视频对应的分类概率都是差不多的，但是如果我们加入这个特征，模型就会知道，如果这条记录是十天前产生的话，该视频会有很高的分类概率，如果是最近几天产生的话，分类概率应该低一些，这样可以更加逼近实际的数据。实验结果也证明了这一点：</p>
<div align="center">
<a href="https://imgtu.com/i/4BzKQe" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BzKQe.png" alt="4BzKQe.png" border="0" width="65%/"></a>
</div>

<p>训练样本的产生方面，正样本是用户所有完整观看过的视频，其余可以视作负样本。同时，针对每一个用户的观看记录，都生成了固定数量的训练样本，这样，每个用户在损失函数中的地位都是相等的，防止一小部分超级活跃用户主导损失函数。</p>
<p>在对待用户的搜索和观看历史时，Youtube并没有选择时序模型，而是完全摒弃了序列关系，采用求平均的方式对历史记录进行了处理。这是因为考虑时序关系，用户的推荐结果将过多受最近观看或搜索的一个视频的影响。文章中给出一个例子，如果用户刚搜索过“taylor swift”，你就把用户主页的推荐结果大部分变成taylor swift有关的视频，这其实是非常差的体验。为了综合考虑之前多次搜索和观看的信息，YouTube丢掉了时序信息，将用户近期的历史纪录等同看待。</p>
<p><a href="https://imgtu.com/i/4DSqNq" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4DSqNq.png" alt="4DSqNq.png" border="0"></a></p>
<p>在处理测试集时，Youtube采用的是图(b)的方式。图(a)是held-out方式，利用上下文信息预估中间的一个视频；图(b)是predicting next watch的方式，则是利用上文信息，预估下一次浏览的视频。我们发现图(b)的方式在线上A/B test中表现更佳。而且只留最后一次观看行为做测试集主要是为了避免引入future information，产生与事实不符的数据穿越。</p>
<p>输出方面，因为Youtube将推荐问题建模成一个“超大规模多分类”问题。即在时刻t，用户U（上下文信息C）会观看视频i的概率（每个具体的视频视为一个类别，i即为一个类别），所以输出应该是一个在所有candidate video上的概率分布，自然是一个多分类问题。</p>
<p>同时，输出分为线上和离线训练两个部分。离线训练阶段输出层为softmax层，输出3.1中公式表达的概率。对于在线服务来说，有严格的性能要求，Youtube没有重新跑一遍模型，而是通过保存用户的embedding和视频的embedding，通过最近邻搜索的方法得到top N（approx topN，使用hash的方法来得到近似的topN）的结果。</p>
<h4 id="精排模型"><a href="#精排模型" class="headerlink" title="精排模型"></a>精排模型</h4><div align="center">
<a href="https://imgtu.com/i/4D9nzT" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4D9nzT.png" alt="4D9nzT.png" border="0" width="75%/"></a>
</div>
排序过程是对生成的候选集做进一步细粒度的排序，模型架构与粗排模型基本一致，区别在于特征工程部分，图中从左至右的特征依次是：

1. **impression video ID embedding**: 当前要计算的video的embedding
2. **watched video IDs average embedding**: 用户观看过的最后N个视频embedding的average pooling
3. **language embedding**: 用户语言的embedding和当前视频语言的embedding
4. **time since last watch**: 自上次观看同channel视频的时间
5. **previous impressions**: 该视频已经被曝光给该用户的次数

后面两个特征很好地引入了对用户行为的观察，第4个特征是用户上次观看同频道时间距现在的时间间隔,从用户的角度想一想，假如我们刚看过“DOTA经典回顾”这个channel的视频，我们很大概率是会继续看这个channel的视频的，那么该特征就很好的捕捉到了这一用户行为。第5个特征previous impressions则一定程度上引入了exploration的思想，避免同一个视频持续对同一用户进行无效曝光。尽量增加用户没看过的新视频的曝光可能性。

在**特征处理**部分分为离散与连续变量：

**离散变量**

* 在进行video embedding的时候，只保留用户最常点击的N个视频的embedding，剩余的长尾视频的embedding直接用0向量代替。把大量长尾的video截断掉，主要还是为了节省online serving中宝贵的内存资源。当然从模型角度讲，低频video的embedding的准确性不佳是另一个“截断掉也不那么可惜”的理由。
* 对于相同域的特征可以共享embedding，比如用户点击过的视频ID，用户观看过的视频ID，用户收藏过的视频ID等等，这些公用一套embedding可以使其更充分的学习，同时减少模型的大小，加速模型的训练。

**连续变量**

* 主要是归一化处理，同时还把归一化后的的根号和平方作为网络输入，以期能使网络能够更容易得到特征的次线性（sub-linear）和（super-linear）超线性函数。（引入了特征的非线性）。

在精排模型的**训练**阶段，模型采用了用户的期望观看时间作为优化目标，所以如果简单使用LR就无法引入正样本的观看时间信息。因此采用weighted LR，将观看时间$T_i$作为正样本的权重，对于负样本，权重是单位权重(可以认为是1)。在线上serving中使用$e^{w^Tx+b}$做预测可以直接得到expected watch time的近似。这里引出一个问题：

1. 在模型serving过程中又为何没有采用sigmoid函数预测正样本的probability，而是使用$e^{w^Tx+b}$这一指数形式预测用户观看时长？

   > 回到LR的定义：
   > $$
   > y=\frac{1}{1+e^{-w^Tx}}
   > $$
   > 对于二分类问题：
   > $$
   > P(y=1|x)=\sigma(x) \\
   > P(y=0|x)=1-\sigma(x)
   > $$
   > 一件事情的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值，如果事件发生的概率是p，那么该事件的odds是$\frac{p}{1-p}$，对于LR而言：
   > $$
   > \frac{\frac{1}{1+e^{-w^Tx}}}{1-\frac{1}{1+e^{-w^Tx}}}=e^{w^Tx}
   > $$
   > 所以$e^{w^Tx+b}$求的就是LR形式下的odds。
   >
   > Weighted LR中的单个样本的weight，并不是让这个样本发生的概率变成了weight倍，而是让这个样本，对预估的影响(也就是loss)提升了weight倍。因为观看时长的几率=$\frac{\sum T_i}{N-k}$，其中k为正样本的个数，非wieght的odds可以直接看成N+/N-，因为wieghted的lr中，N+变成了weight倍，N-没变，还是1倍，所以直接可得后来的odds是之前odds的weight倍。
   >
   > 也就是说样本i的odds变成了下面的式子，由于在视频推荐场景中，用户打开一个视频的概率p往往是一个很小的值，且YouTube采用了用户观看时长$T_i$作为权重，$w_i=T_i$，所以有：
   > $$
   > odds(i)=\frac{w_ip}{1-w_ip}\approx w_ip=T_ip
   > $$
   > 这就是用户观看某视频的期望时长的计算式。


所以模型serving部分使用的是这个形式，经历了$e^{w^Tx+b}\rightarrow odds\rightarrow 用户期望观看时长$的过程。

## Deep & Cross Network for Ad Click Predictions[ADKDD'17]

本节主要参考[玩转企业级Deep&Cross Network模型你只差一步](https://zhuanlan.zhihu.com/p/43364598)、[揭秘 Deep & Cross : 如何自动构造高阶交叉特征](https://zhuanlan.zhihu.com/p/55234968)

### 解决的问题

这篇论文是Google对 Wide & Deep工作的一个后续研究，文中提出 Deep & Cross Network，将Wide部分替换为由特殊网络结构实现的Cross，**自动构造有限高阶的交叉特征**，并学习对应权重，从而在一定程度上告别人工特征叉乘，说一定程度是因为文中出于模型复杂度的考虑，仍是仅对sparse特征对应的embedding作自动叉乘，但这仍是一个有益的创新。

Wide & Deep 的结构能同时实现Memorization与Generalization，但是在Wide部分，仍然需要人工地设计特征叉乘。面对高维稀疏的特征空间、大量的可组合方式，基于人工先验知识虽然可以缓解一部分压力，但仍需要不小的人力和尝试成本，并且很有可能遗漏一些重要的交叉特征。FM可以自动组合特征，但也仅限于二阶叉乘。能否告别人工组合特征，并且自动学习高阶的特征组合呢？Deep & Cross 即是对此的一个尝试。

### 做法及创新

#### 核心思想

DCN的结构如下图所示，由嵌入和堆叠层、交叉网络、深度网络以及组合输出网络四部分构成：

<a href="https://imgtu.com/i/4skSbT" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/25/4skSbT.png" alt="4skSbT.png" border="0"></a>

<div align="center">
<a href="https://imgtu.com/i/4rJKYR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/25/4rJKYR.png" alt="4rJKYR.png" border="0" width="75%/"></a>
</div>

<p><strong>嵌入和堆叠层</strong></p>
<p>这部分和前面介绍的模型做法大同小异，就是对于one-hot编码的离散型特征，通过嵌入来将输入的高维特征压缩到低维稠密向量，最后将嵌入向量与归一化的连续型特征进行堆叠，形成模型的输入。</p>
<p><strong>交叉网络</strong></p>
<p>交叉网络的每一层形式为：</p>
<script type="math/tex; mode=display">
x_{l+1}=x_0x^T_lw_l+b_l+x_l=f(x_l,w_l,b_l)+x_l</script><ol>
<li>每层的神经元个数都相同，都等于输入$x_0$的维度$d$，也即每层的输入输出维度都是相等的。</li>
<li>受残差网络（Residual Network）结构启发，每层的函数f拟合的是$x_{l+1}-x_l$的残差，残差网络有很多优点，其中一点是处理梯度消失的问题，使网络可以“更深”。</li>
</ol>
<p>那么交叉网络为什么能够自动构造有限高阶的交叉特征呢？以一个二层的交叉网络为例，其中$x_0=[x_{0,1};x_{0,2}]$，另各层的$b_i=0$：</p>
<p><a href="https://imgtu.com/i/4rtbWR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/25/4rtbWR.png" alt="4rtbWR.png" border="0"></a></p>
<p>最后得到$y_{cross}=x_2^T*w_{cross}$，可以看到$x_1$包含了原始特征 $x_{0,1}$、$x_{0,2}$从一阶到二阶的所有可能叉乘组合，而 $x_2$包含了其从一阶到三阶的所有可能叉乘组合。从这个例子可以看出DCN的特点：</p>
<ul>
<li><strong>有限高阶</strong>：叉乘<strong>阶数由网络深度决定</strong>，深度$L_c$对应最高阶$L_c+1$的叉乘</li>
<li><strong>自动叉乘</strong>：Cross输出包含了原始特征从一阶（即本身）到$L_c+1$阶的<strong>所有叉乘组合，</strong>而模型参数量仅仅随输入维度成<strong>线性增长</strong>：$2<em>d</em>L_c$</li>
<li><strong>参数共享</strong>：不同叉乘项对应的权重不同，但并非每个叉乘组合对应独立的权重（指数数量级）， 通过参数共享，Cross有效<strong>降低了参数量</strong>。此外，参数共享还使得模型有更强的<strong>泛化性</strong>和<strong>鲁棒性</strong>。例如，如果独立训练权重，当训练集中$x_i\not =0 \land x_j\not =0$这个叉乘特征没有出现 ，对应权重肯定是零，而参数共享则不会，类似地，数据集中的一些噪声可以由大部分正常样本来纠正权重参数的学习</li>
</ul>
<p>训练部分，模型的Deep 部分如上图右侧部分所示，DCN拼接Cross和Deep的输出，采用logistic loss作为损失函数，进行联合训练，这些细节与Wide &amp; Deep几乎是一致的，在这里不再展开论述。另外，文中也在目标函数中加入L2正则防止过拟合。</p>
<h2 id="Neural-Factorization-Machines-for-Sparse-Predictive-Analytics-SIGIR’17"><a href="#Neural-Factorization-Machines-for-Sparse-Predictive-Analytics-SIGIR’17" class="headerlink" title="Neural Factorization Machines for Sparse Predictive Analytics[SIGIR’17]"></a>Neural Factorization Machines for Sparse Predictive Analytics[SIGIR’17]</h2><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>FM虽然引入了高阶特征，但只限于二阶的特征交叉项，而神经网络非常适合建模更高阶的特征之间的关系，因此论文用神经网络DNN替代FM中二阶隐向量内积的部分。</p>
<h3 id="做法及创新-1"><a href="#做法及创新-1" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>FM的表达式为：</p>
<script type="math/tex; mode=display">
y=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^n\sum_{j\ge i}^n<v_i,v_j>x_ix_j</script><p>NFM修改为：</p>
<script type="math/tex; mode=display">
y=w_0+\sum_{i=1}^nw_ix_i+f(x)</script><p>其中$f(x)$用来建模特征之间的高阶交互关系，它的架构如下：</p>
<div align="center">
<a href="https://imgtu.com/i/os5zsP" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2021/12/06/os5zsP.png" alt="os5zsP.png" border="0"></a>
</div>
* **Embedding Layer**同FM中的$<v_i,v_j>$，将高维的离散特征转化为低维稠密的embedding
* **Bi-Interaction Layer**同FM的二次项计算过程，将embedding转化为FM中二阶交叉的形式
* **Hidden Layer**就是引入的神经网络部分，它将上一层的结果进一步输入DNN中，捕捉特征之间的高阶交互关系
* **Prediction Layer**将最后一层的输出转化为预测评分$f(x)=h^Tz_L$




## Attentional Factorization Machines[IJCAI'17]
本节主要参考[推荐算法精排模型AFM](https://zhuanlan.zhihu.com/p/395140453)

### 解决的问题

FM在做特征交互时，对所有交叉项赋予相同的权重，这可能是不够准确的，不相关的特征的交叉项可能还会引来噪声，论文通过attention机制学习各特征交叉项的重要程度进行加权求和。

### 做法及创新

前面介绍DeepFM时说到它是典型的一种DNN与FM融合的并行结构，而本节的AFM就是典型的一种串行结构：

<a href="https://imgtu.com/i/4skFPJ" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/25/4skFPJ.png" alt="4skFPJ.png" border="0"></a>

#### 核心思想

AFM的目的也是像FFM一样区分同一特征与不同特征组合时的相互作用，只是不再划分为field而是通过一个注意力网络学习得到权重，总体参数量增加不明显。

回顾FM的预测公式：
$$
\hat{y}(x):=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+\sum_{i=1}^{n} \sum_{j=i+1}^{n}<v_{i}, v_{j}="">x_{i} x_{j}
$$
其中需要学习的参数为：
$$
w_{0} \in \mathbb{R}, \quad w \in \mathbb{R}^{n}, \quad V \in \mathbb{R}^{n \times k}
$$
它们的含义为：

- $w_0$表示全局的偏差；
- $w_i$表示第i个特征的强度；
- $w_{ij}$表示第i个特征和第j个特征之间的交互，在实际参数学习中不是直接学习交互特征的权重参数$w_{ij}$的，而是通过**学习因式分解参数**来学习交互特征的参数。

<a href="https://imgtu.com/i/4sk3RA" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/25/4sk3RA.png" alt="4sk3RA.png" border="0"></a>

输入层和embedding层与FM模型是一样的，其中对于输入特征都采取了稀疏表示，即将所有的非零特征都嵌入到dense特征。嵌入后的表示为$v_ix_i$，而FM中二次项的系数分解为两个特征i和j的嵌入向量的叉乘，$w_{ij}=v_i^Tv_j$，这里$v_i$就是特征i的嵌入向量。

**Pair-wise交互层**

这一层的目的是在神经网络中表达FM的计算逻辑：
$$
\hat{y}=\mathbf{p}^{T} \sum_{(i, j) \in \mathcal{R}_{x}}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}+b
$$
向量p置为全1以及b设为0就回退到传统的FM模型。

**Attention-based池化层**
$$
f_{\text {Att }}\left(f_{P I}(\mathcal{E})\right)=\sum_{(i, j) \in \mathcal{R}_{x}} a_{i j}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}
$$
跟传统attention一样，$a_{ij}$就是表示特征i和j的交互在进行预测时的重要程度，可以直接通过最小化loss函数去学习$a_{ij}$，虽然看起来是可行的，但是这又会碰到之前的问题：当某个交互特征没有出现在样本中时，就没法学习某个交互特征的attention分数了。为了解决这个泛化能力方面的问题，我们使用MLP网络去参数化这个attention分数，该MLP网络称之为attention network。attention network的输入是嵌入后的两个特征的交互向量：
$$
\begin{aligned}
a_{i j}^{\prime} &=\mathbf{h}^{T} ReL U\left(\mathbf{W}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}+\mathbf{b}\right) \\
a_{i j} &=\frac{\exp \left(a_{i j}^{\prime}\right)}{\sum_{(i, j) \in \mathcal{R}_{x}} \exp \left(a_{i j}^{\prime}\right)}
\end{aligned}
$$
Attention-based 池化层的输出是一个k维的向量，它在embedding空间中通过区分出各特征交互的重要性，来压缩所有的特征交互，然后将这些映射到最终的预测结果上面。

AFM模型在防止过拟合上的做法：

- dropout方式是通过防止神经元之间的共现性从而防止过拟合。由于AFM模型中会学习所有的特征之间的二阶交互特征，因此更加容易导致模型学习特征之间的共现性从而更容易导致过拟合，因此在pair-wise交互层使用了dropout方法来避免共现性。
- 对于AFM模型中的attention network，它是一个单层的MLP网络，这里使用L2正则化来防止过拟合，对于attention network，不选择dropout防止过拟合。

**输出层**

将池化层的输出结果映射到最终的预测评分中：
$$
\hat{y}_{AFM}(x)=w_0+\sum_{i=1}^nw_ix_i+\mathbf{p}^{T} \sum_{i=1}^n\sum_{j=i+1}^na_{ij}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}+b
$$


## Practical Lessons from Predicting Clicks on Ads at Facebook[ADKDD'14]

本节主要参考[GBDT+LR融合方案实战](https://cloud.tencent.com/developer/article/1164780)、[GBDT的原理](https://zhuanlan.zhihu.com/p/280222403)

### 解决的问题

LR虽然能够处理大规模数据，但它的学习能力有限，需要大量的特征工程来增加模型的学习能力，这个过程费时费力而且不一定能保证性能上的提升。论文通过GBDT来自动地进行特征组合，来减少人工的特征工程。

### 做法及创新

#### 核心思想

<div align="center">
<a href="https://imgtu.com/i/IWxx1O" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/11/16/IWxx1O.png" alt="IWxx1O.png" border="0"></a>
</div>


<p>通过GBDT将每棵树的叶子节点编码作为新的特征，输入LR模型。以上图为例，图中的梯度提升树有左右两棵子树，叶节点的数量分别为3和2，假设输入的样本$x$经过梯度提升树后落在了左子树的第二个叶节点以及右子树的第一个叶节点，则新的特征表示为$[0,1,0,1,0]$，是一种one-hot的编码形式。</p>
<p>GBDT及决策树的介绍可见<a href="https://zhuanlan.zhihu.com/p/339380585" target="_blank" rel="noopener">决策树的原理</a>，作者介绍的非常详细。</p>
<h2 id="Pytorch-FM"><a href="#Pytorch-FM" class="headerlink" title="Pytorch-FM"></a>Pytorch-FM</h2><p>介绍了LR、FM等方法后，这里通过<a href="https://github.com/rixwew/pytorch-fm" target="_blank" rel="noopener">pytorch-fm</a>库来了解这些模型的具体实现。</p>
<p><strong>数据预处理</strong></p>
<p><code>MovieLens20M</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MovieLens20MDataset</span><span class="params">(torch.utils.data.Dataset)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    MovieLens 20M Dataset</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Data preparation</span></span><br><span class="line"><span class="string">        treat samples with a rating less than 3 as negative samples</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param dataset_path: MovieLens dataset path</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">        https://grouplens.org/datasets/movielens</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataset_path, sep=<span class="string">','</span>, engine=<span class="string">'c'</span>, header=<span class="string">'infer'</span>)</span>:</span></span><br><span class="line">        data = pd.read_csv(dataset_path, sep=sep, engine=engine, header=header).to_numpy()[:, :<span class="number">3</span>]</span><br><span class="line">        self.items = data[:, :<span class="number">2</span>].astype(np.int) - <span class="number">1</span>  <span class="comment"># -1 because ID begins from 1</span></span><br><span class="line">        self.targets = self.__preprocess_target(data[:, <span class="number">2</span>]).astype(np.float32)</span><br><span class="line">        self.field_dims = np.max(self.items, axis=<span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">        self.user_field_idx = np.array((<span class="number">0</span>, ), dtype=np.long)</span><br><span class="line">        self.item_field_idx = np.array((<span class="number">1</span>,), dtype=np.long)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.targets.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.items[index], self.targets[index]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__preprocess_target</span><span class="params">(self, target)</span>:</span></span><br><span class="line">        target[target &lt;= <span class="number">3</span>] = <span class="number">0</span></span><br><span class="line">        target[target &gt; <span class="number">3</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> target</span><br></pre></td></tr></table></figure>
<p>ml-20m/ratings.csv形式如下：</p>
<div align="center">
<a href="https://imgtu.com/i/IobKZd" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/11/18/IobKZd.png" alt="IobKZd.png" border="0"></a>
</div>
* 这里的实现继承torch.utils.data.Dataset，根据官方文档的说明，一个自定义的数据集必须包含三个函数：*\_\_init\_\_, \_\_len\_\_, \_\_getitem\_\__*
  * *\_\_init\_\_*在数据集实例化时运行一次
  * *\_\_len\_\_*返回数据集中的样本个数
  * *\_\_getitem\_\_*给定一个索引idx返回一个对应位置的样本，这里返回的是用户Id、电影Id以及评分离散化后的标签
* pd.read_csv返回值为dataframe，不支持[:, :3]切片操作，因此需要首先通过to_numpy()转化为ndarray格式。
* [:, :3]表示取前三列['userId', 'movieId', 'rating']
* items = data[:, :2].astype(np.int)取出前两列['userId', 'movieId']，并指定它们的格式为int64，因为数据集中id从1开始编码，这里的-1操作是让id从0开始编码
* targets = data[:, 2]取出['rating']这一列并将其中的值离散为0和1，这里的实现方式是将评分小于等于3的电影看成负样本，targets.shape[0]即为评分总数，在Movielens20M中为20000263
* np.max求序列中的最大值，axis=0表示纵向，这里得到的field_dims包含两个元素，分别是user和movie的数量，+1的原因是上一步里将id从0开始编码，而数量是从1开始计数
* np.array((0, ), dtype=np.long)得到一个行数为1的array，列数不固定

`MovieLens1M`

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MovieLens1MDataset</span><span class="params">(MovieLens20MDataset)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    MovieLens 1M Dataset</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Data preparation</span></span><br><span class="line"><span class="string">        treat samples with a rating less than 3 as negative samples</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param dataset_path: MovieLens dataset path</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">        https://grouplens.org/datasets/movielens</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataset_path)</span>:</span></span><br><span class="line">        super().__init__(dataset_path, sep=<span class="string">'::'</span>, engine=<span class="string">'python'</span>, header=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>

ml-1m/ratings.dat形式如下：

<div align="center">
<a href="https://imgtu.com/i/ITm75R" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/11/18/ITm75R.png" alt="ITm75R.png" border="0"></a>
</div>
和MovieLens20M完全相同，所以这里直接调用了MovieLens20MDataset的构造函数

### 基本组件

#### FeaturesLinear

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeaturesLinear</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, field_dims, output_dim=<span class="number">1</span>)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)</span><br><span class="line">        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))</span><br><span class="line">        self.offsets = np.array((<span class="number">0</span>, *np.cumsum(field_dims)[:<span class="number">-1</span>]), dtype=np.long)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Long tensor of size ``(batch_size, num_fields)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        x = x + x.new_tensor(self.offsets).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># a = torch.tensor([[1,2,3],[4,5,6]])</span></span><br><span class="line">        <span class="comment"># torch.sum(a,dim=1) -&gt; tensor([6,15]) &lt;- torch.Size([2])</span></span><br><span class="line">        <span class="keyword">return</span> torch.sum(self.fc(x), dim=<span class="number">1</span>) + self.bias</span><br></pre></td></tr></table></figure>

* 参考[推荐系统——FFM模型点击率CTR预估（代码，数据流动详细过程）](https://www.cnblogs.com/sunupo/p/12826308.html)

* fc将输入的特征转换为embedding返回，相当于构建了一个embedding字典，以MovieLens20M为例，field_dims为[138493, 131262]，分别为用户Id与电影Id的数量，则sum(field_dims)为269755，是所有Id的总数，这里是把每个Id看作一个特征，那么索引为1到269755，每个索引对应一个长度为output_dim=1的向量，这里取output_dim=1对应LR中$\sum_{i=1}^{n}w_ix_i$的系数$w_i$

  * `torch.nn.Embedding(num_embeddings, embedding_dim)`
    * num_embeddings：存储的embedding数量
    * embedding_dim：embedding的维度

  <div align="center">
    <a href="https://imgtu.com/i/oFhlFI" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/11/25/oFhlFI.jpg" alt="oFhlFI.jpg" border="0"></a>
  </div>

<ul>
<li><p>LR将线性回归模型与Sigmoid函数相结合，线性回归模型的常见形式为$y=w^Tx+b$，这里的bias即对应$b$，初始化为0，作为模型参数的一部分torch.nn.Parameter可以在训练过程中被更新</p>
</li>
<li><p>offset的作用是得到每个特征的索引偏移量，这里以field_dims=[5,10,5]为例，样本为[1,5,1]，那么one-hot编码过后为[<strong>1</strong>,0,0,0,0,0,0,0,0,<strong>1</strong>,0,0,0,0,0,<strong>1</strong>,0,0,0,0]，1所在的位置对应的索引分别为1、10、16，offset的作用就是得到这个索引：</p>
<ul>
<li>np.cumsum()返回序列中每个元素的累加和，那么offset为np.cumsum(field_dims)[:-1]=[0,5,15]，与输入的样本求和就得到[1,5,1]+[0,5,15]=[1,10,16]</li>
<li>以1、10和16作为索引从embedding字典中取出对应的embedding，样本[1,5,1]会取出三个embedding，torch.sum(self.fc(x), dim=1)的作用就是将三个embedding求和得到样本最终的embedding</li>
</ul>
</li>
<li><p>x.new_tensor(self.offsets)在MovieLens20M的例子中得到的tensor形状为torch.Size([1,2])，因此通过unsqueeze(0)去掉第一个维度的1</p>
</li>
<li><p>self.fc(x)会得到一个batch_size*num_field*output_dim的tensor，torch.sum(self.fc(x), dim=1)得到一个batch_size*output_dim的tensor</p>
</li>
<li><p><code>FeaturesLinear</code>对应LR中的$w^Tx+b$，FM中的$w_0+\sum_{i=1}^nw_ix_i$</p>
</li>
</ul>
<h4 id="FeaturesEmbedding"><a href="#FeaturesEmbedding" class="headerlink" title="FeaturesEmbedding"></a>FeaturesEmbedding</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeaturesEmbedding</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, field_dims, embed_dim)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)</span><br><span class="line">        self.offsets = np.array((<span class="number">0</span>, *np.cumsum(field_dims)[:<span class="number">-1</span>]), dtype=np.long)</span><br><span class="line">        torch.nn.init.xavier_uniform_(self.embedding.weight.data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Long tensor of size ``(batch_size, num_fields)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        x = x + x.new_tensor(self.offsets).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> self.embedding(x)</span><br></pre></td></tr></table></figure>
<ul>
<li>参考<a href="https://zhuanlan.zhihu.com/p/165610397" target="_blank" rel="noopener">FM 代码实现细节（Embedding 和数学实现）</a></li>
</ul>
<h4 id="MultiLayer-Perceptron"><a href="#MultiLayer-Perceptron" class="headerlink" title="MultiLayer Perceptron"></a>MultiLayer Perceptron</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiLayerPerceptron</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, embed_dims, dropout, output_layer=True)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        layers = list()</span><br><span class="line">        <span class="keyword">for</span> embed_dim <span class="keyword">in</span> embed_dims:</span><br><span class="line">            layers.append(torch.nn.Linear(input_dim, embed_dim))</span><br><span class="line">            layers.append(torch.nn.BatchNorm1d(embed_dim))</span><br><span class="line">            layers.append(torch.nn.ReLU())</span><br><span class="line">            layers.append(torch.nn.Dropout(p=dropout))</span><br><span class="line">            input_dim = embed_dim</span><br><span class="line">        <span class="keyword">if</span> output_layer:</span><br><span class="line">            layers.append(torch.nn.Linear(input_dim, <span class="number">1</span>))</span><br><span class="line">        self.mlp = torch.nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Float tensor of size ``(batch_size, embed_dim)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> self.mlp(x)</span><br></pre></td></tr></table></figure>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><h4 id="Logistics-Regression"><a href="#Logistics-Regression" class="headerlink" title="Logistics Regression"></a>Logistics Regression</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span><span class="params">(name, dataset)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Hyperparameters are empirically determined, not opitmized.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    field_dims = dataset.field_dims</span><br><span class="line">    <span class="keyword">if</span> name == <span class="string">'lr'</span>:</span><br><span class="line">        <span class="keyword">return</span> LogisticRegressionModel(field_dims)</span><br><span class="line">      </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegressionModel</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A pytorch implementation of Logistic Regression.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, field_dims)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = FeaturesLinear(field_dims)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Long tensor of size ``(batch_size, num_fields)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(self.linear(x).squeeze(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h4 id="Factorization-Machine"><a href="#Factorization-Machine" class="headerlink" title="Factorization Machine"></a>Factorization Machine</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FactorizationMachine</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, reduce_sum=True)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.reduce_sum = reduce_sum</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        square_of_sum = torch.sum(x, dim=<span class="number">1</span>) ** <span class="number">2</span></span><br><span class="line">        sum_of_square = torch.sum(x ** <span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">        ix = square_of_sum - sum_of_square</span><br><span class="line">        <span class="comment"># if reduce_sum = False, ouput size is (batch_size, embed_dim)</span></span><br><span class="line">        <span class="comment"># if reduce_sum = True, ouput size is (batch_size, 1)</span></span><br><span class="line">        <span class="keyword">if</span> self.reduce_sum:</span><br><span class="line">            ix = torch.sum(ix, dim=<span class="number">1</span>, keepdim=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span> * ix</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FactorizationMachineModel</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A pytorch implementation of Factorization Machine.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">        S Rendle, Factorization Machines, 2010.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, field_dims, embed_dim)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.embedding = FeaturesEmbedding(field_dims, embed_dim)</span><br><span class="line">        self.linear = FeaturesLinear(field_dims)</span><br><span class="line">        self.fm = FactorizationMachine(reduce_sum=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Long tensor of size ``(batch_size, num_fields)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        x = self.linear(x) + self.fm(self.embedding(x))</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(x.squeeze(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
y=w_0+\sum_{i=1}^nw_ix_i+\frac{1}{2}\sum_{f=1}^k[(\sum_{i=1}^nv_{i,f}x_i)^2-\sum_{i=1}^nv_{i,f}^2x_i^2]</script><p>pytorch-fm的实现中</p>
<script type="math/tex; mode=display">
\frac{1}{2}\sum_{f=1}^k[(\sum_{i=1}^nv_{i,f}x_i)^2-\sum_{i=1}^nv_{i,f}^2x_i^2]=\frac{1}{2}\sum_{f=1}^k(S_{1,f}^2-S_{2,f})=\frac{1}{2}(S_1^2-S_2)</script><ul>
<li>$\sum_{i=1}^nv_{i,f}x_i$中的$x_i$通常很稀疏，以MovieLens为例：</li>
</ul>
<div align="center">
  <a href="https://imgtu.com/i/oFhlFI" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/11/25/oFhlFI.jpg" alt="oFhlFI.jpg" border="0"></a>
</div>

<p>​    以一个batch中的样本为例，假设batch_size=56，那么在MovieLens1M数据集上得到的就是维度为[56,2]的输入，其中第一列为用户id，第二列为电影id：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># x.shape -&gt; torch.Size([56,2])</span></span><br><span class="line">x -&gt; tensor(</span><br><span class="line">  [[   <span class="number">0</span>,  <span class="number">660</span>],</span><br><span class="line">   [   <span class="number">0</span>,  <span class="number">913</span>],</span><br><span class="line">   [   <span class="number">0</span>, <span class="number">3407</span>],</span><br><span class="line">   [   <span class="number">0</span>, <span class="number">2354</span>],</span><br><span class="line">   ...</span><br><span class="line">   [   <span class="number">1</span>,  <span class="number">646</span>]]</span><br><span class="line">)</span><br><span class="line">embedding = FeaturesEmbedding(dataset.field_dims,<span class="number">10</span>)</span><br><span class="line">e = embedding(x)</span><br><span class="line"><span class="comment"># e.shape -&gt; torch.Size([56, 2, 10])</span></span><br><span class="line">e -&gt; tensor(</span><br><span class="line">  [[[ <span class="number">0.0116</span>, <span class="number">-0.0165</span>,  <span class="number">0.0232</span>,  ...,  <span class="number">0.0208</span>,  <span class="number">0.0075</span>, <span class="number">-0.0057</span>],</span><br><span class="line">    [<span class="number">-0.0108</span>, <span class="number">-0.0218</span>,  <span class="number">0.0192</span>,  ...,  <span class="number">0.0243</span>,  <span class="number">0.0056</span>, <span class="number">-0.0129</span>]],</span><br><span class="line"></span><br><span class="line">   [[ <span class="number">0.0116</span>, <span class="number">-0.0165</span>,  <span class="number">0.0232</span>,  ...,  <span class="number">0.0208</span>,  <span class="number">0.0075</span>, <span class="number">-0.0057</span>],</span><br><span class="line">    [<span class="number">-0.0098</span>, <span class="number">-0.0042</span>, <span class="number">-0.0118</span>,  ...,  <span class="number">0.0168</span>,  <span class="number">0.0208</span>, <span class="number">-0.0151</span>]],</span><br><span class="line"></span><br><span class="line">   [[ <span class="number">0.0116</span>, <span class="number">-0.0165</span>,  <span class="number">0.0232</span>,  ...,  <span class="number">0.0208</span>,  <span class="number">0.0075</span>, <span class="number">-0.0057</span>],</span><br><span class="line">    [ <span class="number">0.0041</span>, <span class="number">-0.0208</span>, <span class="number">-0.0117</span>,  ..., <span class="number">-0.0241</span>,  <span class="number">0.0067</span>, <span class="number">-0.0147</span>]],</span><br><span class="line">   ...,</span><br><span class="line"></span><br><span class="line">   [[<span class="number">-0.0053</span>,  <span class="number">0.0034</span>,  <span class="number">0.0165</span>,  ...,  <span class="number">0.0195</span>,  <span class="number">0.0137</span>,  <span class="number">0.0239</span>],</span><br><span class="line">    [<span class="number">-0.0009</span>,  <span class="number">0.0021</span>, <span class="number">-0.0135</span>,  ..., <span class="number">-0.0206</span>,  <span class="number">0.0217</span>,  <span class="number">0.0160</span>]],</span><br><span class="line"></span><br><span class="line">   [[<span class="number">-0.0053</span>,  <span class="number">0.0034</span>,  <span class="number">0.0165</span>,  ...,  <span class="number">0.0195</span>,  <span class="number">0.0137</span>,  <span class="number">0.0239</span>],</span><br><span class="line">    [ <span class="number">0.0064</span>, <span class="number">-0.0229</span>, <span class="number">-0.0185</span>,  ...,  <span class="number">0.0148</span>,  <span class="number">0.0118</span>,  <span class="number">0.0018</span>]],</span><br><span class="line"></span><br><span class="line">   [[<span class="number">-0.0053</span>,  <span class="number">0.0034</span>,  <span class="number">0.0165</span>,  ...,  <span class="number">0.0195</span>,  <span class="number">0.0137</span>,  <span class="number">0.0239</span>],</span><br><span class="line">    [<span class="number">-0.0141</span>,  <span class="number">0.0136</span>, <span class="number">-0.0051</span>,  ..., <span class="number">-0.0224</span>, <span class="number">-0.0162</span>, <span class="number">-0.0134</span>]]],</span><br><span class="line">  grad_fn=&lt;EmbeddingBackward&gt;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>取样本中的第一个交互记录[0, 660]，假设经过one-hot编码后用户0在整个特征向量中是第0个，电影660是第6700个，在<code>FeaturesEmbedding</code>中通过x = x + x.new_tensor(self.offsets).unsqueeze(0)转化为一个除了第0位与6700位为1之外其余均为0的特征向量，self.embedding()从embedding字典中根据索引0和6700取出对应的embedding，则$\sum_{i=1}^nv_{i,f}x_i=v_{0,f}\times1+v_{6700,f}\times1$，就是取出的embedding相加：</p>
<p>[ 0.0116, -0.0165,  0.0232,  …,  0.0208,  0.0075, -0.0057]</p>
<p>[-0.0108, -0.0218,  0.0192,  …,  0.0243,  0.0056, -0.0129]</p>
</li>
<li><p>实现上面的embedding相加是通过torch.sum(dim=1)，因此pytorch-fm的实现方式为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">square_of_sum = torch.sum(x, dim=<span class="number">1</span>) ** <span class="number">2</span></span><br><span class="line">sum_of_square = torch.sum(x ** <span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">ix = square_of_sum - sum_of_square</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Field-aware-Factorization-Machine"><a href="#Field-aware-Factorization-Machine" class="headerlink" title="Field-aware Factorization Machine"></a>Field-aware Factorization Machine</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FieldAwareFactorizationMachine</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, field_dims, embed_dim)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.num_fields = len(field_dims)</span><br><span class="line">        self.embeddings = torch.nn.ModuleList([</span><br><span class="line">            torch.nn.Embedding(sum(field_dims), embed_dim) <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.num_fields)</span><br><span class="line">        ])</span><br><span class="line">        self.offsets = np.array((<span class="number">0</span>, *np.cumsum(field_dims)[:<span class="number">-1</span>]), dtype=np.long)</span><br><span class="line">        <span class="keyword">for</span> embedding <span class="keyword">in</span> self.embeddings:</span><br><span class="line">            torch.nn.init.xavier_uniform_(embedding.weight.data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Long tensor of size ``(batch_size, num_fields)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        x = x + x.new_tensor(self.offsets).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        xs = [self.embeddings[i](x) <span class="keyword">for</span> i <span class="keyword">in</span> range(self.num_fields)]</span><br><span class="line">        ix = list()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.num_fields - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, self.num_fields):</span><br><span class="line">                ix.append(xs[j][:, i] * xs[i][:, j])</span><br><span class="line">        ix = torch.stack(ix, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> ix</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FieldAwareFactorizationMachineModel</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A pytorch implementation of Field-aware Factorization Machine.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">        Y Juan, et al. Field-aware Factorization Machines for CTR Prediction, 2015.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, field_dims, embed_dim)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = FeaturesLinear(field_dims)</span><br><span class="line">        self.ffm = FieldAwareFactorizationMachine(field_dims, embed_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Long tensor of size ``(batch_size, num_fields)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        ffm_term = torch.sum(torch.sum(self.ffm(x), dim=<span class="number">1</span>), dim=<span class="number">1</span>, keepdim=<span class="keyword">True</span>)</span><br><span class="line">        x = self.linear(x) + ffm_term</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(x.squeeze(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<ul>
<li><p>在FM中，不对各个field之间的交互进行区分，而FFM中，每一维特征，在与每个field的特征交互时使用的是不同的隐变量，因此有多少个field就需要构建多少个torch.nn.Embedding层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.embeddings = torch.nn.ModuleList([</span><br><span class="line">  torch.nn.Embedding(sum(field_dims), embed_dim) <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.num_fields)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>xs = [self.embeddings[i](x) for i in range(self.num_fields)]</code>得到一个长度为num_fields的列表，其中的每一个元素大小为batch_size*num_fields*embed_dim，即FM中embedding大小，而这里形成的num_fields个元素就体现了FFM的Field-aware的思想，以batch_size=5，num_fields=3为例，则列表的第1、2、3个元素分别记录着当前batch中的所有样本各自的特征对第1、2、3个field的隐向量。</p>
</li>
<li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ix = list()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(self.num_fields - <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, self.num_fields):</span><br><span class="line">        ix.append(xs[j][:, i] * xs[i][:, j])</span><br></pre></td></tr></table></figure>
<p>这里的代码是求$w_{i,f_j}\cdot w_{j,f_i}x_ix_j$，以field_dims=[5,10,5]，样本[1,5,1]为例，首先需要说明的是在FFM中同一field之间的特征不交互，例如”1”和”5”不交互，因为1和5属于[1,2,…,5]都是field1，所以考虑的是field1、field2、field3之间的交叉。</p>
<p>每个embeddings[i]都是n*sum(field_dims)=20大小的字典，根据对应的索引取出embedding。样本经过offset后得到[1,10,16]，因为只有1、10和16的位置不为0，所以只会考虑这三个特征之间的相互交互，得到3项特征交互项：field1*field2，field2*field3、field1*field3，则最后得到的ix就是一个长度为3（指特征交互项的数目，不是num_fields）的列表。</p>
<p>关于参与交互的特征，id类特征经过one-hot编码后每一个id就是一个特征了，只有当前id的电影在这个特征上为1其余电影均为0。而其他0/1变量例如是否为动作电影等各自成为一个特征：</p>
<p>|        |      |      |      |      |      | is_action |<br>| :——: | :—: | :—: | :—: | :—: | :—: | :———-: |<br>| movie1 |  1   |  0   |  0   |  0   |  0   |     1     |<br>| movie2 |  0   |  1   |  0   |  0   |  0   |     1     |<br>| movie3 |  0   |  0   |  1   |  0   |  0   |     0     |</p>
<p>还是以样本[1,5,1]为例，它的特征向量[1,10,16]对3个field的隐向量分别为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">-0.3187</span>, <span class="number">-0.2215</span>,  <span class="number">0.2950</span>, <span class="number">-0.2186</span>],  <span class="comment"># 特征“1”对field1的隐向量</span></span><br><span class="line"> [<span class="number">-0.1316</span>,  <span class="number">0.1353</span>,  <span class="number">0.3162</span>,  <span class="number">0.0994</span>], <span class="comment"># 特征“10”对field1的隐向量</span></span><br><span class="line"> [ <span class="number">0.1061</span>,  <span class="number">0.0932</span>, <span class="number">-0.3512</span>, <span class="number">-0.2172</span>]], <span class="comment"># 特征“16”对field1的隐向量</span></span><br><span class="line"></span><br><span class="line">[[<span class="number">-0.2026</span>,  <span class="number">0.0910</span>, <span class="number">-0.1647</span>, <span class="number">-0.0428</span>], <span class="comment"># 特征“1”对field2的隐向量</span></span><br><span class="line"> [ <span class="number">0.1085</span>,  <span class="number">0.2459</span>,  <span class="number">0.2358</span>, <span class="number">-0.0501</span>], <span class="comment"># 特征“10”对field2的隐向量</span></span><br><span class="line"> [ <span class="number">0.2694</span>,  <span class="number">0.0325</span>,  <span class="number">0.2198</span>,  <span class="number">0.2486</span>]], <span class="comment"># 特征“16”对field2的隐向量</span></span><br><span class="line"></span><br><span class="line">[[<span class="number">-0.0756</span>, <span class="number">-0.1417</span>,  <span class="number">0.0075</span>,  <span class="number">0.0632</span>], <span class="comment"># 特征“1”对field3的隐向量</span></span><br><span class="line"> [<span class="number">-0.0770</span>,  <span class="number">0.2010</span>,  <span class="number">0.0051</span>,  <span class="number">0.0050</span>], <span class="comment"># 特征“10”对field3的隐向量</span></span><br><span class="line">  [<span class="number">-0.1394</span>,  <span class="number">0.0776</span>,  <span class="number">0.2685</span>, <span class="number">-0.1017</span>]], <span class="comment"># 特征“16”对field3的隐向量</span></span><br></pre></td></tr></table></figure>
<p>最终得到的ix为长度为3（指特征交互项的数目，不是num_fields）的列表：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># [tensor([</span></span><br><span class="line"><span class="comment">#					[ 0.0267,  0.0123, -0.0521, -0.0043],</span></span><br><span class="line"><span class="comment">#         [-0.0288, -0.0049,  0.0477,  0.0070],</span></span><br><span class="line"><span class="comment">#         [ 0.0045, -0.0982,  0.0159, -0.0079],</span></span><br><span class="line"><span class="comment">#         [ 0.0352, -0.0154,  0.0057, -0.0013],</span></span><br><span class="line"><span class="comment">#         [-0.0783, -0.0160,  0.0329, -0.0632]</span></span><br><span class="line"><span class="comment">#				], grad_fn=&lt;MulBackward0&gt;),   	</span></span><br><span class="line"><span class="comment">#  tensor([</span></span><br><span class="line"><span class="comment">#					[-0.0080, -0.0132, -0.0026, -0.0137],</span></span><br><span class="line"><span class="comment">#         [-0.0080, -0.0132, -0.0026, -0.0137],</span></span><br><span class="line"><span class="comment">#         [-0.0933, -0.0658, -0.0572, -0.0075],</span></span><br><span class="line"><span class="comment">#         [ 0.0065, -0.0565, -0.0052, -0.1054],</span></span><br><span class="line"><span class="comment">#         [-0.0130, -0.0319, -0.0128,  0.0080]</span></span><br><span class="line"><span class="comment">#				], grad_fn=&lt;MulBackward0&gt;), </span></span><br><span class="line"><span class="comment">#  tensor([</span></span><br><span class="line"><span class="comment">#					[-0.0207,  0.0065,  0.0011,  0.0012],</span></span><br><span class="line"><span class="comment">#         [-0.0487,  0.0010,  0.0265,  0.0394],</span></span><br><span class="line"><span class="comment">#         [ 0.0219, -0.0474, -0.0293, -0.0323],</span></span><br><span class="line"><span class="comment">#         [-0.0141, -0.0528,  0.0460, -0.0026],</span></span><br><span class="line"><span class="comment">#         [ 0.0227,  0.0099,  0.0768,  0.0151]</span></span><br><span class="line"><span class="comment">#				], grad_fn=&lt;MulBackward0&gt;)]</span></span><br></pre></td></tr></table></figure>
<p>[0.0267,  0.0123, -0.0521, -0.0043]表示batch_size=5的batch中样本1的特征”1”和特征”10”的交互，</p>
<p>[-0.0288, -0.0049,  0.0477,  0.0070]表示batch_size=5的batch中样本2的特征”1”和特征”10”的交互，</p>
<p>[-0.0080, -0.0132, -0.0026, -0.0137]表示batch_size=5的batch中样本1的特征”1”和特征”16”的交互，以此类推</p>
</li>
<li><p>上面得到的ix中的元素是不同样本的相同特征交互项，例如都表示特征”1”和特征”10”的交互，我们希望得到相同样本的不同特征交互项，代码中就是通过<code>ix = torch.stack(ix, dim=1)</code>实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#	tensor(</span></span><br><span class="line"><span class="comment">#       [[[ 0.0267,  0.0123, -0.0521, -0.0043],</span></span><br><span class="line"><span class="comment">#          [-0.0080, -0.0132, -0.0026, -0.0137],</span></span><br><span class="line"><span class="comment">#          [-0.0207,  0.0065,  0.0011,  0.0012]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[-0.0288, -0.0049,  0.0477,  0.0070],</span></span><br><span class="line"><span class="comment">#          [-0.0080, -0.0132, -0.0026, -0.0137],</span></span><br><span class="line"><span class="comment">#          [-0.0487,  0.0010,  0.0265,  0.0394]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 0.0045, -0.0982,  0.0159, -0.0079],</span></span><br><span class="line"><span class="comment">#          [-0.0933, -0.0658, -0.0572, -0.0075],</span></span><br><span class="line"><span class="comment">#          [ 0.0219, -0.0474, -0.0293, -0.0323]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[ 0.0352, -0.0154,  0.0057, -0.0013],</span></span><br><span class="line"><span class="comment">#          [ 0.0065, -0.0565, -0.0052, -0.1054],</span></span><br><span class="line"><span class="comment">#          [-0.0141, -0.0528,  0.0460, -0.0026]],</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         [[-0.0783, -0.0160,  0.0329, -0.0632],</span></span><br><span class="line"><span class="comment">#          [-0.0130, -0.0319, -0.0128,  0.0080],</span></span><br><span class="line"><span class="comment">#          [ 0.0227,  0.0099,  0.0768,  0.0151]]], grad_fn=&lt;StackBackward&gt;)</span></span><br></pre></td></tr></table></figure>
</li>
<li><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ffm_term = torch.sum(torch.sum(self.ffm(x), dim=<span class="number">1</span>), dim=<span class="number">1</span>, keepdim=<span class="keyword">True</span>)</span><br><span class="line">x = self.linear(x) + ffm_term</span><br></pre></td></tr></table></figure>
<p>各自得到线性和特征交互项后，通过上面的代码将两部分相加。self.ffm(x)返回batch_size*num_fields*embed_dim大小的列表，torch.sum(self.ffm(x), dim=1)沿着num_fields对各个field求和，得到batch_size<em>embed_dim的结果，再沿着embed_dim求和得到batch_size\</em>1的结果，即为ffm_term的大小，而self.linear(x)返回的是batch_size*output_dim大小的列表，其中output_dim=1，因此两部分可以直接相加，最后通过<code>x.squeeze(1)</code>消除长度为1的维度。</p>
</li>
<li><p>最后经过一个sigmoid得到大小为batch_size的一个tensor，其中每一个元素都在0到1之间，在MovieLens1M下表示用户喜欢电影的概率，CTR预估场景下为广告是否会被点击的概率。</p>
</li>
</ul>
<h4 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide &amp; Deep"></a>Wide &amp; Deep</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> name == <span class="string">'wd'</span>:</span><br><span class="line">  <span class="keyword">return</span> WideAndDeepModel(field_dims, embed_dim=<span class="number">16</span>, mlp_dims=(<span class="number">16</span>, <span class="number">16</span>), dropout=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WideAndDeepModel</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A pytorch implementation of wide and deep learning.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">        HT Cheng, et al. Wide &amp; Deep Learning for Recommender Systems, 2016.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, field_dims, embed_dim, mlp_dims, dropout)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = FeaturesLinear(field_dims)</span><br><span class="line">        self.embedding = FeaturesEmbedding(field_dims, embed_dim)</span><br><span class="line">        self.embed_output_dim = len(field_dims) * embed_dim</span><br><span class="line">        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Long tensor of size ``(batch_size, num_fields)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        embed_x = self.embedding(x)</span><br><span class="line">        x = self.linear(x) + self.mlp(embed_x.view(<span class="number">-1</span>, self.embed_output_dim))</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(x.squeeze(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<ul>
<li>Wide &amp; Deep模型中，Deep包含所有特征，Wide中包含人工设计的需要加强记忆能力的特征交互，Deep部分在pytorch-fm中由MLP实现，而Wide部分使用的是全部的物品特征，而且没有人工设计特征交互，使用LR进行实现。</li>
<li><code>embed_x.view(-1, self.embed_output_dim)</code>中的-1表示这一维度将由其他维度的结果推测得到。</li>
</ul>
<h4 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> name == <span class="string">'dfm'</span>:</span><br><span class="line">  <span class="keyword">return</span> DeepFactorizationMachineModel(field_dims, embed_dim=<span class="number">16</span>, mlp_dims=(<span class="number">16</span>, <span class="number">16</span>), dropout=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeepFactorizationMachineModel</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A pytorch implementation of DeepFM.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">        H Guo, et al. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction, 2017.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, field_dims, embed_dim, mlp_dims, dropout)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = FeaturesLinear(field_dims)</span><br><span class="line">        self.fm = FactorizationMachine(reduce_sum=<span class="keyword">True</span>)</span><br><span class="line">        self.embedding = FeaturesEmbedding(field_dims, embed_dim)</span><br><span class="line">        self.embed_output_dim = len(field_dims) * embed_dim</span><br><span class="line">        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Long tensor of size ``(batch_size, num_fields)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        embed_x = self.embedding(x)</span><br><span class="line">        x = self.linear(x) + self.fm(embed_x) + self.mlp(embed_x.view(<span class="number">-1</span>, self.embed_output_dim))</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(x.squeeze(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<ul>
<li>与Wide &amp; Deep对比，DeepFM在wide部分加入self.fm(embed_x)来进行特征的二阶自动交叉。</li>
</ul>
<h4 id="Neural-Factorization-Machine"><a href="#Neural-Factorization-Machine" class="headerlink" title="Neural Factorization Machine"></a>Neural Factorization Machine</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralFactorizationMachineModel</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A pytorch implementation of Neural Factorization Machine.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">        X He and TS Chua, Neural Factorization Machines for Sparse Predictive Analytics, 2017.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, field_dims, embed_dim, mlp_dims, dropouts)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.embedding = FeaturesEmbedding(field_dims, embed_dim)</span><br><span class="line">        self.linear = FeaturesLinear(field_dims)</span><br><span class="line">        self.fm = torch.nn.Sequential(</span><br><span class="line">            FactorizationMachine(reduce_sum=<span class="keyword">False</span>),</span><br><span class="line">            torch.nn.BatchNorm1d(embed_dim),</span><br><span class="line">            torch.nn.Dropout(dropouts[<span class="number">0</span>])</span><br><span class="line">        )</span><br><span class="line">        self.mlp = MultiLayerPerceptron(embed_dim, mlp_dims, dropouts[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Long tensor of size ``(batch_size, num_fields)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        cross_term = self.fm(self.embedding(x))</span><br><span class="line">        x = self.linear(x) + self.mlp(cross_term)</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(x.squeeze(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<ul>
<li>pytorch-fm通过FM实现NFM中的Bi-Interaction Layer，除此之外，NFM原文提到在Bi-Interaction Layer后面接着Batch Normalization和Dropout操作</li>
</ul>
<h4 id="Attention-Factorization-Machine"><a href="#Attention-Factorization-Machine" class="headerlink" title="Attention Factorization Machine"></a>Attention Factorization Machine</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> name == <span class="string">'afm'</span>:</span><br><span class="line">  <span class="keyword">return</span> AttentionalFactorizationMachineModel(field_dims, embed_dim=<span class="number">16</span>, attn_size=<span class="number">16</span>, dropouts=(<span class="number">0.2</span>, <span class="number">0.2</span>))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AttentionalFactorizationMachine</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, embed_dim, attn_size, dropouts)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.attention = torch.nn.Linear(embed_dim, attn_size)</span><br><span class="line">        self.projection = torch.nn.Linear(attn_size, <span class="number">1</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(embed_dim, <span class="number">1</span>)</span><br><span class="line">        self.dropouts = dropouts</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        num_fields = x.shape[<span class="number">1</span>]</span><br><span class="line">        row, col = list(), list()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_fields - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, num_fields):</span><br><span class="line">                row.append(i), col.append(j)</span><br><span class="line">        p, q = x[:, row], x[:, col]</span><br><span class="line">        inner_product = p * q</span><br><span class="line">        attn_scores = F.relu(self.attention(inner_product))</span><br><span class="line">        attn_scores = F.softmax(self.projection(attn_scores), dim=<span class="number">1</span>)</span><br><span class="line">        attn_scores = F.dropout(attn_scores, p=self.dropouts[<span class="number">0</span>], training=self.training)</span><br><span class="line">        attn_output = torch.sum(attn_scores * inner_product, dim=<span class="number">1</span>)</span><br><span class="line">        attn_output = F.dropout(attn_output, p=self.dropouts[<span class="number">1</span>], training=self.training)</span><br><span class="line">        <span class="keyword">return</span> self.fc(attn_output)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AttentionalFactorizationMachineModel</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A pytorch implementation of Attentional Factorization Machine.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">        J Xiao, et al. Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks, 2017.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, field_dims, embed_dim, attn_size, dropouts)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.num_fields = len(field_dims)</span><br><span class="line">        self.embedding = FeaturesEmbedding(field_dims, embed_dim)</span><br><span class="line">        self.linear = FeaturesLinear(field_dims)</span><br><span class="line">        self.afm = AttentionalFactorizationMachine(embed_dim, attn_size, dropouts)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param x: Long tensor of size ``(batch_size, num_fields)``</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        x = self.linear(x) + self.afm(self.embedding(x))</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(x.squeeze(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
\hat{y}_{AFM}(x)=w_0+\sum_{i=1}^nw_ix_i+\mathbf{p}^{T} \sum_{i=1}^n\sum_{j=i+1}^na_{ij}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}+b\\
\begin{aligned}
a_{ij}^{\prime} &=\mathbf{h}^{T} ReLU\left(\mathbf{W}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}+\mathbf{b}\right) \\
a_{ij} &=\frac{\exp \left(a_{ij}^{\prime}\right)}{\sum_{(i,j) \in \mathcal{R}_{x}} \exp \left(a_{ij}^{\prime}\right)}
\end{aligned}</script><ul>
<li>两个for循环是为了得到公式中embedding两两交叉，维度为(num_fields*(num_fields-1))/2的结果矩阵，row和col存储的是需要交叉的embedding的索引，以num_fields=3为例，需要两两交叉的embedding索引为[0,1],[0,2],[1,2]，则row=[0,0,1]，col=[1,2,2]。p，q分别为需要两两交叉的embedding中对应的第一个和第二个。</li>
</ul>
</v_{i},></v_i,v_j></v_i,v_j></计算机类书籍></程序员>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/推荐系统/" rel="tag">#推荐系统</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/11/16/增量学习笔记/" rel="next" title="增量学习笔记">
                <i class="fa fa-chevron-left"></i> 增量学习笔记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/11/17/图学习笔记/" rel="prev" title="图学习笔记">
                图学习笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.jpg"
                alt="Mr.shuan" />
            
              <p class="site-author-name" itemprop="name">Mr.shuan</p>
              <p class="site-description motion-element" itemprop="description">May 4th be with you</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">65</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">31</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://joaquinchou.com/" title="喵语小站" target="_blank">喵语小站</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://fans-xmu.github.io/" title="Fans的学习博客" target="_blank">Fans的学习博客</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#问题与挑战"><span class="nav-number">1.</span> <span class="nav-text">问题与挑战</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#做法及创新"><span class="nav-number">1.1.</span> <span class="nav-text">做法及创新</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#粗排模型"><span class="nav-number">1.2.</span> <span class="nav-text">粗排模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#精排模型"><span class="nav-number">1.3.</span> <span class="nav-text">精排模型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Neural-Factorization-Machines-for-Sparse-Predictive-Analytics-SIGIR’17"><span class="nav-number"></span> <span class="nav-text">Neural Factorization Machines for Sparse Predictive Analytics[SIGIR’17]</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#解决的问题"><span class="nav-number">1.</span> <span class="nav-text">解决的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#做法及创新-1"><span class="nav-number">2.</span> <span class="nav-text">做法及创新</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pytorch-FM"><span class="nav-number"></span> <span class="nav-text">Pytorch-FM</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#FeaturesEmbedding"><span class="nav-number">0.1.</span> <span class="nav-text">FeaturesEmbedding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MultiLayer-Perceptron"><span class="nav-number">0.2.</span> <span class="nav-text">MultiLayer Perceptron</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型"><span class="nav-number">1.</span> <span class="nav-text">模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Logistics-Regression"><span class="nav-number">1.1.</span> <span class="nav-text">Logistics Regression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Factorization-Machine"><span class="nav-number">1.2.</span> <span class="nav-text">Factorization Machine</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Field-aware-Factorization-Machine"><span class="nav-number">1.3.</span> <span class="nav-text">Field-aware Factorization Machine</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Wide-amp-Deep"><span class="nav-number">1.4.</span> <span class="nav-text">Wide &amp; Deep</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DeepFM"><span class="nav-number">1.5.</span> <span class="nav-text">DeepFM</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Neural-Factorization-Machine"><span class="nav-number">1.6.</span> <span class="nav-text">Neural Factorization Machine</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Attention-Factorization-Machine"><span class="nav-number">1.7.</span> <span class="nav-text">Attention Factorization Machine</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mr.shuan</span>

  
</div>


  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <span id="busuanzi_container_site_pv">原力小站已到访<span id="busuanzi_value_site_pv"></span>人次</span>
  <span class="post-meta-divider">|</span>
  <span id="busuanzi_container_site_uv">欢迎第<span id="busuanzi_value_site_uv"></span>位绝地武士








<div class="theme-info">
  <span class="post-meta-divider">|</span>
  <span class="post-count">小站全站共159.5k字</span>
</div>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("yfqHuQnnOVtQFUYkBt8hCuPk-gzGzoHsz", "04fMIxrudywlX8NlYX71hCnM");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  


</body>
</html>
