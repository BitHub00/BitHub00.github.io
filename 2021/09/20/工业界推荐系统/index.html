<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="推荐系统," />





  <link rel="alternate" href="/atom.xml" title="原力小站" type="application/atom+xml" />






<meta name="description" content="借这篇博客记录看工业界推荐系统论文的心得。">
<meta name="keywords" content="推荐系统">
<meta property="og:type" content="article">
<meta property="og:title" content="工业界推荐系统小综述">
<meta property="og:url" content="http://Bithub00.com/2021/09/20/工业界推荐系统/index.html">
<meta property="og:site_name" content="原力小站">
<meta property="og:description" content="借这篇博客记录看工业界推荐系统论文的心得。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BEwJs.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BVanK.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BVNX6.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BZZUe.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BZnCd.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BZVED.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BZgPJ.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BZ654.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4Besyt.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BerQI.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BeDSA.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/17/4KtfW8.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/17/4KB1ts.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4ahAk6.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4ahMnA.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4ahhH1.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4a4d2D.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4a5Uwn.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4aIt1O.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4aovQS.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4aT2wj.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4aTRTs.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4aTIpV.jpg">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4wrxln.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4wsVp9.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4wsmOx.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4wsGpd.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4wscXq.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/4wyp3d.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/40FPt1.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/40AJoj.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/23/40Eihn.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BqpB6.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BOiSH.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4BzKQe.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4DSqNq.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/24/4D9nzT.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/25/4skSbT.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/25/4rJKYR.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/25/4rtbWR.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/25/4skFPJ.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/09/25/4sk3RA.png">
<meta property="og:updated_time" content="2021-09-25T08:24:39.411Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="工业界推荐系统小综述">
<meta name="twitter:description" content="借这篇博客记录看工业界推荐系统论文的心得。">
<meta name="twitter:image" content="https://z3.ax1x.com/2021/09/24/4BEwJs.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://Bithub00.com/2021/09/20/工业界推荐系统/"/>





  <title>工业界推荐系统小综述 | 原力小站</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?43ca6a51990599ac3de948cb708d3909";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://github.com/BitHub00" 
      class="github-corner" 
      aria-label="View source on Github">
      <svg width="80" height="80" viewBox="0 0 250 250" 
      style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" 
      aria-hidden="true">
      <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
      <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
      <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path>
      </svg>
    </a>
      <style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}
      </style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">原力小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">扎导的原版正联出了吗？</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://Bithub00.com/2021/09/20/工业界推荐系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.shuan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="原力小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">工业界推荐系统小综述</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-09-20T23:28:26+08:00">
                2021-09-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2021/09/20/工业界推荐系统/" class="leancloud_visitors" data-flag-title="工业界推荐系统小综述">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  7,522
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>借这篇博客记录看工业界推荐系统论文的心得。</p>
<a id="more"></a>
<h2 id="Logistics-Regression"><a href="#Logistics-Regression" class="headerlink" title="Logistics Regression"></a>Logistics Regression</h2><p>本节主要参考<a href="https://zhuanlan.zhihu.com/p/151036015" target="_blank" rel="noopener">刘启林的推荐系统</a></p>
<p>逻辑回归是推荐领域的经典模型之一，回归是指将值回归到[0,1]区间。</p>
<h3 id="做法及创新"><a href="#做法及创新" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h4><p>LR将线性回归模型与Sigmoid函数相结合，线性回归模型的常见形式为$y=w^Tx+b$，为了表达形式上的统一，常将$w_0=b,x_0=1$，则有下图的$y=\sum_{i=0}^nw_ix_i=w^Tx$：</p>
<p><a href="https://imgtu.com/i/4BEwJs" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BEwJs.jpg" alt="4BEwJs.jpg"></a></p>
<p>LR按照输出y的取值可以分为$y\in\{0,1\}、y\in\{-1,1\}$两种形式：</p>
<ul>
<li><p>CTR预估（0：曝光后未被点击，1：曝光后被点击）</p>
<blockquote>
<p>伯努利分布：随机变量X只能取0和1两个值：</p>
<script type="math/tex; mode=display">
P(X=k)=p^k(1-p)^{1-k},~k={0,1}</script></blockquote>
<p><a href="https://imgtu.com/i/4BVanK" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BVanK.jpg" alt="4BVanK.jpg"></a></p>
</li>
<li><p>分类预估（-1：负类，1：正类）</p>
<p><a href="https://imgtu.com/i/4BVNX6" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BVNX6.jpg" alt="4BVNX6.jpg"></a></p>
</li>
</ul>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p><a href="https://imgtu.com/i/4BZZUe" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BZZUe.jpg" alt="4BZZUe.jpg"></a></p>
<p><a href="https://imgtu.com/i/4BZnCd" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BZnCd.jpg" alt="4BZnCd.jpg"></a><br><a href="https://imgtu.com/i/4BZVED" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BZVED.jpg" alt="4BZVED.jpg"></a></p>
<p><a href="https://imgtu.com/i/4BZgPJ" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BZgPJ.jpg" alt="4BZgPJ.jpg"></a><br><a href="https://imgtu.com/i/4BZ654" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BZ654.jpg" alt="4BZ654.jpg"></a></p>
<p><a href="https://imgtu.com/i/4Besyt" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4Besyt.jpg" alt="4Besyt.jpg"></a><br><a href="https://imgtu.com/i/4BerQI" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BerQI.jpg" alt="4BerQI.jpg"></a><br><a href="https://imgtu.com/i/4BeDSA" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BeDSA.jpg" alt="4BeDSA.jpg"></a></p>
<h4 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h4><ul>
<li>适合离散特征；增加、减少特征容易，易于拟合、快速迭代</li>
<li>特征空间大，容易过拟合；</li>
<li>去掉高度相关特征；</li>
</ul>
<h2 id="Wide-amp-Deep-Learning-for-Recommender-Systems-DLRS’16"><a href="#Wide-amp-Deep-Learning-for-Recommender-Systems-DLRS’16" class="headerlink" title="Wide &amp; Deep Learning for Recommender Systems[DLRS’16]"></a>Wide &amp; Deep Learning for Recommender Systems[DLRS’16]</h2><h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>解决推荐时Memorization和Generalization无法兼顾的问题。</p>
<h4 id="Memorization"><a href="#Memorization" class="headerlink" title="Memorization"></a>Memorization</h4><p>面对拥有大规模离散sparse特征的CTR预估问题时，可以通过将特征之间进行叉乘来捕捉特征之间的相关性，典型代表如LR模型，使用原始sparse特征和叉乘特征作为输入。但缺点是特征的叉乘需要人工进行设计，而且对于训练数据中未曾出现过的特征对，模型中对应项的权重也会为0.</p>
<h4 id="Generalization"><a href="#Generalization" class="headerlink" title="Generalization"></a>Generalization</h4><p>Generalization为sparse特征学习低维的dense embeddings来捕获相关性，它相较于Memorization涉及更少的人工设计以及更好的泛化能力，即使训练数据中未曾出现的特征对，对应的权重也会因为各自的dense embeddings而非零。但缺点也是会带来过度泛化，当user-item矩阵非常稀疏时，例如小众爱好的user和冷门商品，这时大部分user-item应该是没有关联的，但dense embedding还是能得到非零预测，导致推荐不怎么相关的商品，这时Memorization更好，因为它可以记忆这些特殊的特征组合。</p>
<p>Memorization根据历史行为数据，产生的推荐通常和用户已有行为的物品直接相关的物品。而Generalization会学习新的特征组合，提高推荐物品的多样性。 论文作者结合两者的优点，提出了一个新的学习算法——Wide &amp; Deep Learning，其中Wide &amp; Deep分别对应Memorization &amp; Generalization。</p>
<p><a href="https://imgtu.com/i/4KtfW8" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/17/4KtfW8.png" alt="4KtfW8.png"></a></p>
<h3 id="做法及创新-1"><a href="#做法及创新-1" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><strong>Wide</strong>部分是一个广义线性模型，其中$x$和$\phi(x)$表示原始特征和叉乘特征：</p>
<script type="math/tex; mode=display">
y=w^T[x,\phi(x)]+b</script><p>原始特征$x=[x_1,x_2,\cdots,x_d]$有$d$维，叉乘特征的构造方式为：$\phi_k(x)=\Pi_{i=1}^dx_i^{c_{ki}},~c_{ki}\in\{0,1\}$</p>
<p>其实就是用一个布尔变量来标示哪些特征进行了叉乘。</p>
<p><strong>Deep</strong>部分是前馈神经网络，它会对一些sparse特征（如ID类特征）学习一个dense embeddings，维度在O(10)到O(100)之间。</p>
<script type="math/tex; mode=display">
a^{l+1}=f(W^la^l+b^l)</script><p><strong>损失函数</strong>选取的是logistic损失函数，模型最后的预测输出为，其中$a^{l_f}$是神经网络最后一层的激活值：</p>
<script type="math/tex; mode=display">
p(y=1|x)=\sigma(w^T_{wide}[x,\phi(x)]+w^T_{deep}a^{l_f}+b)</script><p><strong>联合训练</strong>时Wide部分只需要做一小部分的特征叉乘来弥补Deep部分的不足，不需要一个完整的Wide模型。优化方法使用的是mini-batch随机梯度下降，Wide部分是带L1正则的FTRL算法，Deep部分是AdaGrad算法。</p>
<p><a href="https://imgtu.com/i/4KB1ts" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/17/4KB1ts.png" alt="4KB1ts.png"></a></p>
<p>实验部分采取的模型设置如上图所示，其中的细节为：</p>
<ul>
<li>连续型特征会被归一化到[0,1]之间</li>
<li>离散型特征映射到32维embeddings，与原始连续特征共1200维作为网络输入</li>
<li>Wide部分只有一组特征叉乘，被推荐的App×用户下载的App，希望Wide部分能发现这样的规则：用户安装了应用A，此时曝光应用B，用户安装的B概率大。</li>
<li>线上模型更新时，用上次的embeddings和模型参数进行”热启动“</li>
</ul>
<h4 id="实践细节"><a href="#实践细节" class="headerlink" title="实践细节"></a>实践细节</h4><ol>
<li><p>为什么Wide部分要用L1 FTRL训练？</p>
<p>FTRL的介绍可见<a href="https://github.com/wzhe06/Ad-papers/blob/master/Optimization%20Method/%E5%9C%A8%E7%BA%BF%E6%9C%80%E4%BC%98%E5%8C%96%E6%B1%82%E8%A7%A3(Online%20Optimization" target="_blank" rel="noopener">文章</a>-%E5%86%AF%E6%89%AC.pdf)。这种方式注重模型的稀疏性，能让Wide部分变得更加稀疏，大部分权重都为0。</p>
</li>
<li><p>为什么Deep部分不考虑稀疏性的问题？</p>
<p>Deep部分的输入，要么是Age，#App Installs这些数值类特征，要么是已经降维并稠密化的Embeddings向量。所以Deep部分不存在严重的特征稀疏问题，自然可以使用精度更好，更适用于深度学习训练的AdaGrad去训练。</p>
</li>
</ol>
<h2 id="Factorization-Machines"><a href="#Factorization-Machines" class="headerlink" title="Factorization Machines"></a>Factorization Machines</h2><p>本节内容主要参考<a href="https://zhuanlan.zhihu.com/p/145436595" target="_blank" rel="noopener">刘启林的推荐系统</a></p>
<h3 id="解决的问题-1"><a href="#解决的问题-1" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>因子分解机在线性回归模型中加入了特征的交互，来建模特征的相关性，并且解决数据的稀疏性以及特征空间维度过高的问题。</p>
<p>对于常见的categorical特征，经过one-hot编码以后，样本的数据就会变得很稀疏。举例来说，假设淘宝或者京东上的item为100万，如果对item这个维度进行one-hot编码，光这一个维度数据的稀疏度就是百万分之一。将item进行one-hot编码以后，样本空间有一个categorical变为了百万维的数值特征，特征空间也会一下子暴增一百万。</p>
<h3 id="做法及创新-2"><a href="#做法及创新-2" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="核心思想-1"><a href="#核心思想-1" class="headerlink" title="核心思想"></a>核心思想</h4><p>线性回归模型假设特征之间相互独立：</p>
<script type="math/tex; mode=display">
y=w_0+\sum_{i=1}^nw_ix_i</script><p>而现实场景中，特征之间是有相关性的，例如&lt;程序员&gt;与&lt;计算机类书籍&gt;，因此需要在线性回归模型中加入特征组合项。最简单的组合方式是两两组合，变为二阶多项式回归模型，多出$\frac{n(n-1)}{2}$项：</p>
<script type="math/tex; mode=display">
y=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^n\sum_{j\ge i}^nw_{ij}x_ix_j</script><p>这样做的局限是对于样本中没出现过交互的特征组合，就无法对相应的参数进行估计，而且时间复杂度上升到了$O(n^2)$。</p>
<p>上式中的二项式参数$w_{ij}$可以组成一个对称矩阵$W$，根据Cholesky分解可以分解成：</p>
<blockquote>
<p>Cholesky分解：将一个对称正定矩阵化为一个下三角矩阵与其共轭转置矩阵的积</p>
</blockquote>
<script type="math/tex; mode=display">
W=VV^T</script><p>二次项参数转化为$w_{ij}=<v_i,v_j>=\sum_{f=1}^kv_{i,f}v_{j,f}$，此时隐向量的特征维度$k$一般远小于原始特征维度$n$。$v_i\in \mathbb{R}^k$是特征i的嵌入向量。FM的假设是，特征两两相关。</v_i,v_j></p>
<h4 id="计算化简"><a href="#计算化简" class="headerlink" title="计算化简"></a>计算化简</h4><p>FM的计算复杂度可以化简为线性复杂度：</p>
<p><a href="https://imgtu.com/i/4ahAk6" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4ahAk6.jpg" alt="4ahAk6.jpg"></a></p>
<p><a href="https://imgtu.com/i/4ahMnA" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4ahMnA.jpg" alt="4ahMnA.jpg"></a></p>
<p><a href="https://imgtu.com/i/4ahhH1" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4ahhH1.jpg" alt="4ahhH1.jpg"></a></p>
<h4 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h4><p>FM模型可用于回归（Regression）、二分类（Binary classification）、排名（Ranking）任务，其对应的损失函数如下：</p>
<p><a href="https://imgtu.com/i/4a4d2D" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4a4d2D.jpg" alt="4a4d2D.jpg"></a></p>
<p><a href="https://imgtu.com/i/4a5Uwn" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4a5Uwn.jpg" alt="4a5Uwn.jpg"></a></p>
<p>以随机梯度下降训练为例：</p>
<p><a href="https://imgtu.com/i/4aIt1O" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4aIt1O.jpg" alt="4aIt1O.jpg"></a></p>
<p><a href="https://imgtu.com/i/4aovQS" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4aovQS.jpg" alt="4aovQS.jpg"></a></p>
<h4 id="特征工程-1"><a href="#特征工程-1" class="headerlink" title="特征工程"></a>特征工程</h4><p>FM模型对特征两两自动组合，不需要人工参与，类别特征One-Hot化，以一个电影数据集为例：</p>
<p><a href="https://imgtu.com/i/4aT2wj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4aT2wj.jpg" alt="4aT2wj.jpg"></a></p>
<p><a href="https://imgtu.com/i/4aTRTs" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4aTRTs.jpg" alt="4aTRTs.jpg"></a></p>
<p><a href="https://imgtu.com/i/4aTIpV" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4aTIpV.jpg" alt="4aTIpV.jpg"></a></p>
<h2 id="Field-aware-Factorization-Machines-for-CTR-Prediction-RecSys’16"><a href="#Field-aware-Factorization-Machines-for-CTR-Prediction-RecSys’16" class="headerlink" title="Field-aware Factorization Machines for CTR Prediction[RecSys’16]"></a>Field-aware Factorization Machines for CTR Prediction[RecSys’16]</h2><p>本节主要参考<a href="https://tech.meituan.com/2016/03/03/deep-understanding-of-ffm-principles-and-practices.html" target="_blank" rel="noopener">深入FFM原理与实践</a>、<a href="https://www.jianshu.com/p/781cde3d5f3d" target="_blank" rel="noopener">FFM模型理论和实践</a></p>
<h3 id="解决的问题-2"><a href="#解决的问题-2" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>FM在遇到one-hot类型的特征时遇到的数据稀疏性问题。</p>
<h3 id="做法及创新-3"><a href="#做法及创新-3" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="核心思想-2"><a href="#核心思想-2" class="headerlink" title="核心思想"></a>核心思想</h4><p>FFM模型中引入了域（field）的概念，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个域，包括用户国籍，广告类型，日期等等，以一条CTR点击数据为例，说明FFM与FM的区别：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Clicked</th>
<th style="text-align:center">Publisher(P)</th>
<th style="text-align:center">Advertiser(A)</th>
<th style="text-align:center">Gender(G)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Yes</td>
<td style="text-align:center">ESPN</td>
<td style="text-align:center">Nike</td>
<td style="text-align:center">Male</td>
</tr>
</tbody>
</table>
</div>
<p>对于FM，只会考虑二次交叉项：</p>
<script type="math/tex; mode=display">
\phi_{FM}=V_{ESPN}\cdot V_{Nike}+V_{ESPN}\cdot V_{Male}+V_{Nike}\cdot V_{Male}</script><p>因为Nike与Male显然属于不同的field，所以（ESPN，Nike）和（ESPN，Male）的隐含含义也可能是不同的，而FM只用一个隐向量$V_{ESPN}$来统一表示ESPN与Nike和Maled的交互作用，不够准确。而在FFM中，域之间的交互作用是不同的，每个特征有k个隐向量个数，k为其余特征field的个数：</p>
<script type="math/tex; mode=display">
\phi_{FFM}=V_{ESPN,A}\cdot V_{Nike,P}+V_{ESPN,G}\cdot V_{Male,P}+V_{Nike,G}\cdot V_{Male,A}</script><p>所以FFM的数学表达式为：</p>
<script type="math/tex; mode=display">
\phi_{FFM}(w,x)=\sum_{i=1}^n\sum_{j\ge i}^nw_{i,f_j}\cdot w_{j,f_i}x_ix_j</script><p>FFM的参数个数为kfn，FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型。值得注意的是，由于隐向量与field相关，所以FFM中的二次项不能够化简，它的时间复杂度为$O(kn^2)$。</p>
<h4 id="实践细节-1"><a href="#实践细节-1" class="headerlink" title="实践细节"></a>实践细节</h4><ol>
<li>样本归一化。FFM默认是进行样本数据的归一化，否则容易造成数据inf溢出，进而引起梯度计算的nan错误。因此，样本层面的数据是推荐进行归一化的。</li>
<li>特征归一化。CTR/CVR模型采用了多种类型的源特征，包括数值型和categorical类型等。但是，categorical类编码后的特征取值只有0或1，较大的数值型特征会造成样本归一化后categorical类生成特征的值非常小，没有区分性。例如，一条用户-商品记录，用户为“男”性，商品的销量是5000个（假设其它特征的值为零），那么归一化后特征“sex=male”（性别为男）的值略小于0.0002，而“volume”（销量）的值近似为1。特征“sex=male”在这个样本中的作用几乎可以忽略不计，这是相当不合理的。因此，将源数值型特征的值归一化到[0,1]是非常必要的。</li>
<li>省略零值特征。零值特征对模型完全没有贡献。包含零值特征的一次项和组合项均为零，对于训练模型参数或者目标值预估是没有作用的。因此，可以省去零值特征，提高FFM模型训练和预测的速度，这也是稀疏样本采用FFM的显著优势。</li>
</ol>
<h2 id="DeepFM-A-Factorization-Machine-based-Neural-Network-for-CTR-Prediction-IJCAI’17"><a href="#DeepFM-A-Factorization-Machine-based-Neural-Network-for-CTR-Prediction-IJCAI’17" class="headerlink" title="DeepFM: A Factorization-Machine based Neural Network for CTR Prediction[IJCAI’17]"></a>DeepFM: A Factorization-Machine based Neural Network for CTR Prediction[IJCAI’17]</h2><p>本节主要参考<a href="https://static001.geekbang.org/con/33/pdf/1511951900/file/%E6%9C%80%E7%BB%88%E7%89%88-%E5%BC%A0%E4%BF%8A%E6%9E%97-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%9A%84%E6%8A%80%E6%9C%AF%E8%BF%9B%E5%B1%95%E5%8F%8A%E5%BE%AE%E5%8D%9A%E7%9A%84%E5%BA%94%E7%94%A8.pdf" target="_blank" rel="noopener">深度学习在推荐的技术进展及微博的应用</a>、<a href="https://www.jianshu.com/p/6f1c2643d31b" target="_blank" rel="noopener">DeepFM模型理论与实践</a></p>
<h3 id="解决的问题-3"><a href="#解决的问题-3" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>对于一个基于CTR预估的推荐系统，最重要的是学习到用户点击行为背后隐含的特征组合。举例来说，在主流的app市场上，我们发现，用户喜欢在用餐时间下载送餐app， 说明二阶交叉特征“app类别-时间戳” 可以作为CTR预估的重要特征。另一个发现， 男青年喜欢射击游戏和RPG游戏，因此，三阶交叉特征“app类别-用户性别-用户年龄”也可以作为CTR预估的一个特征。但是这种交叉特征往往需要专家知识，类似“尿布-啤酒”这种经典的例子。</p>
<p>前面提到的FM虽然理论上来讲可以对高阶特征组合进行建模，但实际上因为计算复杂度的原因一般都只用到了二阶特征组合。而多层神经网络能够学习复杂的交叉特征。</p>
<h3 id="做法及创新-4"><a href="#做法及创新-4" class="headerlink" title="做法及创新"></a>做法及创新</h3><h4 id="DNN与高维特征"><a href="#DNN与高维特征" class="headerlink" title="DNN与高维特征"></a>DNN与高维特征</h4><p>虽然DNN能够学习复杂的特征组合，但直接应用于CTR预告等问题上时会在离散型特征上遇到阻碍，对于离散型特征典型的做法是进行one-hot编码，这会导致输入的数据维度非常高：</p>
<p><a href="https://imgtu.com/i/4wrxln" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4wrxln.png" alt="4wrxln.png"></a></p>
<p><a href="https://imgtu.com/i/4wsVp9" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4wsVp9.png" alt="4wsVp9.png"></a></p>
<p>类似于FFM中将特征按域来进行分类，可以将输入的one-hot数据按照域形成对应的dense vector，来避免数据稀疏性的问题：</p>
<p><a href="https://imgtu.com/i/4wsmOx" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4wsmOx.png" alt="4wsmOx.png"></a></p>
<p><a href="https://imgtu.com/i/4wsGpd" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4wsGpd.png" alt="4wsGpd.png"></a></p>
<p><a href="https://imgtu.com/i/4wscXq" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4wscXq.png" alt="4wscXq.png"></a></p>
<p><a href="https://imgtu.com/i/4wyp3d" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/4wyp3d.png" alt="4wyp3d.png"></a></p>
<p>也就是希望能将DNN与FM进行一个融合，而融合的形式总的来说分为串行与并行，本节介绍的DeepFM以及前面介绍过的Wide&amp;Deep都为典型的并行结构。</p>
<p><a href="https://imgtu.com/i/40FPt1" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/40FPt1.png" alt="40FPt1.png"></a></p>
<h4 id="核心思想-3"><a href="#核心思想-3" class="headerlink" title="核心思想"></a>核心思想</h4><p><a href="https://imgtu.com/i/40AJoj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/40AJoj.png" alt="40AJoj.png"></a></p>
<p>首先来看DeepFM的结构，FM与DNN分别负责提取低阶与高阶特征，这两部分<strong>共享输入</strong>：</p>
<p><a href="https://imgtu.com/i/40Eihn" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/23/40Eihn.png" alt="40Eihn.png"></a></p>
<p>FM部分与标准的FM并无不同，而DNN部分，在进入第一层隐藏层之前，首先通过一个嵌入层来将输入的高维特征压缩到低维稠密向量。这一部分的两个特点为：</p>
<ol>
<li>尽管不同域的特征维度不同，在经过压缩后的维度均为k。</li>
<li>FM部分的隐向量V现在作为DNN的嵌入层权重。这样一来就不需要通过FM对隐向量V进行预训练之后对DNN的嵌入层进行初始化，而是在训练DNN时对V一起进行学习，做到端到端。</li>
</ol>
<h2 id="Deep-Neural-Networks-for-YouTube-Recommendations-RecSys’16"><a href="#Deep-Neural-Networks-for-YouTube-Recommendations-RecSys’16" class="headerlink" title="Deep Neural Networks for YouTube Recommendations[RecSys’16]"></a>Deep Neural Networks for YouTube Recommendations[RecSys’16]</h2><p>本节要介绍的是Youtube出品的经典工业界论文，主要内容参考<a href="https://zhuanlan.zhihu.com/p/52169807" target="_blank" rel="noopener">王喆的机器学习笔记1</a>、<a href="https://zhuanlan.zhihu.com/p/61827629" target="_blank" rel="noopener">王喆的机器学习笔记2</a>、<a href="https://www.jianshu.com/p/8fa4dcbd5588" target="_blank" rel="noopener">深度学习遇上推荐系统</a>。</p>
<h3 id="解决的问题-4"><a href="#解决的问题-4" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>作为全球最大的UGC的视频网站，Youtube需要在百万量级的视频规模下进行个性化推荐。由于候选视频集合过大，考虑online系统延迟问题，不宜用复杂网络直接进行推荐，所以Youtube采取了两层深度网络完成整个推荐过程：</p>
<ol>
<li>第一层是<strong>Candidate Generation Model</strong>完成候选视频的快速筛选，这一步候选视频集合由百万降低到了百的量级（粗排）。</li>
<li>第二层是用<strong>Ranking Model</strong>完成几百个候选视频的排序（精排）。</li>
</ol>
<div align="center">
<a href="https://imgtu.com/i/4BqpB6" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BqpB6.png" alt="4BqpB6.png" border="0" width="75%"></a>
</div>

<h4 id="做法及创新-5"><a href="#做法及创新-5" class="headerlink" title="做法及创新"></a>做法及创新</h4><h4 id="粗排模型"><a href="#粗排模型" class="headerlink" title="粗排模型"></a>粗排模型</h4><div align="center">
<a href="https://imgtu.com/i/4BOiSH" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BOiSH.png" alt="4BOiSH.png" border="0" width="65%/"></a>
</div>

<p>自底向上看粗排模型的结构，最底层的输入是用户观看过的video的embedding向量，以及搜索词的embedding向量，由word2vec得到。特别地，历史搜索的query分词后的token的embedding向量进行平均，能够反映用户的整体搜索历史状态。其它的特征向量还包括了用户的地理位置的embedding，年龄，性别等。然后把所有这些特征concatenate起来，输入上层的ReLU神经网络。</p>
<p><strong>引入fresh content的bias的作用？</strong></p>
<p>这里比较特别的一个特征是”example age“。每一秒中，YouTube都有大量视频被上传，推荐这些最新视频对于YouTube来说是极其重要的。同时，通过观察历史数据发现，用户更倾向于推荐相关度不高但最新（fresh）的视频。视频的点击率实际上都会受fresh的影响，训练的时候加入example age ，为的就是“显式”的告诉模型example age对点击的影响。在预测的时候，example age置0，就排除了这个特征对模型的影响。类似于广告，广告在展示列表中的位置，对广告的点击概率有非常大影响，排名越靠前的广告，越容易被点击，在产生训练样本的时候，把展示位置作为特征放在样本里面，并且在使用模型的时候，把展示位置特征统一置为0。</p>
<p>假设一个视频是十天前发布的，许多用户在当前观看了该视频，那么在当天会产生许多Sample Log，而在后面的九天里，观看记录不多，Sample Log也很少。如果我们没有加入Example Age这个特征的话，无论何时训练模型，这个视频对应的分类概率都是差不多的，但是如果我们加入这个特征，模型就会知道，如果这条记录是十天前产生的话，该视频会有很高的分类概率，如果是最近几天产生的话，分类概率应该低一些，这样可以更加逼近实际的数据。实验结果也证明了这一点：</p>
<div align="center">
<a href="https://imgtu.com/i/4BzKQe" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4BzKQe.png" alt="4BzKQe.png" border="0" width="65%/"></a>
</div>

<p>训练样本的产生方面，正样本是用户所有完整观看过的视频，其余可以视作负样本。同时，针对每一个用户的观看记录，都生成了固定数量的训练样本，这样，每个用户在损失函数中的地位都是相等的，防止一小部分超级活跃用户主导损失函数。</p>
<p>在对待用户的搜索和观看历史时，Youtube并没有选择时序模型，而是完全摒弃了序列关系，采用求平均的方式对历史记录进行了处理。这是因为考虑时序关系，用户的推荐结果将过多受最近观看或搜索的一个视频的影响。文章中给出一个例子，如果用户刚搜索过“taylor swift”，你就把用户主页的推荐结果大部分变成taylor swift有关的视频，这其实是非常差的体验。为了综合考虑之前多次搜索和观看的信息，YouTube丢掉了时序信息，将用户近期的历史纪录等同看待。</p>
<p><a href="https://imgtu.com/i/4DSqNq" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4DSqNq.png" alt="4DSqNq.png" border="0"></a></p>
<p>在处理测试集时，Youtube采用的是图(b)的方式。图(a)是held-out方式，利用上下文信息预估中间的一个视频；图(b)是predicting next watch的方式，则是利用上文信息，预估下一次浏览的视频。我们发现图(b)的方式在线上A/B test中表现更佳。而且只留最后一次观看行为做测试集主要是为了避免引入future information，产生与事实不符的数据穿越。</p>
<p>输出方面，因为Youtube将推荐问题建模成一个“超大规模多分类”问题。即在时刻t，用户U（上下文信息C）会观看视频i的概率（每个具体的视频视为一个类别，i即为一个类别），所以输出应该是一个在所有candidate video上的概率分布，自然是一个多分类问题。</p>
<p>同时，输出分为线上和离线训练两个部分。离线训练阶段输出层为softmax层，输出3.1中公式表达的概率。对于在线服务来说，有严格的性能要求，Youtube没有重新跑一遍模型，而是通过保存用户的embedding和视频的embedding，通过最近邻搜索的方法得到top N（approx topN，使用hash的方法来得到近似的topN）的结果。</p>
<h4 id="精排模型"><a href="#精排模型" class="headerlink" title="精排模型"></a>精排模型</h4><div align="center">
<a href="https://imgtu.com/i/4D9nzT" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/24/4D9nzT.png" alt="4D9nzT.png" border="0" width="75%/"></a>
</div>
排序过程是对生成的候选集做进一步细粒度的排序，模型架构与粗排模型基本一致，区别在于特征工程部分，图中从左至右的特征依次是：

1. **impression video ID embedding**: 当前要计算的video的embedding
2. **watched video IDs average embedding**: 用户观看过的最后N个视频embedding的average pooling
3. **language embedding**: 用户语言的embedding和当前视频语言的embedding
4. **time since last watch**: 自上次观看同channel视频的时间
5. **previous impressions**: 该视频已经被曝光给该用户的次数

后面两个特征很好地引入了对用户行为的观察，第4个特征是用户上次观看同频道时间距现在的时间间隔,从用户的角度想一想，假如我们刚看过“DOTA经典回顾”这个channel的视频，我们很大概率是会继续看这个channel的视频的，那么该特征就很好的捕捉到了这一用户行为。第5个特征previous impressions则一定程度上引入了exploration的思想，避免同一个视频持续对同一用户进行无效曝光。尽量增加用户没看过的新视频的曝光可能性。

在**特征处理**部分分为离散与连续变量：

**离散变量**

* 在进行video embedding的时候，只保留用户最常点击的N个视频的embedding，剩余的长尾视频的embedding直接用0向量代替。把大量长尾的video截断掉，主要还是为了节省online serving中宝贵的内存资源。当然从模型角度讲，低频video的embedding的准确性不佳是另一个“截断掉也不那么可惜”的理由。
* 对于相同域的特征可以共享embedding，比如用户点击过的视频ID，用户观看过的视频ID，用户收藏过的视频ID等等，这些公用一套embedding可以使其更充分的学习，同时减少模型的大小，加速模型的训练。

**连续变量**

* 主要是归一化处理，同时还把归一化后的的根号和平方作为网络输入，以期能使网络能够更容易得到特征的次线性（sub-linear）和（super-linear）超线性函数。（引入了特征的非线性）。

在精排模型的**训练**阶段，模型采用了用户的期望观看时间作为优化目标，所以如果简单使用LR就无法引入正样本的观看时间信息。因此采用weighted LR，将观看时间$T_i$作为正样本的权重，对于负样本，权重是单位权重(可以认为是1)。在线上serving中使用$e^{w^Tx+b}$做预测可以直接得到expected watch time的近似。这里引出一个问题：

1. 在模型serving过程中又为何没有采用sigmoid函数预测正样本的probability，而是使用$e^{w^Tx+b}$这一指数形式预测用户观看时长？

   > 回到LR的定义：
   > $$
   > y=\frac{1}{1+e^{-w^Tx}}
   > $$
   > 对于二分类问题：
   > $$
   > P(y=1|x)=\sigma(x) \\
   > P(y=0|x)=1-\sigma(x)
   > $$
   > 一件事情的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值，如果事件发生的概率是p，那么该事件的odds是$\frac{p}{1-p}$，对于LR而言：
   > $$
   > \frac{\frac{1}{1+e^{-w^Tx}}}{1-\frac{1}{1+e^{-w^Tx}}}=e^{w^Tx}
   > $$
   > 所以$e^{w^Tx+b}$求的就是LR形式下的odds。
   >
   > Weighted LR中的单个样本的weight，并不是让这个样本发生的概率变成了weight倍，而是让这个样本，对预估的影响(也就是loss)提升了weight倍。因为观看时长的几率=$\frac{\sum T_i}{N-k}$，其中k为正样本的个数，非wieght的odds可以直接看成N+/N-，因为wieghted的lr中，N+变成了weight倍，N-没变，还是1倍，所以直接可得后来的odds是之前odds的weight倍。
   >
   > 也就是说样本i的odds变成了下面的式子，由于在视频推荐场景中，用户打开一个视频的概率p往往是一个很小的值，且YouTube采用了用户观看时长$T_i$作为权重，$w_i=T_i$，所以有：
   > $$
   > odds(i)=\frac{w_ip}{1-w_ip}\approx w_ip=T_ip
   > $$
   > 这就是用户观看某视频的期望时长的计算式。


所以模型serving部分使用的是这个形式，经历了$e^{w^Tx+b}\rightarrow odds\rightarrow 用户期望观看时长$的过程。

## Deep & Cross Network for Ad Click Predictions[ADKDD'17]

本节主要参考[玩转企业级Deep&Cross Network模型你只差一步](https://zhuanlan.zhihu.com/p/43364598)、[揭秘 Deep & Cross : 如何自动构造高阶交叉特征](https://zhuanlan.zhihu.com/p/55234968)

### 解决的问题

这篇论文是Google对 Wide & Deep工作的一个后续研究，文中提出 Deep & Cross Network，将Wide部分替换为由特殊网络结构实现的Cross，**自动构造有限高阶的交叉特征**，并学习对应权重，从而在一定程度上告别人工特征叉乘，说一定程度是因为文中出于模型复杂度的考虑，仍是仅对sparse特征对应的embedding作自动叉乘，但这仍是一个有益的创新。

Wide & Deep 的结构能同时实现Memorization与Generalization，但是在Wide部分，仍然需要人工地设计特征叉乘。面对高维稀疏的特征空间、大量的可组合方式，基于人工先验知识虽然可以缓解一部分压力，但仍需要不小的人力和尝试成本，并且很有可能遗漏一些重要的交叉特征。FM可以自动组合特征，但也仅限于二阶叉乘。能否告别人工组合特征，并且自动学习高阶的特征组合呢？Deep & Cross 即是对此的一个尝试。

### 做法及创新

#### 核心思想

DCN的结构如下图所示，由嵌入和堆叠层、交叉网络、深度网络以及组合输出网络四部分构成：

<a href="https://imgtu.com/i/4skSbT" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/25/4skSbT.png" alt="4skSbT.png" border="0"></a>

<div align="center">
<a href="https://imgtu.com/i/4rJKYR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/25/4rJKYR.png" alt="4rJKYR.png" border="0" width="75%/"></a>
</div>

<p><strong>嵌入和堆叠层</strong></p>
<p>这部分和前面介绍的模型做法大同小异，就是对于one-hot编码的离散型特征，通过嵌入来将输入的高维特征压缩到低维稠密向量，最后将嵌入向量与归一化的连续型特征进行堆叠，形成模型的输入。</p>
<p><strong>交叉网络</strong></p>
<p>交叉网络的每一层形式为：</p>
<script type="math/tex; mode=display">
x_{l+1}=x_0x^T_lw_l+b_l+x_l=f(x_l,w_l,b_l)+x_l</script><ol>
<li>每层的神经元个数都相同，都等于输入$x_0$的维度$d$，也即每层的输入输出维度都是相等的。</li>
<li>受残差网络（Residual Network）结构启发，每层的函数f拟合的是$x_{l+1}-x_l$的残差，残差网络有很多优点，其中一点是处理梯度消失的问题，使网络可以“更深”。</li>
</ol>
<p>那么交叉网络为什么能够自动构造有限高阶的交叉特征呢？以一个二层的交叉网络为例，其中$x_0=[x_{0,1};x_{0,2}]$，另各层的$b_i=0$：</p>
<p><a href="https://imgtu.com/i/4rtbWR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/25/4rtbWR.png" alt="4rtbWR.png" border="0"></a></p>
<p>最后得到$y_{cross}=x_2^T*w_{cross}$，可以看到$x_1$包含了原始特征 $x_{0,1}$、$x_{0,2}$从一阶到二阶的所有可能叉乘组合，而 $x_2$包含了其从一阶到三阶的所有可能叉乘组合。从这个例子可以看出DCN的特点：</p>
<ul>
<li><strong>有限高阶</strong>：叉乘<strong>阶数由网络深度决定</strong>，深度$L_c$对应最高阶$L_c+1$的叉乘</li>
<li><strong>自动叉乘</strong>：Cross输出包含了原始特征从一阶（即本身）到$L_c+1$阶的<strong>所有叉乘组合，</strong>而模型参数量仅仅随输入维度成<strong>线性增长</strong>：$2<em>d</em>L_c$</li>
<li><strong>参数共享</strong>：不同叉乘项对应的权重不同，但并非每个叉乘组合对应独立的权重（指数数量级）， 通过参数共享，Cross有效<strong>降低了参数量</strong>。此外，参数共享还使得模型有更强的<strong>泛化性</strong>和<strong>鲁棒性</strong>。例如，如果独立训练权重，当训练集中$x_i\not =0 \land x_j\not =0$这个叉乘特征没有出现 ，对应权重肯定是零，而参数共享则不会，类似地，数据集中的一些噪声可以由大部分正常样本来纠正权重参数的学习</li>
</ul>
<p>训练部分，模型的Deep 部分如上图右侧部分所示，DCN拼接Cross和Deep的输出，采用logistic loss作为损失函数，进行联合训练，这些细节与Wide &amp; Deep几乎是一致的，在这里不再展开论述。另外，文中也在目标函数中加入L2正则防止过拟合。</p>
<h2 id="Attentional-Factorization-Machines-IJCAI’17"><a href="#Attentional-Factorization-Machines-IJCAI’17" class="headerlink" title="Attentional Factorization Machines[IJCAI’17]"></a>Attentional Factorization Machines[IJCAI’17]</h2><p>本节主要参考<a href="https://zhuanlan.zhihu.com/p/395140453" target="_blank" rel="noopener">推荐算法精排模型AFM</a></p>
<h3 id="解决的问题-5"><a href="#解决的问题-5" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>FM在做特征交互时，对所有交叉项赋予相同的权重，这可能是不够准确的，不相关的特征的交叉项可能还会引来噪声，论文通过attention机制学习各特征交叉项的重要程度进行加权求和。</p>
<h3 id="做法及创新-6"><a href="#做法及创新-6" class="headerlink" title="做法及创新"></a>做法及创新</h3><p>前面介绍DeepFM时说到它是典型的一种DNN与FM融合的并行结构，而本节的AFM就是典型的一种串行结构：</p>
<p><a href="https://imgtu.com/i/4skFPJ" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/25/4skFPJ.png" alt="4skFPJ.png" border="0"></a></p>
<h4 id="核心思想-4"><a href="#核心思想-4" class="headerlink" title="核心思想"></a>核心思想</h4><p>AFM的目的也是像FFM一样区分同一特征与不同特征组合时的相互作用，只是不再划分为field而是通过一个注意力网络学习得到权重，总体参数量增加不明显。</p>
<p>回顾FM的预测公式：</p>
<script type="math/tex; mode=display">
\hat{y}(x):=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+\sum_{i=1}^{n} \sum_{j=i+1}^{n}<v_{i}, v_{j}>x_{i} x_{j}</script><p>其中需要学习的参数为：</p>
<script type="math/tex; mode=display">
w_{0} \in \mathbb{R}, \quad w \in \mathbb{R}^{n}, \quad V \in \mathbb{R}^{n \times k}</script><p>它们的含义为：</p>
<ul>
<li>$w_0$表示全局的偏差；</li>
<li>$w_i$表示第i个特征的强度；</li>
<li>$w_{ij}$表示第i个特征和第j个特征之间的交互，在实际参数学习中不是直接学习交互特征的权重参数$w_{ij}$的，而是通过<strong>学习因式分解参数</strong>来学习交互特征的参数。</li>
</ul>
<p><a href="https://imgtu.com/i/4sk3RA" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/25/4sk3RA.png" alt="4sk3RA.png" border="0"></a></p>
<p>输入层和embedding层与FM模型是一样的，其中对于输入特征都采取了稀疏表示，即将所有的非零特征都嵌入到dense特征。嵌入后的表示为$v_ix_i$，而FM中二次项的系数分解为两个特征i和j的嵌入向量的叉乘，$w_{ij}=v_i^Tv_j$，这里$v_i$就是特征i的嵌入向量。</p>
<p><strong>Pair-wise交互层</strong></p>
<p>这一层的目的是在神经网络中表达FM的计算逻辑：</p>
<script type="math/tex; mode=display">
\hat{y}=\mathbf{p}^{T} \sum_{(i, j) \in \mathcal{R}_{x}}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}+b</script><p>向量p置为全1以及b设为0就回退到传统的FM模型。</p>
<p><strong>Attention-based池化层</strong></p>
<script type="math/tex; mode=display">
f_{\text {Att }}\left(f_{P I}(\mathcal{E})\right)=\sum_{(i, j) \in \mathcal{R}_{x}} a_{i j}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}</script><p>跟传统attention一样，$a_{ij}$就是表示特征i和j的交互在进行预测时的重要程度，可以直接通过最小化loss函数去学习$a_{ij}$，虽然看起来是可行的，但是这又会碰到之前的问题：当某个交互特征没有出现在样本中时，就没法学习某个交互特征的attention分数了。为了解决这个泛化能力方面的问题，我们使用MLP网络去参数化这个attention分数，该MLP网络称之为attention network。attention network的输入是嵌入后的两个特征的交互向量：</p>
<script type="math/tex; mode=display">
\begin{aligned}
a_{i j}^{\prime} &=\mathbf{h}^{T} ReL U\left(\mathbf{W}\left(\mathbf{v}_{i} \odot \mathbf{v}_{j}\right) x_{i} x_{j}+\mathbf{b}\right) \\
a_{i j} &=\frac{\exp \left(a_{i j}^{\prime}\right)}{\sum_{(i, j) \in \mathcal{R}_{x}} \exp \left(a_{i j}^{\prime}\right)}
\end{aligned}</script><p>Attention-based 池化层的输出是一个k维的向量，它在embedding空间中通过区分出各特征交互的重要性，来压缩所有的特征交互，然后将这些映射到最终的预测结果上面。</p>
<p>AFM模型在防止过拟合上的做法：</p>
<ul>
<li>dropout方式是通过防止神经元之间的共现性从而防止过拟合。由于AFM模型中会学习所有的特征之间的二阶交互特征，因此更加容易导致模型学习特征之间的共现性从而更容易导致过拟合，因此在pair-wise交互层使用了dropout方法来避免共现性。</li>
<li>对于AFM模型中的attention network，它是一个单层的MLP网络，这里使用L2正则化来防止过拟合，对于attention network，不选择dropout防止过拟合。</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/推荐系统/" rel="tag">#推荐系统</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/09/07/Leetcode笔记/" rel="next" title="Leetcode笔记">
                <i class="fa fa-chevron-left"></i> Leetcode笔记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.jpg"
                alt="Mr.shuan" />
            
              <p class="site-author-name" itemprop="name">Mr.shuan</p>
              <p class="site-description motion-element" itemprop="description">May 4th be with you</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">61</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://joaquinchou.com/" title="喵语小站" target="_blank">喵语小站</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://fans-xmu.github.io/" title="Fans的学习博客" target="_blank">Fans的学习博客</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Logistics-Regression"><span class="nav-number">1.</span> <span class="nav-text">Logistics Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#做法及创新"><span class="nav-number">1.1.</span> <span class="nav-text">做法及创新</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#核心思想"><span class="nav-number">1.1.1.</span> <span class="nav-text">核心思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#损失函数"><span class="nav-number">1.1.2.</span> <span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#特征工程"><span class="nav-number">1.1.3.</span> <span class="nav-text">特征工程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Wide-amp-Deep-Learning-for-Recommender-Systems-DLRS’16"><span class="nav-number">2.</span> <span class="nav-text">Wide &amp; Deep Learning for Recommender Systems[DLRS’16]</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#解决的问题"><span class="nav-number">2.1.</span> <span class="nav-text">解决的问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Memorization"><span class="nav-number">2.1.1.</span> <span class="nav-text">Memorization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Generalization"><span class="nav-number">2.1.2.</span> <span class="nav-text">Generalization</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#做法及创新-1"><span class="nav-number">2.2.</span> <span class="nav-text">做法及创新</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#网络结构"><span class="nav-number">2.2.1.</span> <span class="nav-text">网络结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#实践细节"><span class="nav-number">2.2.2.</span> <span class="nav-text">实践细节</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Factorization-Machines"><span class="nav-number">3.</span> <span class="nav-text">Factorization Machines</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#解决的问题-1"><span class="nav-number">3.1.</span> <span class="nav-text">解决的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#做法及创新-2"><span class="nav-number">3.2.</span> <span class="nav-text">做法及创新</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#核心思想-1"><span class="nav-number">3.2.1.</span> <span class="nav-text">核心思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#计算化简"><span class="nav-number">3.2.2.</span> <span class="nav-text">计算化简</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#损失函数-1"><span class="nav-number">3.2.3.</span> <span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#特征工程-1"><span class="nav-number">3.2.4.</span> <span class="nav-text">特征工程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Field-aware-Factorization-Machines-for-CTR-Prediction-RecSys’16"><span class="nav-number">4.</span> <span class="nav-text">Field-aware Factorization Machines for CTR Prediction[RecSys’16]</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#解决的问题-2"><span class="nav-number">4.1.</span> <span class="nav-text">解决的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#做法及创新-3"><span class="nav-number">4.2.</span> <span class="nav-text">做法及创新</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#核心思想-2"><span class="nav-number">4.2.1.</span> <span class="nav-text">核心思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#实践细节-1"><span class="nav-number">4.2.2.</span> <span class="nav-text">实践细节</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DeepFM-A-Factorization-Machine-based-Neural-Network-for-CTR-Prediction-IJCAI’17"><span class="nav-number">5.</span> <span class="nav-text">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction[IJCAI’17]</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#解决的问题-3"><span class="nav-number">5.1.</span> <span class="nav-text">解决的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#做法及创新-4"><span class="nav-number">5.2.</span> <span class="nav-text">做法及创新</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DNN与高维特征"><span class="nav-number">5.2.1.</span> <span class="nav-text">DNN与高维特征</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#核心思想-3"><span class="nav-number">5.2.2.</span> <span class="nav-text">核心思想</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-Neural-Networks-for-YouTube-Recommendations-RecSys’16"><span class="nav-number">6.</span> <span class="nav-text">Deep Neural Networks for YouTube Recommendations[RecSys’16]</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#解决的问题-4"><span class="nav-number">6.1.</span> <span class="nav-text">解决的问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#做法及创新-5"><span class="nav-number">6.1.1.</span> <span class="nav-text">做法及创新</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#粗排模型"><span class="nav-number">6.1.2.</span> <span class="nav-text">粗排模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#精排模型"><span class="nav-number">6.1.3.</span> <span class="nav-text">精排模型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Attentional-Factorization-Machines-IJCAI’17"><span class="nav-number">7.</span> <span class="nav-text">Attentional Factorization Machines[IJCAI’17]</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#解决的问题-5"><span class="nav-number">7.1.</span> <span class="nav-text">解决的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#做法及创新-6"><span class="nav-number">7.2.</span> <span class="nav-text">做法及创新</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#核心思想-4"><span class="nav-number">7.2.1.</span> <span class="nav-text">核心思想</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mr.shuan</span>

  
</div>


  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <span id="busuanzi_container_site_pv">原力小站已到访<span id="busuanzi_value_site_pv"></span>人次</span>
  <span class="post-meta-divider">|</span>
  <span id="busuanzi_container_site_uv">欢迎第<span id="busuanzi_value_site_uv"></span>位绝地武士








<div class="theme-info">
  <span class="post-meta-divider">|</span>
  <span class="post-count">小站全站共140.7k字</span>
</div>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("yfqHuQnnOVtQFUYkBt8hCuPk-gzGzoHsz", "04fMIxrudywlX8NlYX71hCnM");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  


</body>
</html>
